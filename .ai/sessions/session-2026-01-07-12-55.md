# Session Handoff: Dual LLM 설정 및 운영 최적화

## 요약 (Summary)
LG EXAONE 3.5 7.8B 모델을 news-crawler에 도입하여 gpt-oss:20b와 듀얼 LLM 체제를 구축했습니다. buy-scanner 스캔 간격을 3분으로 단축하고, 수동 관리 종목 제외 로직을 정리했습니다.

## 변경 사항 (Changes)
- `infrastructure/env-vars-wsl.yaml`:
  - `LOCAL_MODEL_FAST: exaone3.5:7.8b` (news-crawler용 EXAONE 모델)
  - `EXCLUDED_STOCKS: ""` (종목 제외 로직 제거)
  - `ENABLE_SCOUT_JOB_WORKER: true` (Scout Job 활성화)
- `services/daily-briefing/reporter.py`: `MANUAL_MANAGED_CODES` 리스트 비움
- `README.md`: "핵심 지능" 섹션 v1.1로 업데이트 (Dual Local LLM 운영 강조)
- **DB 변경**:
  - `jobs.interval_seconds`: buy-scanner 300초 → 180초 (5분 → 3분)
  - Redis `buy_lock:*` 삭제 (중복 매수 Lock 해제)

## EXAONE 3.5 테스트 결과
- **모델**: `exaone3.5:7.8b` (LG AI Research, 4.8GB)
- **뉴스 분석 속도**: ~0.83 items/sec (gpt-oss:20b 대비 **2배 빠름**)
- **VRAM 사용량**: ~5-6GB (gpt-oss:20b ~14GB와 동시 운영 시 총 ~20GB)

## 다음 단계 (Next Steps)
- [ ] EXAONE 3.5 JSON 출력 안정성 모니터링 (파싱 오류 발생 시 gpt-oss로 원복)
- [ ] **Phase 3: 백테스트 데이터 분할 (Train/Test 70/30 Split)** - `utilities/backtest_gpt_v2.py`
- [ ] **Phase 1: 분봉 데이터 수집** - 장중 1분봉 수집 스크립트

## Context for Next Session
- `infrastructure/env-vars-wsl.yaml` - LLM 모델 설정
- `utilities/backtest_gpt_v2.py` - 백테스트 개선 대상
- `shared/llm_factory.py` - LLM Tier 설정 확인
