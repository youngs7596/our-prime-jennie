# Session Handoff: Hybrid DeepSeek Cloud Gateway & System Stability

## 요약 (Summary)
이번 세션에서는 DeepSeek V3.2 Cloud 모델 도입을 완료하고, `ollama-gateway`에 하이브리드 클라우드 프록시 로직을 구현하여 시스템 안정성을 확보했습니다. Gemini Fallback 로직을 완전히 제거했으며, 속도 제한(429) 및 서킷 브레이커(503) 이슈를 해결했습니다.

## 변경 사항 (Changes)
- `services/ollama-gateway/main.py`: 하이브리드 프록시 로직 구현. `:cloud` 접미사가 붙은 모델 요청을 `https://ollama.com`으로 중계하며, 실패 시 로컬 `gpt-oss:20b`로 자동 폴백합니다.
- `shared/llm_factory.py`, `shared/llm.py`: Gemini Fallback 관련 모든 로직(`get_fallback_provider`)을 제거했습니다.
- `docker-compose.yml`:
    - `ollama-gateway`: `OLLAMA_RATE_LIMIT`를 분당 1000개로 상향하고 `OLLAMA_MAX_CONCURRENT_REQUESTS`를 설정했습니다.
    - `scout-worker`: `LOCAL_MODEL_REASONING`을 `deepseek-v3.2:cloud`로 고정했습니다.
- `infrastructure/env-vars-wsl.yaml`: 테스트를 위해 `SCOUT_UNIVERSE_SIZE`를 5로 임시 조정했습니다. (운영 시 다시 200으로 상향 필요)
- `shared/auth.py`: `secrets.json`에서 `ollama_api_key`를 로드하는 로직을 확인 및 활용했습니다.

## 다음 단계 (Next Steps)
- DeepSeek Cloud API의 실제 Reject Rate 모니터링 (`ollama-gateway` 로그 확인).
- `SCOUT_UNIVERSE_SIZE`를 다시 200으로 원복하여 전체 유니버스 스캔 수행.
- Cloud API 비용 최적화 (Quota 초과 시 로컬 폴백 동작 확인).
- DeepSeek R1 32B 로컬 모델의 유효성 검증 (필요 시).
