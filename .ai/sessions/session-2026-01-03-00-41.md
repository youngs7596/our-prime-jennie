# Session Handoff: News Crawler 뉴스 소스 필터링 개선

## 요약 (Summary)
현자 3인(Gemini, Claude, GPT) 피드백을 반영하여 뉴스 크롤러의 소스 필터링 로직을 대폭 개선했습니다. 저품질 뉴스 유입 차단, 실제 발행일 검증, 중복 제거 기능을 추가하고, FDR API 장애 대응으로 네이버 금융 스크래핑 Fallback을 구현했습니다.

## 변경 사항 (Changes)

### services/news-crawler/crawler.py
- `TRUSTED_NEWS_DOMAINS` (13개 경제 전문지), `WRAPPER_DOMAINS` (포털), `NOISE_KEYWORDS` (14개) 상수 추가
- `TRUSTED_SOURCE_NAMES` (20개 언론사 이름) 상수 추가
- `get_hostname()`, `is_trusted_hostname()`, `is_wrapper_domain()` 함수 추가 (hostname suffix 매칭)
- `extract_date_from_url()` 함수 추가 (URL 패턴 날짜 추출)
- `is_noise_title()`, `is_trusted_source_name()` 함수 추가
- `compute_news_hash()`, `_seen_news_hashes` 추가 (세션 내 중복 제거)
- `_scrape_naver_finance_top_stocks()` 함수 추가 (FDR 장애 대응 Fallback)
- `crawl_news_for_stock()` 함수 전면 리팩토링 (5단계 필터링 + 통계 로그)
- `GENERAL_RSS_FEEDS` 업데이트 (한국경제 추가, Investing.com 제거)

### shared/llm_factory.py
- `LLMTier.FAST` 모델을 `gpt-oss:20b` → `gemma3:27b`로 변경 (JSON 안정성)

### tests/services/news-crawler/test_source_filter.py
- 뉴스 필터링 유틸 함수 단위 테스트 18개 추가

## 검증 결과
- 단위 테스트: 18개 전체 통과
- 운영 테스트: 1008개 문서 수집 → 721개 신규 문서 분석 확인
- Universe: 18개 → 200개 종목 정상 확장

## 다음 단계 (Next Steps)
- [ ] Grafana에서 필터링 통계 대시보드 구성
- [ ] 네이버 금융 종목 뉴스 직접 크롤링 검토 (장기)
- [ ] 뉴스 품질 지표 모니터링 (Drop rate, 소스 분포)
