# Session Handoff: News Crawler Cost Elimination

## 요약 (Summary)
News Crawler의 과도한 Gemini API 비용(월 약 41만원) 문제를 해결하기 위해 임베딩 및 LLM 분석 과정을 전면 로컬화했습니다. Cloud Embedding을 Local HuggingFace Embedding으로, Cloud Gemini를 Local Ollama(gemma3:27b)로 대체하여 API 비용을 완전히 제거했습니다.

## 변경 사항 (Changes)
- **Local Embedding 도입**: `services/news-crawler/crawler.py`에서 `GoogleGenerativeAIEmbeddings` 대신 `HuggingFaceEmbeddings` (`jhgan/ko-sroberta-multitask`) 사용.
- **Local LLM 전환**: `shared/llm_factory.py`에서 `FAST` tier 기본 제공자를 `ollama`로 변경하고, `news-crawler` Docker 설정에서 강제 적용.
- **필터링 제거**: 비용 절감을 위해 존재했던 키워드 기반 사전 필터링(`NewsClassifier`) 및 40개 문서 분석 제한을 제거하고, 모든 종목 뉴스에 대해 심층 분석 수행.
- **Docker 최적화**: `requirements.txt` 레이어 캐싱을 통해 `news-crawler` 빌드 시간을 5분에서 30초 내외로 단축.
- **Cloud Fallback 제거**: Local LLM 실패 시 비용 발생을 막기 위해 Cloud API로의 Fallback 로직 제거.

## 다음 단계 (Next Steps)
- **Local LLM 속도 최적화**: 현재 문서당 약 20초 소요되는 분석 속도 개선 필요 (Ollama 직접 병렬 호출 또는 경량화 모델 `gemma2:9b` 도입 검토).
- **Scheduler 재검증**: 변경된 `news-crawler` 및 `scout-job` 스케줄링(시간 분리)이 실제 운영 환경에서 충돌 없이 작동하는지 모니터링.
