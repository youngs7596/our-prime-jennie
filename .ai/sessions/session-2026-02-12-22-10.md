# Session Handoff: 2026-02-12 22:10

## 세션 주제
news-archiver Qdrant 연결 장애 복구 + Redis Streams pending 메시지 자동 복구 로직

## 배경
컨테이너 현황 점검 중 `news-archiver`가 928회 재시작 루프에 빠져있는 것을 발견.
원인은 Qdrant 컨테이너가 포트 바인딩 없이 생성되어 `localhost:6333` 접근 불가.
복구 과정에서 Redis Streams의 pending 메시지(미ACK)가 영원히 처리되지 않는 구조적 버그도 발견.

## 진단 결과
1. **Qdrant 포트 바인딩 누락**: 2026-02-07 컨테이너 생성 시 `ports: 6333:6333`이 반영 안 됨
   - `network_mode: host`인 news-archiver만 `localhost:6333` 접근 불가 → 재시작 루프
   - 다른 서비스는 Docker 내부 네트워크(`msa-network`)로 접근하여 영향 없음
2. **pending 메시지 미처리 구조적 버그**: `consume_messages()`가 `">"` (신규만) 읽기만 수행
   - 이전 실행에서 deliver 후 crash → ACK 안 된 메시지가 영원히 pending 상태로 남음
3. **영향 범위**: 2026-02-07 ~ 02-12 (약 5일간) 뉴스 아카이빙 중단, RAG 검색 저하

## 변경 내역

### 1. Qdrant 컨테이너 재생성 (운영 조치)
- `docker compose --profile infra up -d --force-recreate qdrant`
- 포트 바인딩 `0.0.0.0:6333→6333` 정상 적용, 데이터 유실 없음

### 2. Redis Streams pending 자동 복구 (`shared/messaging/stream_client.py`)
- **`_recover_pending_messages()` 함수 신설**
  - Consumer 시작 시 ID `"0"`으로 읽어 미ACK pending 메시지 재처리
  - 실패한 메시지도 ACK 처리하여 무한 pending 누적 방지
  - 성공/실패 카운트 로깅
- **`consume_messages()` 2단계 구조로 변경**
  - Phase 1: `_recover_pending_messages()` 호출 (pending 복구)
  - Phase 2: `">"` 신규 메시지 소비 (기존 로직)

### 3. news-archiver 재빌드 및 복구 실행
- 7,941건 pending → 성공 7,192건, 실패 749건 (Qdrant 과부하 시 connection reset)
- Qdrant 벡터: 24,388 → 25,164 points

## 수정 파일 목록
| 파일 | 변경 |
|------|------|
| `shared/messaging/stream_client.py` | `_recover_pending_messages()` 신설, `consume_messages()` 2단계 구조 |

## 테스트 결과
- 문법 검증: OK
- `tests/shared/test_news_deduplicator.py`: 18/18 passed

## 롤백 전략
- `stream_client.py`의 `_recover_pending_messages` 제거 시 기존 동작(신규만 처리)으로 복귀
- pending 복구는 시작 시 1회만 실행되므로 성능 영향 없음

## 다음 단계 (TODO)
- [ ] 실패한 749건 뉴스 누락 모니터링 (대부분 중복 뉴스일 가능성 높음)
- [ ] `_recover_pending_messages`에 대한 유닛 테스트 추가 (mock Redis)
- [ ] news-archiver `network_mode: host` → Docker 네트워크 전환 검토 (근본 해결)
