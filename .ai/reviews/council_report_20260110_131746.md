# Prime Council Report
- Date: 2026-01-10 13:19:23
- Query: Code Structure Review
- Target: scripts/ask_prime_council.py

# Final Plan

## 1) 승인된 범위 (Approved scope)
- `scripts/ask_prime_council.py`의 JSON 파싱 견고성, 오류 컨텍스트 표준화, 스키마 유효성 검사 로직

## 2) 실행 순서가 있는 액션 스텝 (Action Steps)
1. **JSON 파싱 견고성 강화**: 
   - `_safe_generate` 함수 내 JSON 추출 로직을 개선하여, 여러 JSON 블록이나 잘못된 형식의 JSON을 처리할 수 있도록 수정합니다.
   
2. **오류 컨텍스트 표준화**: 
   - `load_file_content` 및 `load_system_prompt` 함수를 수정하여 구조화된 오류 객체를 반환하도록 합니다.
   
3. **스키마 유효성 검사 정의**: 
   - 각 LLM의 예상 출력 구조에 대한 명시적 검증을 추가합니다 (예: Pydantic 모델).
   
4. **보안: Secrets 마스킹**: 
   - 로그 및 예외 처리에서 API 키를 마스킹하는 유틸리티 함수를 추가합니다.
   
5. **실험 1: JSON 추출 및 스키마 유효성 검사**: 
   - `_safe_generate` 함수 개선 및 각 LLM의 예상 출력 스키마 정의 후, 파싱 성공률을 모니터링합니다.
   
6. **실험 2: 구조화된 오류 컨텍스트**: 
   - `load_file_content` 및 `load_system_prompt` 수정 후, LLM 응답에서 오류 메시지를 분석 대상으로 오인하는 경우를 모니터링합니다.
   
7. **리뷰 및 피드백**: 
   - 개선 사항을 적용한 후, 각 LLM의 출력 및 최종 보고서를 검토하여 품질을 평가합니다.

## 3) 실험 (Experiments) 및 수용 기준 (Acceptance criteria)
- **실험 1**: 
  - **가설**: 더 견고한 JSON 추출 + 스키마 유효성 검사 = LLM 간 통신 신뢰성 향상
  - **수용 기준**: 
    - Jennie 출력의 파싱 성공률 > 95%
    - Minji/Junho 입력에서 JSON 파싱 실패 빈도 < 5%

- **실험 2**: 
  - **가설**: 구조화된 오류 컨텍스트 + 명확한 LLM 지침 = 오류 메시지 오염 제거
  - **수용 기준**: 
    - LLM 응답에서 오류 메시지를 "분석 대상"으로 오인하는 경우 0건

## 4) 리스크 및 롤백 트리거 (Risk & rollback triggers)
- **리스크**:
  - 침묵하는 파싱 실패: JSON 파싱 실패가 다음 단계로 전달되어 최종 보고서 품질 저하.
  - LLM 컨텍스트 오염: 원시 오류 메시지가 LLM 입력에 포함되어 불필요한 토큰 소비 및 분석 정확도 저하.
  - 스키마 불일치: 파싱 성공 후 필드 누락이나 타입 오류 발생 가능.
  - 보안 유출: 로그나 예외 메시지에 API 키가 노출될 수 있음.

- **롤백 트리거**:
  - Jennie 또는 Minji의 출력이 2회 연속으로 JSON 파싱에 실패할 경우.
  - 최종 보고서에 `[System Context Errors]` 섹션이 있음에도 불구하고 오류가 분석 본문에 혼입된 경우.
  - `secrets.json` 로딩 중 API 키가 로그에 평문으로 출력되는 경우.

## Notes
- 제니, 민지의 이견은 보존하였으며, 준호의 결정을 우선하였습니다.

---
## Appendix: Raw JSON Outputs
<details><summary>Click to expand</summary>

### Jennie
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 95\n- scope: `scripts/ask_prime_council.py`의 LLM 출력 파싱, 컨텍스트 전달, 오류 처리 로직\n\n## Key Findings (<=5)\n1.  **취약한 LLM 간 통신:** `_safe_generate` 함수의 JSON 파싱 로직은 LLM 응답에 대화 텍스트나 잘못된 형식의 JSON이 포함될 경우 실패하기 쉬워, 후속 단계에 손상된 컨텍스트를 전달할 위험이 있습니다.\n2.  **부적절한 오류 전파:** 파일 없음, 프롬프트 누락 등 시스템 수준의 오류 메시지가 LLM 컨텍스트에 원시 문자열로 직접 전달되어, LLM이 이를 코드 분석 대상으로 오인하거나 불필요한 토큰을 낭비할 수 있습니다.\n3.  **출력 스키마 강제성 부족:** 각 LLM의 출력에 대한 명시적인 JSON 스키마 유효성 검사가 없어, 파싱이 성공하더라도 데이터 구조가 예상과 달라 논리적 오류를 유발할 수 있습니다.\n4.  **암묵적인 LLM 공급자 가정:** `generate_chat` 메서드와 특정 출력 구조에 대한 의존성은 다양한 LLM 공급자나 향후 API 변경에 대해 견고하지 않아, 숨겨진 취약점을 내포합니다.\n5.  **최적화되지 않은 Veto 트리거:** LLM 오류 시 `veto`를 반환하는 방어 로직은 존재하나, JSON 파싱의 취약성으로 인해 실제로는 유효한 LLM 응답이더라도 잘못 파싱되어 불필요한 Veto가 발생할 수 있습니다.\n\n## Evidence\n- references:\n    - `scripts/ask_prime_council.py`:\n        - `_safe_generate` 함수: `text_content.find(\"{\")`, `text_content.rfind(\"}\")`, `json.loads(text_content[start:end])` (JSON 파싱 로직)\n        - `_safe_generate` 함수: `return {\"text\": text_content, \"error\": \"No JSON found\"}` 또는 `{\"text\": text_content, \"error\": \"JSON Parse Failed\"}` (파싱 실패 시 반환 값)\n        - `_safe_generate` 함수: `return {\"error\": str(e), \"decision\": \"veto\"}` (LLM 호출 오류 시 반환 값)\n        - `load_file_content` 함수: `return f\"(File not found: {file_path})\"` 또는 `f\"(Error reading file {file_path}: {e})\"` (파일 오류 시 반환 값)\n        - `load_system_prompt` 함수: `return f\"You are {sage_name}. analyzing the request.\"` (시스템 프롬프트 누락 시 반환 값)\n        - `minji_context`, `junho_context`: `json.dumps(jennie_output, ensure_ascii=False)` (잠재적으로 잘못 파싱된 JSON을 다음 단계로 전달)\n- missing_data:\n    - **LLM 원시 출력 로그:** 실제 LLM (Jennie, Minji, Junho)의 원시 출력 로그, 특히 JSON 파싱이 실패하거나 파일/프롬프트가 누락된 시나리오에서의 로그가 있다면 현재 파싱 로직의 실패 빈도와 LLM이 오류 문자열에 어떻게 반응하는지 명확히 확인할 수 있습니다.\n    - **각 Council 멤버의 예상 JSON 스키마:** 각 LLM의 출력에 대한 명확한 JSON 스키마 정의가 있다면, `experiments` 섹션에서 제안된 유효성 검사 로직을 더 구체적으로 설계할 수 있습니다.\n\n## Risks & Veto Triggers\n- risks:\n    - **침묵하는 실패:** LLM의 잘못된 형식의 출력이 부분적으로 파싱되거나 오류 객체로 전달되어, 후속 단계의 품질이 저하되더라도 명확한 경고 없이 진행될 수 있습니다.\n    - **오해의 소지가 있는 보고서:** LLM이 원시 오류 메시지나 잘못된 형식의 컨텍스트를 받아들이면, 관련 없는 분석을 생성하여 최종 보고서의 신뢰성을 떨어뜨릴 수 있습니다.\n    - **파이프라인 불안정성:** LLM 공급자 API 또는 출력 형식의 변경은 취약한 JSON 파싱을 쉽게 무너뜨려 전체 Council 파이프라인이 예기치 않게 실패할 수 있습니다.\n    - **자원 낭비:** LLM이 잘못된 형식의 입력이나 오류 메시지를 해석하려 시도하면서 불필요한 토큰을 소비할 수 있습니다.\n- veto_if:\n    - 2개 이상의 연속된 LLM 단계가 예상 스키마에 맞는 유효한 JSON 출력을 생성하지 못할 경우.\n    - 최종 오케스트레이터 보고서가 핵심 컨텍스트(예: 대상 파일 내용)가 누락되었거나 해석 불가능하다고 명시적으로 언급할 경우.\n    - 특정 LLM 공급자가 3회 연속으로 API 오류(예: 5xx 상태 코드)를 반환할 경우.\n\n## Recommendations\n- immediate_actions:\n    1.  **JSON 견고성 강화:** `_safe_generate` 함수 내에서 대화 텍스트를 포함하는 JSON 블록을 처리하고, 약간 잘못된 형식의 JSON도 파싱을 시도할 수 있는 더욱 탄력적인 JSON 추출 메커니즘(예: `json5` 라이브러리 또는 커스텀 정규식 기반 추출기)을 구현합니다.\n    2.  **오류 컨텍스트 표준화:** `load_file_content` 및 `load_system_prompt` 함수를 수정하여 원시 문자열 대신 구조화된 오류 객체(예: `{\"type\": \"file_error\", \"message\": \"...\", \"path\": \"...\"}`)를 반환하도록 합니다. `_safe_generate` 함수는 이 구조화된 오류를 LLM 프롬프트의 전용 `[Contextual Errors]` 섹션에 래핑하여 전달하도록 업데이트합니다.\n    3.  **출력 스키마 정의:** Jennie, Minji, Junho 각 LLM의 예상 출력에 대한 명시적인 JSON 스키마(예: Pydantic 모델 또는 `jsonschema` 정의)를 생성합니다.\n- experiments:\n    1.  **Hypothesis:** 더 견고한 JSON 추출 방법(예: JSON 블록을 찾는 정규식 사용 또는 부분 JSON을 파싱할 수 있는 라이브러리)을 스키마 유효성 검사와 결합하면 LLM 간 통신의 신뢰성이 크게 향상될 것입니다.\n        *   **Method:**\n            1.  `_safe_generate`를 수정하여 더 정교한 JSON 추출(예: `json5` 또는 최외곽 JSON 객체를 찾는 정규식 기반 접근 방식)을 사용합니다.\n            2.  Jennie의 예상 출력에 대한 간단한 Pydantic 모델 또는 딕셔너리 스키마(예: `{\"decision\": str, \"confidence\": int, \"key_findings\": list, ...}`)를 도입합니다.\n            3.  추출 후, 이 스키마에 대해 추출된 JSON의 유효성을 검사합니다. 유효성 검사에 실패하면 오류를 로깅하고, 원시 오류 문자열 대신 표준화된 \"잘못된 형식의 출력\" JSON을 다음 단계에 제공합니다.\n        *   **Success Metrics:**\n            *   Minji의 입력에서 `{\"error\": \"JSON Parse Failed\"}` 또는 `{\"error\": \"No JSON found\"}`의 감소.\n            *   예상 스키마에 대해 성공적으로 파싱 및 유효성 검사된 Jennie 출력의 비율 증가.\n            *   Minji 및 Junho 보고서의 질적 향상(더 나은 구조화된 입력을 받았음을 나타냄).\n    2.  **Hypothesis:** LLM 컨텍스트 내에서 오류 메시지를 명확하게 구조화하고, 이를 해석하는 방법에 대한 명확한 지침을 제공하면 LLM이 시스템 오류를 실행 가능한 콘텐츠로 오해하는 것을 방지할 수 있습니다.\n        *   **Method:**\n            1.  `load_file_content` 및 `load_system_prompt`를 수정하여 문제가 발생할 때 원시 오류 문자열 대신 구조화된 객체(예: `{\"status\": \"error\", \"message\": \"File not found\", \"path\": \"...\"}`)를 반환하도록 합니다.\n            2.  `_safe_generate` 함수를 업데이트하여 이 구조화된 오류를 LLM 프롬프트의 특정 섹션(예: `[System Context Errors]: {error_json}`)에 포맷하고, 시스템 프롬프트에 \"만약 `[System Context Errors]`가 존재한다면, 이를 인지하고 분석에 미치는 영향을 설명하며, 존재하지 않는 코드를 분석하려 하지 마십시오.\"와 같은 특정 지침을 추가합니다.\n        *   **Success Metrics:**\n            *   오류 메시지를 \"분석\"하려는 LLM 응답의 감소.\n            *   누락된 파일이나 프롬프트의 영향을 올바르게 식별하고 설명하는 LLM 응답의 증가.\n            *   오류 시나리오에서 LLM이 더 효율적으로 안내됨에 따라 토큰 사용량 감소.\n- if_code_change_needed:\n    - `_safe_generate` 함수를 리팩토링하여 견고한 JSON 추출 및 스키마 유효성 검사 로직을 포함합니다.\n    - `load_file_content` 및 `load_system_prompt` 함수를 수정하여 구조화된 오류 객체를 반환하도록 합니다.\n    - `_safe_generate` 내의 프롬프트 구성 로직을 업데이트하여 구조화된 오류 컨텍스트를 처리합니다.\n    - LLM 간 데이터 전송을 위한 스키마 정의(예: Pydantic 모델)를 도입합니다.",
  "error": "JSON Parse Failed"
}
```
### Minji
```json
{
  "text": "# Council Output: Code Structure Review\n\n## Verdict\n- **decision:** approve_with_changes\n- **confidence:** 88\n- **scope:** `scripts/ask_prime_council.py`의 JSON 파싱 견고성, 오류 컨텍스트 표준화, 스키마 유효성 검사 로직 (파일 I/O, LLM 호출, 파이프라인 오케스트레이션은 제외)\n\n---\n\n## Key Findings (<=5)\n\n1. **JSON 파싱 취약점 (Critical):**\n   - `_safe_generate` 함수의 `text_content.find(\"{\")` + `rfind(\"}\")` 방식은 LLM 응답에 여러 JSON 블록이나 중괄호가 포함될 경우 잘못된 범위를 추출할 수 있습니다.\n   - 파싱 실패 시 `{\"error\": \"JSON Parse Failed\"}` 객체가 다음 단계로 전달되어, Minji/Junho가 이를 유효한 Jennie 출력으로 오인할 위험이 있습니다.\n\n2. **오류 메시지의 LLM 컨텍스트 오염:**\n   - `load_file_content`에서 `\"(File not found: {file_path})\"` 같은 원시 문자열이 LLM 입력에 직접 포함되면, LLM이 이를 분석 대상 코드로 오해하거나 불필요한 토큰을 소비합니다.\n   - 마찬가지로 `load_system_prompt`의 폴백 메시지도 LLM을 혼동시킬 수 있습니다.\n\n3. **스키마 유효성 검사 부재:**\n   - Jennie/Minji/Junho의 예상 출력 구조(예: `decision`, `confidence`, `scope` 필드)에 대한 명시적 검증이 없어, 파싱은 성공하더라도 필드 누락이나 타입 오류가 발생할 수 있습니다.\n\n4. **오류 전파 불명확성:**\n   - `_safe_generate`에서 LLM 호출 실패 시 `{\"error\": str(e), \"decision\": \"veto\"}`를 반환하지만, JSON 파싱 실패 시는 `{\"error\": \"JSON Parse Failed\"}`만 반환하여 일관성이 부족합니다.\n   - 후속 단계에서 `error` 필드의 존재 여부만으로 성공/실패를 판단하기 어렵습니다.\n\n5. **Secrets 로딩의 보안 고려:**\n   - `secrets.json`을 환경 변수로 직접 로드하는 방식은 메모리에 민감한 정보를 노출시킵니다.\n   - 현재 코드는 시크릿을 마스킹하지 않으므로, 로그나 오류 메시지에 API 키가 유출될 가능성이 있습니다.\n\n---\n\n## Evidence\n\n- **references:**\n  - `scripts/ask_prime_council.py` 라인 ~75-90: `_safe_generate` 함수의 JSON 추출 로직\n    ```python\n    start = text_content.find(\"{\")\n    end = text_content.rfind(\"}\") + 1\n    if start != -1 and end != -1:\n        return json.loads(text_content[start:end])\n    ```\n  - 라인 ~50-60: `load_file_content` 함수의 오류 반환\n    ```python\n    return f\"(File not found: {file_path})\"\n    return f\"(Error reading file {file_path}: {e})\"\n    ```\n  - 라인 ~42-48: `load_system_prompt` 함수의 폴백\n    ```python\n    return f\"You are {sage_name}. analyzing the request.\"\n    ```\n  - 라인 ~140-160: 파이프라인 단계별 컨텍스트 구성\n    ```python\n    minji_context = f\"{file_context}\\n\\n[Jennie's Findings]:\\n{json.dumps(jennie_output, ensure_ascii=False)}\"\n    ```\n  - 라인 ~180-195: `secrets.json` 로딩\n    ```python\n    for k, v in secrets.items():\n        if k == \"openai-api-key\": os.environ[\"OPENAI_API_KEY\"] = v\n    ```\n\n- **missing_data:**\n  - 실제 LLM 원시 응답 샘플 (특히 JSON 파싱이 실패하는 경우)\n  - Jennie/Minji/Junho의 예상 JSON 스키마 정의 (현재 `prompts/council/{name}_system.txt` 내용 미확인)\n  - 파이프라인 실행 로그 (파싱 실패 빈도, 오류 분포)\n\n---\n\n## Risks & Veto Triggers\n\n- **risks:**\n  - **침묵하는 파싱 실패:** `{\"error\": \"JSON Parse Failed\"}`가 다음 단계로 전달되면, Minji가 이를 유효한 Jennie 분석으로 처리하여 최종 보고서 품질이 저하됩니다.\n  - **LLM 컨텍스트 오염:** 원시 오류 메시지가 LLM 입력에 포함되면, 불필요한 토큰 소비 및 분석 정확도 저하.\n  - **스키마 불일치:** 파싱은 성공하지만 필드가 누락되거나 타입이 잘못되면, 후속 단계에서 KeyError 또는 타입 오류 발생 가능.\n  - **보안 유출:** 로그나 예외 메시지에 API 키가 노출될 수 있습니다.\n\n- **veto_if:**\n  - Jennie 또는 Minji의 출력이 2회 연속으로 JSON 파싱에 실패할 경우.\n  - 최종 보고서에 `[System Context Errors]` 섹션이 있음에도 불구하고 오류가 분석 본문에 혼입된 경우.\n  - `secrets.json` 로딩 중 API 키가 로그에 평문으로 출력되는 경우.\n\n---\n\n## Recommendations\n\n### immediate_actions\n\n1. **JSON 파싱 견고성 강화 (High Priority)**\n   - `_safe_generate` 함수 내 JSON 추출 로직을 개선하여, 여러 JSON 블록이나 마크다운 코드 펜스를 처리합니다.\n   - 추출 후 스키마 유효성 검사를 추가하여, 필드 누락 시 명확한 오류를 반환합니다.\n\n2. **오류 컨텍스트 표준화 (High Priority)**\n   - `load_file_content` 및 `load_system_prompt`를 수정하여 구조화된 오류 객체를 반환합니다.\n   - `_safe_generate`에서 이 오류를 LLM 프롬프트의 전용 `[System Context Errors]` 섹션으로 래핑합니다.\n\n3. **보안: Secrets 마스킹 (Medium Priority)**\n   - 로그 및 예외 처리에서 API 키를 마스킹하는 유틸리티 함수를 추가합니다.\n   - `secrets.json` 로딩 후 메모리에서 민감한 정보를 최소화합니다.\n\n---\n\n### experiments\n\n**Hypothesis 1:** 더 견고한 JSON 추출 + 스키마 유효성 검사 = LLM 간 통신 신뢰성 향상\n\n- **Method:**\n  1. `_safe_generate` 함수를 다음과 같이 개선:\n     - 마크다운 코드 펜스 (```json ... ```) 또는 최외곽 JSON 객체를 찾는 정규식 기반 추출\n     - 추출 후 예상 스키마(예: Jennie는 `decision`, `confidence`, `scope` 필드 필수)에 대해 유효성 검사\n     - 유효성 검사 실패 시 `{\"status\": \"invalid_schema\", \"raw_text\": \"...\", \"expected_fields\": [...]}` 반환\n  2. 각 LLM의 예상 출력 스키마를 `shared/council_schemas.py`에 정의 (Pydantic 모델 또는 딕셔너리)\n  3. 파이프라인 실행 시 각 단계의 파싱 성공률 메트릭 수집\n\n- **Success Metrics:**\n  - Jennie 출력의 파싱 성공률 > 95%\n  - Minji/Junho 입력에서 `{\"error\": \"JSON Parse Failed\"}` 발생 빈도 < 5%\n  - 최종 보고서에서 누락된 필드로 인한 오류 0건\n\n---\n\n**Hypothesis 2:** 구조화된 오류 컨텍스트 + 명확한 LLM 지침 = 오류 메시지 오염 제거\n\n- **Method:**\n  1. `load_file_content` 및 `load_system_prompt` 수정:\n     ```python\n     def load_file_content(file_path: str) -> dict:\n         path = Path(file_path)\n         if not path.exists():\n             return {\n                 \"status\": \"error\",\n                 \"type\": \"file_not_found\",\n                 \"path\": str(file_path),\n                 \"message\": f\"File not found: {file_path}\"\n             }\n         # ... 정상 로드 시\n         return {\"status\": \"ok\", \"content\": content, \"path\": str(file_path)}\n     ```\n  2. `_safe_generate`에서 컨텍스트 구성 시:\n     ```python\n     if isinstance(file_context, dict) and file_context.get(\"status\") == \"error\":\n         context = f\"[System Context Errors]\\n{json.dumps(file_context, ensure_ascii=False)}\\n\\n[Note] If errors are present, acknowledge them and explain impact on analysis.\"\n     else:\n         context = file_context\n     ```\n  3. 각 LLM의 시스템 프롬프트에 다음 지침 추가:\n     > \"If `[System Context Errors]` section exists, acknowledge it explicitly. Do NOT attempt to analyze non-existent files or missing prompts. Instead, explain how this affects your analysis.\"\n\n- **Success Metrics:**\n  - LLM 응답에서 오류 메시지를 \"분석 대상\"으로 오인하는 경우 0건\n  - 누락된 파일/프롬프트의 영향을 명시적으로 설명하는 LLM 응답 비율 > 90%\n  - 오류 시나리오에서 토큰 사용량 감소 (불필요한 분석 제거)\n\n---\n\n### if_code_change_needed\n\n**Concrete Diff (Minji's Proposal):**\n\n```python\n# 1. 스키마 정의 추가 (shared/council_schemas.py 신규 파일)\nfrom typing import Literal\nfrom pydantic import BaseModel, Field\n\nclass JennieOutput(BaseModel):\n    decision: Literal[\"approve\", \"approve_with_changes\", \"veto\"]\n    confidence: int = Field(ge=0, le=100)\n    scope: str\n    key_findings: list[str]\n    evidence: dict\n    risks: dict\n    recommendations: dict\n\n# 2. _safe_generate 함수 개선\nimport re\nfrom shared.council_schemas import JennieOutput\n\ndef _safe_generate(provider, system_prompt, user_query, context, prev_reports):\n    \"\"\"Enhanced LLM generation with robust JSON parsing and schema validation\"\"\"\n    history = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": f\"{context}\\n\\nQuestion: {user_query}\"}\n    ]\n    try:\n        res = provider.generate_chat(history)\n        text_content = res.get(\"text\") or res.get(\"content\", \"\")\n        \n        # 개선된 JSON 추출: 마크다운 코드 펜스 또는 최외곽 JSON 객체\n        json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', text_content, re.DOTALL)\n        if json_match:\n            json_str = json_match.group(1)\n        else:\n            # 최외곽 JSON 객체 찾기\n            start = text_content.find(\"{\")\n            end = text_content.rfind(\"}\") + 1\n            if start != -1 and end > start:\n                json_str = text_content[start:end]\n            else:\n                return {\n                    \"status\": \"parse_error\",\n                    \"error\": \"No JSON found\",\n                    \"raw_text\": text_content[:500]  # 처음 500자만 포함\n                }\n        \n        try:\n            parsed = json.loads(json_str)\n            # 스키마 유효성 검사 (Jennie 출력 기준)\n            if \"decision\" in parsed:  # Jennie 출력 감지\n                JennieOutput(**parsed)  # Pydantic 검증\n            return {\"status\": \"ok\", \"data\": parsed}\n        except json.JSONDecodeError as e:\n            return {\n                \"status\": \"parse_error\",\n                \"error\": f\"JSON decode failed: {e}\",\n                \"raw_text\": json_str[:500]\n            }\n        except Exception as e:  # Pydantic 검증 실패\n            return {\n                \"status\": \"schema_error\",\n                \"error\": f\"Schema validation failed: {e}\",\n                \"raw_data\": parsed\n            }\n            \n    except Exception as e:\n        logger.error(f\"LLM Error: {e}\")\n        return {\"status\": \"llm_error\", \"error\": str(e)}\n\n# 3. load_file_content 함수 개선\ndef load_file_content(file_path: str) -> dict:\n    \"\"\"Load file content with structured error handling\"\"\"\n    path = Path(file_path)\n    if not path.is_absolute():\n        path = PROJECT_ROOT / path\n    \n    if not path.exists():\n        return {\n            \"status\": \"error\",\n            \"type\": \"file_not_found\",\n            \"path\": str(file_path),\n            \"message\": f\"File not found: {file_path}\"\n        }\n    \n    try:\n        content = path.read_text(encoding=\"utf-8\")\n        return {\n            \"status\": \"",
  "error": "JSON Parse Failed"
}
```
### Junho
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 90\n- scope: `scripts/ask_prime_council.py`의 JSON 파싱 견고성, 오류 컨텍스트 표준화, 스키마 유효성 검사 로직 (파일 I/O, LLM 호출, 파이프라인 오케스트레이션은 제외)\n\n## Key Findings (<=5)\n1. **JSON 파싱 취약점:** `_safe_generate` 함수의 JSON 파싱 로직은 LLM 응답에 여러 JSON 블록이나 잘못된 형식이 포함될 경우 실패할 위험이 있습니다.\n2. **오류 메시지의 LLM 컨텍스트 오염:** 원시 오류 메시지가 LLM 입력에 포함되면, LLM이 이를 분석 대상 코드로 오해하거나 불필요한 토큰을 소비할 수 있습니다.\n3. **스키마 유효성 검사 부재:** 각 LLM의 예상 출력 구조에 대한 명시적 검증이 없어, 파싱 성공 후에도 필드 누락이나 타입 오류가 발생할 수 있습니다.\n4. **오류 전파 불명확성:** LLM 호출 실패 시 반환되는 오류 메시지가 일관성이 부족하여, 후속 단계에서 성공/실패 판단이 어렵습니다.\n5. **Secrets 로딩의 보안 고려:** `secrets.json`을 환경 변수로 직접 로드하는 방식은 민감한 정보를 노출시킬 수 있습니다.\n\n## Evidence\n- references:\n  - `scripts/ask_prime_council.py`의 `_safe_generate` 함수: JSON 추출 로직\n  - `load_file_content` 및 `load_system_prompt` 함수의 오류 반환\n  - 파이프라인 단계별 컨텍스트 구성\n  - `secrets.json` 로딩\n- missing_data:\n  - 실제 LLM 원시 응답 샘플 (특히 JSON 파싱이 실패하는 경우)\n  - 각 LLM의 예상 JSON 스키마 정의\n  - 파이프라인 실행 로그 (파싱 실패 빈도, 오류 분포)\n\n## Risks & Veto Triggers\n- risks:\n  - **침묵하는 파싱 실패:** JSON 파싱 실패가 다음 단계로 전달되어, 최종 보고서 품질이 저하될 수 있습니다.\n  - **LLM 컨텍스트 오염:** 원시 오류 메시지가 LLM 입력에 포함되면, 불필요한 토큰 소비 및 분석 정확도 저하.\n  - **스키마 불일치:** 파싱은 성공하지만 필드가 누락되거나 타입이 잘못되면, 후속 단계에서 오류 발생 가능.\n  - **보안 유출:** 로그나 예외 메시지에 API 키가 노출될 수 있습니다.\n- veto_if:\n  - Jennie 또는 Minji의 출력이 2회 연속으로 JSON 파싱에 실패할 경우.\n  - 최종 보고서에 `[System Context Errors]` 섹션이 있음에도 불구하고 오류가 분석 본문에 혼입된 경우.\n  - `secrets.json` 로딩 중 API 키가 로그에 평문으로 출력되는 경우.\n\n## Recommendations\n- immediate_actions:\n  1. **JSON 파싱 견고성 강화:** `_safe_generate` 함수 내 JSON 추출 로직을 개선하여, 여러 JSON 블록이나 마크다운 코드 펜스를 처리합니다.\n  2. **오류 컨텍스트 표준화:** `load_file_content` 및 `load_system_prompt`를 수정하여 구조화된 오류 객체를 반환합니다.\n  3. **보안: Secrets 마스킹:** 로그 및 예외 처리에서 API 키를 마스킹하는 유틸리티 함수를 추가합니다.\n  \n- experiments:\n  1. **Hypothesis:** 더 견고한 JSON 추출 + 스키마 유효성 검사 = LLM 간 통신 신뢰성 향상\n     - **Method:** `_safe_generate` 함수 개선 및 각 LLM의 예상 출력 스키마 정의.\n     - **Success Metrics:** Jennie 출력의 파싱 성공률 > 95%, Minji/Junho 입력에서 JSON 파싱 실패 빈도 < 5%.\n  2. **Hypothesis:** 구조화된 오류 컨텍스트 + 명확한 LLM 지침 = 오류 메시지 오염 제거\n     - **Method:** `load_file_content` 및 `load_system_prompt` 수정하여 구조화된 오류 객체 반환.\n     - **Success Metrics:** LLM 응답에서 오류 메시지를 \"분석 대상\"으로 오인하는 경우 0건.\n\n- if_code_change_needed:\n  - `_safe_generate` 함수 리팩토링 및 스키마 유효성 검사 로직 포함.\n  - `load_file_content` 및 `load_system_prompt` 수정하여 구조화된 오류 객체 반환.",
  "error": "No JSON found"
}
```

</details>