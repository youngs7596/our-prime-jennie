# Prime Council Report
- Date: 2026-02-06 16:45:02
- Query: 다음 RAG 검색 품질 개선 계획서를 리뷰해주세요. 현재 뉴스 RAG 시스템의 3가지 핵심 문제(page_content에 제목만 저장, 하드코딩 단일 쿼리, 낮은 RAG 후보 정밀도)에 대한 개선 방안의 타당성, 우선순위, 리스크를 분석하고 최종 권고안을 제시해주세요.
- Target: .ai/reviews/rag_improvement_plan.md

# Final Plan: RAG 검색 품질 개선 계획

## 1. 승인된 범위 (Approved scope)
- **IN**: 
  - Phase 1A (뉴스 본문 크롤링) → 조건부 승인 (리스크 완화 후 파일럿)
  - Phase 1C (메타데이터 강화) → 즉시 구현
  - Phase 2 (다중 쿼리) → 즉시 구현
  - Phase 3 (RAG 후보 개선) → 즉시 구현
- **OUT**: 
  - Phase 1B (LLM 요약) → 비용/지연 대비 효과 불명확, 보류
  - 임베딩 모델 변경 → 현재 데이터 부족, 별도 검증 필요

## 2. 실행 순서가 있는 액션 스텝 (Action Steps)
1. **Phase 1A (뉴스 본문 크롤링) 선행 준비 및 리스크 완화**
   - 본문 크롤링 로직 개발 및 네이버 크롤링 리스크 완화 전략 병행
   - ThreadPoolExecutor, request_delay, 프록시 활용 등 적용
2. **Phase 2 (다중 쿼리 검색) 즉시 적용**
   - `_generate_search_queries` 함수 구현 및 `_search_news_for_stock()`에 적용
3. **Phase 3 (RAG 후보 발굴 개선) 즉시 적용**
   - 중복 제거 로직 및 `created_at_utc` 필터 적용
4. **기존 뉴스 데이터 마이그레이션 전략 수립**
   - 수백만 건의 기존 뉴스 데이터 본문 재크롤링 계획 수립
5. **모니터링 시스템 구축**
   - 크롤링 중 IP 차단 감지 시 자동 중단 및 알림 시스템 구축
6. **성능 메트릭 수집 및 분석**
   - Precision, Recall, F1-score 등의 메트릭 수집 및 분석
7. **실험 결과 분석 및 피드백**
   - 각 Phase의 실험 결과를 분석하여 개선 사항 도출

## 3. 실험 및 수용 기준 (Experiments & Acceptance criteria)
- **가설 1**: 뉴스 본문(또는 요약)을 포함한 `page_content`는 임베딩 검색의 정밀도와 재현율을 유의미하게 향상시킨다.
  - **성공 메트릭**: 정밀도, 재현율, 의사결정 관련성 평가
- **가설 2**: 다중 쿼리 검색 전략은 단일 쿼리 대비 다양한 관점의 뉴스를 포착하여 리스크 감지 및 기회 발굴 능력을 향상시킨다.
  - **성공 메트릭**: 검색 결과의 다양성, 리스크 뉴스 감지율, 오탐율
- **가설 3**: Phase 3의 RAG 후보 발굴 개선 방안은 후보 종목의 정밀도와 다양성을 높인다.
  - **성공 메트릭**: 후보 종목의 고유성, 정밀도, 다양성

## 4. 리스크 및 롤백 트리거 (Risk & rollback triggers)
- **리스크**:
  - 네이버 크롤링 Rate Limit/IP 차단
  - 데이터 신선도 저하
  - 기존 데이터 마이그레이션 비용
  - 다중 쿼리의 벡터 스토어 부하
- **롤백 트리거**:
  - Phase 1A 구현 시 24시간 내 IP 차단 3회 이상 발생
  - 개선된 RAG 시스템의 정밀도 향상 < 5% (기존 대비)
  - 리스크 신호 감지율 개선 < 3% (기존 대비)
  - 자동매매 시스템의 오탐율 증가 > 10% (기존 대비)

## Notes
- 제니와 민지의 의견을 반영하여 Phase 1A의 리스크 완화 전략을 강화하고, 데이터 마이그레이션 계획을 수립해야 합니다.

---
## Appendix: Raw JSON Outputs
<details><summary>Click to expand</summary>

### Jennie
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 90\n- scope: RAG 검색 품질 개선 계획 전반 (뉴스 데이터 수집, 임베딩, 검색 쿼리 전략, 후보 발굴)\n\n## Key Findings\n1.  **`page_content`의 근본적 한계**: 현재 뉴스 제목만으로 구성된 `page_content`는 시맨틱 검색의 핵심인 임베딩 품질을 심각하게 저해하며, 이는 \"실적이 좋았는지 나빴는지 알 수 없음\"과 같은 결정적 순간의 정보 부족으로 이어집니다. 이는 모든 RAG 개선의 선행 조건입니다.\n2.  **단일 쿼리의 리스크 노출**: \"실적 수주 호재\"와 같은 단일 하드코딩 쿼리는 시장 국면 변화, 섹터별 특성, 그리고 특히 \"부정적 뉴스(리스크)를 놓침\"으로써 자동매매 시스템의 보수적 리스크 관점과 정면으로 배치됩니다.\n3.  **RAG 후보 발굴의 비효율성**: `k=50`의 대량 검색에도 불구하고 중복, 잡음, 오래된 뉴스 혼입은 \"실질적 다양성\"과 \"정밀도\"를 떨어뜨려 기회 발굴 및 리스크 감지 효율을 저하시킵니다.\n4.  **Phase 1A의 높은 잠재력과 리스크**: 뉴스 본문 크롤링(Phase 1A)은 검색 품질을 가장 크게 개선할 잠재력이 있으나, 네이버의 rate limit 및 IP 차단 리스크, 크롤링 시간 증가, 기존 데이터 마이그레이션 비용 등 운영상 리스크가 가장 큽니다.\n\n## Evidence\n- references:\n    - `shared/crawlers/naver.py:177`, `collector.py:122`: `page_content` 구성\n    - `scout.py:326`, `scout.py:547`: 하드코딩된 단일 검색 쿼리\n    - `rag_improvement_plan.md` 섹션 1.1, 1.2, 1.3: 현재 문제점 분석\n    - `rag_improvement_plan.md` 섹션 2.1, 2.2, 2.3: 개선 방안\n    - `rag_improvement_plan.md` 섹션 3: 구현 우선순위\n- missing_data:\n    - **현재 RAG 시스템의 정량적 성능 지표**: 현재 RAG 검색의 정밀도(Precision), 재현율(Recall), F1-score, 그리고 최종 의사결정(예: 매수/매도 신호)에 대한 기여도 메트릭이 있다면 각 개선 방안의 예상 효과를 더 정확히 예측하고 우선순위를 조정할 수 있습니다.\n    - **네이버 크롤링 실제 Rate Limit 및 차단 경험 데이터**: Phase 1A의 리스크를 정량화하고 대응 전략을 수립하는 데 필수적입니다.\n    - **LLM 요약 비용 및 지연 시간 추정치**: Phase 1B 고려 시 LLM tier별 비용 및 API 응답 지연 시간이 있다면 방안 B의 타당성을 더 정확히 평가할 수 있습니다.\n    - **`kure-v1` 모델의 한국어 뉴스 데이터에 대한 벤치마크 결과**: 현재 임베딩 모델의 적합성을 판단하기 위한 외부 또는 내부 벤치마크 데이터가 필요합니다.\n\n## Risks & Veto Triggers\n- risks:\n    - **네이버 크롤링 Rate Limit/IP 차단**: Phase 1A 구현 시 발생할 수 있는 가장 큰 운영 리스크입니다. 크롤링 시스템의 안정성 저하 및 데이터 수집 중단으로 이어질 수 있습니다.\n    - **데이터 신선도 저하**: 본문 크롤링으로 인한 수집 시간 증가는 뉴스 데이터의 신선도를 떨어뜨려 실시간 시장 대응 능력을 저해할 수 있습니다.\n    - **오래된 데이터의 영향**: Phase 1A 적용 시 기존에 제목만으로 저장된 뉴스 데이터에 대한 마이그레이션 전략이 부재하면, 과거 데이터의 검색 품질은 여전히 낮게 유지됩니다.\n    - **과도한 쿼리 부하**: Phase 2, 3에서 다중 쿼리 사용 시 벡터 스토어에 대한 쿼리 부하가 증가하여 시스템 지연을 유발할 수 있습니다.\n- veto_if:\n    - Phase 1A 구현 시 네이버 뉴스 크롤링이 24시간 이내 3회 이상 IP 차단 또는 서비스 중단으로 이어져 데이터 수집 파이프라인의 안정성이 심각하게 훼손될 경우.\n    - 개선된 RAG 시스템이 기존 대비 유의미한 성능 향상(예: 정밀도 10% 이상, 리스크 신호 감지율 5% 이상)을 보이지 않거나, 오히려 오탐(false positive)이 증가하여 자동매매 시스템의 신뢰도를 저하시킬 경우.\n\n## Recommendations\n- immediate_actions:\n    1.  **Phase 1A (뉴스 본문 크롤링) 선행 준비 및 리스크 완화**: Phase 1A는 다른 모든 개선의 기반이므로, 지금부터 본문 크롤링 로직 개발 및 네이버 크롤링 리스크 완화 전략(ThreadPoolExecutor, request_delay, 프록시 활용, 분산 크롤링 등)을 병행하여 준비해야 합니다. `page_content`의 근본적 개선 없이는 다른 개선 효과가 제한적입니다.\n    2.  **Phase 2 (다중 쿼리 검색) 즉시 적용**: 구현 난이도가 낮고 영향도가 높으므로, `_generate_search_queries` 함수를 구현하고 `_search_news_for_stock()` 및 `gather_candidate_stocks()`에 즉시 적용하여 리스크 감지 능력을 강화합니다.\n    3.  **Phase 3 (RAG 후보 발굴 개선) 즉시 적용**: Phase 2와 함께 `created_at_utc` 필터 및 중복 제거 로직을 적용하여 RAG 후보 발굴의 정밀도를 높입니다.\n- experiments:\n    1.  **가설**: 뉴스 본문(또는 요약)을 포함한 `page_content`는 임베딩 검색의 정밀도와 재현율을 유의미하게 향상시킨다.\n        - **방법**:\n            - **A그룹 (대조군)**: 현재 `page_content` (제목만).\n            - **B그룹 (실험군)**: Phase 1A 또는 1B를 통해 본문(또는 요약)이 포함된 `page_content`.\n            - 특정 기간 동안 발생한 실제 시장 이벤트(예: 특정 종목의 실적 발표, 대규모 수주, 악재 뉴스)에 대해 A/B 그룹의 RAG 검색 결과를 비교합니다.\n        - **성공 메트릭**:\n            - **정밀도**: 검색된 상위 k개 문서 중 실제 이벤트와 관련된 문서의 비율.\n            - **재현율**: 실제 이벤트와 관련된 모든 문서 중 검색된 문서의 비율.\n            - **의사결정 관련성**: 검색된 문서가 해당 이벤트에 대한 긍정/부정적 판단을 내리는 데 얼마나 도움이 되는지 전문가 평가 (1-5점 척도).\n    2.  **가설**: 다중 쿼리 검색 전략은 단일 쿼리 대비 다양한 관점의 뉴스를 포착하여 리스크 감지 및 기회 발굴 능력을 향상시킨다.\n        - **방법**:\n            - **A그룹 (대조군)**: 기존 단일 쿼리 (`\"{stock_name} 실적 수주 호재\"`).\n            - **B그룹 (실험군)**: Phase 2의 `_generate_search_queries`를 활용한 다중 쿼리.\n            - 동일한 종목 및 기간에 대해 A/B 그룹의 검색 결과를 비교하고, 특히 부정적 뉴스(리스크) 감지율을 분석합니다.\n        - **성공 메트릭**:\n            - **검색 결과의 다양성**: 검색된 문서들의 토픽 분포 (예: 실적, 수주, 리스크 등).\n            - **리스크 뉴스 감지율**: 실제 발생한 부정적 뉴스 중 검색된 비율.\n            - **오탐율**: 관련 없는 뉴스가 검색되는 비율.\n    3.  **가설**: Phase 3의 RAG 후보 발굴 개선 방안은 후보 종목의 정밀도와 다양성을 높인다.\n        - **방법**:\n            - **A그룹 (대조군)**: 기존 `similarity_search(query=\"실적 호재 계약 수주\", k=50)`.\n            - **B그룹 (실험군)**: Phase 3의 다중 쿼리 + 날짜 필터 + 중복 제거 로직.\n            - A/B 그룹에서 발굴된 상위 50개 후보 종목 리스트를 비교합니다.\n        - **성공 메트릭**:\n            - **후보 종목의 고유성**: 발굴된 50개 종목 중 중복되지 않는 실제 종목 수.\n            - **정밀도**: 발굴된 후보 종목 중 실제 RAG 분석에 유의미한 종목의 비율 (전문가 평가).\n            - **다양성**: 발굴된 후보 종목들의 섹터 분포 또는 시가총액 분포.\n- if_code_change_needed:\n    - `shared/crawlers/naver.py`, `collector.py`: `page_content` 필드에 뉴스 본문(또는 요약)을 포함하도록 크롤링 및 저장 로직 수정.\n    - `scout.py`: `_search_news_for_stock()` 및 `gather_candidate_stocks()` 함수 내 검색 쿼리 생성 및 실행 로직을 다중 쿼리 전략으로 변경하고, `created_at_utc` 필터 및 결과 병합/중복 제거 로직 추가.\n    - 기존 뉴스 데이터에 대한 마이그레이션 스크립트 필요 (Phase 1A 적용 시).\n\n## Questions to the User\n- Phase 1A (뉴스 본문 크롤링)의 네이버 rate limit/IP 차단 리스크에 대해 현재 시스템에서 사용 중인 프록시 서버, IP 로테이션, 분산 크롤링 등의 완화 전략이 있다면 구체적으로 설명해주세요.\n- `kure-v1` 모델 외에 한국어 뉴스 검색에 특화된 다른 임베딩 모델(예: KLUE-RoBERTa, KorBERT 등)에 대한 사전 검토나 벤치마크 계획이 있는지 궁금합니다.\n- Phase 1A 적용 시 기존에 제목만으로 저장된 수백만 건의 뉴스 데이터에 대한 본문 재크롤링 및 업데이트 계획(마이그레이션 전략)이 수립되어 있습니까?",
  "error": "JSON Parse Failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
  "raw_json_snippet": "{stock_name}"
}
```
### Minji
```json
{
  "text": "# Council Output: RAG 검색 품질 개선 계획 리뷰\n\n## Verdict\n- **decision**: approve_with_changes\n- **confidence**: 85\n- **scope**: \n  - ✅ **IN**: Phase 2 (다중 쿼리), Phase 3 (RAG 후보 개선), Phase 1C (메타데이터 강화) → 즉시 구현\n  - ✅ **IN**: Phase 1A (본문 크롤링) → 조건부 승인 (리스크 완화 후 파일럿)\n  - ❌ **OUT**: Phase 1B (LLM 요약) → 비용/지연 대비 효과 불명확, 보류\n  - ❌ **OUT**: 임베딩 모델 변경 → 현재 데이터 부족, 별도 검증 필요\n\n---\n\n## Key Findings\n\n### 1. **page_content의 근본적 한계 → 즉시 해결 필요**\n현재 제목만으로 구성된 `page_content`는 시맨틱 검색의 핵심 약점입니다.\n- **임베딩 벡터**: 1줄 제목 텍스트만 반영 → 맥락 정보 부족\n- **검색 품질**: \"삼성전자 2분기 실적\" 제목만으로는 긍정/부정 판단 불가\n- **RAG 신뢰도**: 의사결정 근거가 불충분 → 자동매매 시스템의 리스크\n\n**Jennie의 지적 동의**: 이는 \"모든 RAG 개선의 선행 조건\"입니다.\n\n---\n\n### 2. **단일 쿼리의 리스크 노출 → 즉시 개선 가능**\n```python\n# 현재: 모든 종목에 동일 쿼리\nquery = f\"{stock_name} 실적 수주 호재\"  # 긍정 신호만 추구\n```\n\n**문제점**:\n- 부정적 뉴스(리스크) 완전 누락 → 손실 방어 실패\n- 섹터별 특성 무시 (반도체 ≠ 바이오 ≠ 금융)\n- 시장 국면 변화 대응 불가\n\n**개선 효과**: Phase 2 다중 쿼리로 리스크 감지율 ↑ (정량화 필요)\n\n---\n\n### 3. **RAG 후보 발굴의 비효율성 → 쉽게 개선 가능**\n```python\n# 현재: k=50 대량 검색 → 중복/잡음 많음\nrag_results = vectorstore.similarity_search(query=\"실적 호재 계약 수주\", k=50)\n```\n\n**문제점**:\n- `created_at_utc` 필터 없음 → 오래된 뉴스 혼입\n- `stock_code` 필터 없음 → 무관한 종목 포함\n- 중복 제거 로직 부재 → 실질적 다양성 낮음\n\n**개선 효과**: Phase 3으로 정밀도 ↑, 쿼리 부하 ↓\n\n---\n\n### 4. **Phase 1A의 높은 잠재력 vs. 운영 리스크**\n\n| 측면 | 평가 |\n|------|------|\n| **검색 품질 개선** | ⭐⭐⭐⭐⭐ (가장 큼) |\n| **구현 난이도** | ⭐⭐⭐ (중간) |\n| **운영 리스크** | ⭐⭐⭐⭐ (높음) |\n| **데이터 마이그레이션** | ⭐⭐⭐⭐ (비용 큼) |\n\n**Jennie의 경고 동의**: \"네이버 rate limit 및 IP 차단 리스크가 가장 큼\"\n\n---\n\n## Evidence\n\n### References\n- **현재 코드 문제**:\n  - `shared/crawlers/naver.py:177`: `\"page_content\": f\"뉴스 제목: {title}\\n링크: {href}\"`\n  - `scout.py:326`: `query=f\"{stock_name} 실적 수주 호재\"` (하드코딩)\n  - `scout.py:547`: `query=\"실적 호재 계약 수주\"` (필터 없음)\n\n- **계획서 근거**:\n  - 섹션 1.1~1.3: 문제점 분석 명확\n  - 섹션 2: 개선 방안 3가지 제시 (A/B/C)\n  - 섹션 3: 우선순위 표 (영향도/난이도/시간)\n\n### Missing Data (의사결정에 필요한 정보)\n\n| 항목 | 필요성 | 영향도 |\n|------|--------|--------|\n| **현재 RAG 성능 메트릭** (Precision/Recall/F1) | 🔴 높음 | 각 개선안의 예상 효과 정량화 |\n| **네이버 크롤링 실제 Rate Limit 경험** | 🔴 높음 | Phase 1A 리스크 정량화 |\n| **LLM 요약 비용/지연 추정치** | 🟡 중간 | Phase 1B 타당성 평가 |\n| **kure-v1 벤치마크 결과** | 🟡 중간 | 임베딩 모델 적합성 판단 |\n| **기존 뉴스 데이터 규모** (건수, 기간) | 🟡 중간 | 마이그레이션 비용 추정 |\n\n---\n\n## Risks & Veto Triggers\n\n### 🔴 Critical Risks\n\n#### 1. **네이버 크롤링 Rate Limit / IP 차단** (Phase 1A)\n```\n현재: 200종목 × 2페이지 × 10뉴스 = 4,000 요청/수집 주기\nPhase 1A: 8,000 요청 (2배) → 차단 확률 ↑\n```\n\n**완화 전략** (필수):\n- ✅ ThreadPoolExecutor + request_delay (1~3초)\n- ✅ 프록시 로테이션 (또는 분산 크롤링)\n- ✅ User-Agent 변경\n- ✅ 요청 분산 (시간대별, IP별)\n- ✅ 모니터링: 차단 감지 시 자동 중단\n\n**Veto 조건**:\n```\nIF 24시간 내 IP 차단 3회 이상 발생\n   OR 데이터 수집 파이프라인 중단 > 1시간\nTHEN Phase 1A 즉시 롤백\n```\n\n---\n\n#### 2. **데이터 신선도 저하** (Phase 1A)\n```\n현재: 뉴스 수집 → 즉시 저장 (지연 ~1분)\nPhase 1A: 뉴스 수집 → 본문 크롤링 → 저장 (지연 ~5~10분)\n```\n\n**영향**: 실시간 시장 대응 능력 저하 (자동매매 시스템에 치명적)\n\n**완화 전략**:\n- ✅ 제목만 먼저 저장 → 비동기로 본문 크롤링 (큐 기반)\n- ✅ 본문 크롤링 실패 시 제목만으로 검색 가능하도록 fallback 로직\n\n---\n\n#### 3. **기존 데이터 마이그레이션 비용** (Phase 1A)\n```\n기존 뉴스 데이터: 수백만 건 (추정)\n재크롤링 필요: 모든 기존 뉴스의 본문 추출\n비용: 시간 + 네이버 크롤링 리스크 재발생\n```\n\n**완화 전략**:\n- ✅ 마이그레이션 스크립트 사전 개발 및 테스트\n- ✅ 배치 처리 (야간, 저트래픽 시간대)\n- ✅ 점진적 마이그레이션 (최근 1개월 → 3개월 → 전체)\n\n---\n\n#### 4. **다중 쿼리의 벡터 스토어 부하** (Phase 2/3)\n```\n현재: 종목당 1회 쿼리\nPhase 2: 종목당 4~5회 쿼리 (섹터별 추가)\n부하: 4~5배 증가\n```\n\n**완화 전략**:\n- ✅ 쿼리 결과 캐싱 (Redis)\n- ✅ 배치 쿼리 최적화 (벡터 스토어 인덱싱)\n- ✅ 모니터링: 응답 시간 > 5초 시 알림\n\n---\n\n### 🟡 Medium Risks\n\n#### 5. **Phase 1A 구현 복잡도**\n- Naver 뉴스 본문 HTML 구조 다양 (네이버 뉴스 vs 언론사 직접 링크)\n- 파싱 실패율 증가 가능성\n- **완화**: 구조별 파서 분리, 실패 로깅, 폴백 로직\n\n#### 6. **오탐(False Positive) 증가**\n- 다중 쿼리로 관련 없는 뉴스도 증가 가능\n- **완화**: 검색 결과 필터링 강화 (유사도 임계값 조정)\n\n---\n\n### Veto Triggers (최종 판단 기준)\n\n```\n❌ VETO IF:\n  1. Phase 1A 파일럿 후 IP 차단 3회 이상 발생 (24시간 내)\n  2. 개선된 RAG 시스템의 정밀도 향상 < 5% (기존 대비)\n  3. 리스크 신호 감지율 개선 < 3% (기존 대비)\n  4. 자동매매 시스템의 오탐율 증가 > 10% (기존 대비)\n  5. 뉴스 데이터 신선도 저하로 실시간 대응 능력 저하 감지\n```\n\n---\n\n## Recommendations\n\n### 🎯 Immediate Actions (우선순위 순)\n\n#### **Action 1: Phase 2 (다중 쿼리) 즉시 구현** ⏱️ 30분\n**이유**: 난이도 낮음, 영향도 높음, 리스크 최소\n\n**구현 체크리스트**:\n\n```python\n# 파일: scout.py (또는 새 파일: search_strategies.py)\n\ndef _generate_search_queries(\n    stock_name: str, \n    stock_code: str, \n    sector: str = None\n) -> list[str]:\n    \"\"\"\n    종목별 다중 검색 쿼리 생성\n    \n    Args:\n        stock_name: 종목명 (예: \"삼성전자\")\n        stock_code: 종목코드 (예: \"005930\")\n        sector: 섹터 (예: \"반도체\", \"바이오\", \"금융\")\n    \n    Returns:\n        검색 쿼리 리스트\n    \"\"\"\n    # 기본 쿼리 (모든 종목)\n    base_queries = [\n        f\"{stock_name} 실적 매출 영업이익 순이익\",\n        f\"{stock_name} 신규 수주 계약 사업 수주\",\n        f\"{stock_name} 리스크 하락 우려 소송 손실\",\n    ]\n    \n    # 섹터별 추가 쿼리\n    sector_queries = {\n        \"반도체\": f\"{stock_name} 반도체 AI HBM 수요 공급\",\n        \"바이오\": f\"{stock_name} 임상 FDA 신약 승인 치료제\",\n        \"2차전지\": f\"{stock_name} 배터리 전기차 수주 공급\",\n        \"금융\": f\"{stock_name} 실적 배당 이자수익 대출\",\n        \"자동차\": f\"{stock_name} 전기차 수소 자율주행\",\n    }\n    \n    queries = base_queries.copy()\n    if sector and sector in sector_queries:\n        queries.append(sector_queries[sector])\n    \n    return queries\n\n\ndef _search_news_for_stock(\n    stock_name: str,\n    stock_code: str,\n    sector: str = None,\n    k: int = 10,\n    recency_days: int = 30\n) -> list[dict]:\n    \"\"\"\n    종목별 뉴스 검색 (다중 쿼리)\n    \n    Returns:\n        중복 제거된 검색 결과 리스트\n    \"\"\"\n    from datetime import datetime, timedelta\n    \n    recency_timestamp = (\n        datetime.utcnow() - timedelta(days=recency_days)\n    ).timestamp()\n    \n    # 다중 쿼리 생성\n    queries = _generate_search_queries(stock_name, stock_code, sector)\n    \n    # 결과 병합 (중복 제거)\n    seen_doc_ids = set()\n    merged_results = []\n    \n    for query in queries:\n        results = vectorstore.similarity_search(\n            query=query,\n            k=k,\n            filter={\n                \"$and\": [\n                    {\"stock_code\": stock_code},\n                    {\"created_at_utc\": {\"$gte\": recency_timestamp}}\n                ]\n            }\n        )\n        \n        for doc in results:\n            doc_id = doc.metadata.get('id') or hash(doc.page_content)\n            if doc_id not in seen_doc_ids:\n                seen_doc_ids.add(doc_id)\n                merged_results.append(doc)\n    \n    return merged_results[:k]  # 상위 k개 반환\n```\n\n**테스트 방법**:\n```bash\n# Unit test\npytest tests/test_search_strategies.py::test_generate_search_queries\npytest tests/test_search_strategies.py::test_search_news_",
  "error": "JSON Parse Failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
  "raw_json_snippet": "{stock_name} 실적 수주 호재\"  # 긍정 신호만 추구\n```\n\n**문제점**:\n- 부정적 뉴스(리스크) 완전 누락 → 손실 방어 실패\n- 섹터별 특성 무시 (반도체 ≠ 바이오 ≠ 금융)\n- 시장 국면 변화 대응 불가\n\n**개선 효과**: Phase 2 다중 쿼리로 리스크 감지율 ↑ (정량화 필요)\n\n---\n\n### 3. **RAG 후보 발굴의 비"
}
```
### Junho
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 90\n- scope: \n  - ✅ **IN**: Phase 1A (뉴스 본문 크롤링) → 조건부 승인 (리스크 완화 후 파일럿)\n  - ✅ **IN**: Phase 1C (메타데이터 강화) → 즉시 구현\n  - ✅ **IN**: Phase 2 (다중 쿼리) → 즉시 구현\n  - ✅ **IN**: Phase 3 (RAG 후보 개선) → 즉시 구현\n  - ❌ **OUT**: Phase 1B (LLM 요약) → 비용/지연 대비 효과 불명확, 보류\n  - ❌ **OUT**: 임베딩 모델 변경 → 현재 데이터 부족, 별도 검증 필요\n\n## Key Findings\n1. **page_content의 근본적 한계**: 현재 뉴스 제목만으로 구성된 `page_content`는 시맨틱 검색의 핵심 약점입니다. 임베딩 벡터가 제목 텍스트만 반영하여 맥락 정보 부족으로 이어지며, 이는 RAG 시스템의 신뢰도를 저하시킵니다.\n2. **단일 쿼리의 리스크 노출**: 하드코딩된 단일 쿼리는 부정적 뉴스(리스크)를 완전히 누락시켜 손실 방어 실패로 이어질 수 있습니다. 시장 국면 변화에 대한 대응이 불가능합니다.\n3. **RAG 후보 발굴의 비효율성**: 현재의 후보 발굴 방식은 중복 및 잡음이 많아 실질적 다양성을 저하시킵니다. 개선 방안을 통해 정밀도를 높일 수 있습니다.\n4. **Phase 1A의 높은 잠재력 vs. 운영 리스크**: 뉴스 본문 크롤링은 검색 품질을 크게 개선할 수 있지만, 네이버의 rate limit 및 IP 차단 리스크가 큽니다. 이에 대한 완화 전략이 필요합니다.\n\n## Evidence\n- references:\n  - `shared/crawlers/naver.py:177`: `page_content` 구성\n  - `scout.py:326`: 하드코딩된 단일 검색 쿼리\n  - `rag_improvement_plan.md` 섹션 1.1, 1.2, 1.3: 현재 문제점 분석\n  - `rag_improvement_plan.md` 섹션 2: 개선 방안\n  - `rag_improvement_plan.md` 섹션 3: 구현 우선순위\n- missing_data:\n  - **현재 RAG 시스템의 정량적 성능 지표**: Precision, Recall, F1-score 등의 메트릭이 필요합니다.\n  - **네이버 크롤링 실제 Rate Limit 및 차단 경험 데이터**: Phase 1A의 리스크를 정량화하는 데 필요합니다.\n  - **LLM 요약 비용 및 지연 시간 추정치**: Phase 1B의 타당성을 평가하는 데 필요합니다.\n  - **kure-v1 모델의 한국어 뉴스 데이터에 대한 벤치마크 결과**: 현재 임베딩 모델의 적합성을 판단하기 위한 데이터가 필요합니다.\n\n## Risks & Veto Triggers\n- risks:\n  - **네이버 크롤링 Rate Limit/IP 차단**: Phase 1A 구현 시 발생할 수 있는 가장 큰 운영 리스크입니다.\n  - **데이터 신선도 저하**: 본문 크롤링으로 인한 수집 시간 증가는 뉴스 데이터의 신선도를 떨어뜨릴 수 있습니다.\n  - **기존 데이터 마이그레이션 비용**: 수백만 건의 기존 뉴스 데이터에 대한 재크롤링 필요로 인한 비용이 발생할 수 있습니다.\n  - **다중 쿼리의 벡터 스토어 부하**: Phase 2, 3에서 다중 쿼리 사용 시 쿼리 부하가 증가할 수 있습니다.\n- veto_if:\n  - Phase 1A 구현 시 네이버 뉴스 크롤링이 24시간 이내 3회 이상 IP 차단 또는 서비스 중단으로 이어질 경우.\n  - 개선된 RAG 시스템이 기존 대비 유의미한 성능 향상(예: 정밀도 10% 이상)을 보이지 않거나, 오히려 오탐이 증가하여 자동매매 시스템의 신뢰도를 저하시킬 경우.\n\n## Recommendations\n- immediate_actions:\n  1. **Phase 1A (뉴스 본문 크롤링) 선행 준비 및 리스크 완화**: 본문 크롤링 로직 개발 및 네이버 크롤링 리스크 완화 전략을 병행하여 준비합니다.\n  2. **Phase 2 (다중 쿼리 검색) 즉시 적용**: 다중 쿼리 검색 전략을 즉시 구현하여 리스크 감지 능력을 강화합니다.\n  3. **Phase 3 (RAG 후보 발굴 개선) 즉시 적용**: 중복 제거 로직을 적용하여 RAG 후보 발굴의 정밀도를 높입니다.\n- experiments:\n  1. **가설**: 뉴스 본문(또는 요약)을 포함한 `page_content`는 임베딩 검색의 정밀도와 재현율을 유의미하게 향상시킨다.\n  2. **가설**: 다중 쿼리 검색 전략은 단일 쿼리 대비 다양한 관점의 뉴스를 포착하여 리스크 감지 및 기회 발굴 능력을 향상시킨다.\n  3. **가설**: Phase 3의 RAG 후보 발굴 개선 방안은 후보 종목의 정밀도와 다양성을 높인다.\n- if_code_change_needed:\n  - `shared/crawlers/naver.py`, `collector.py`: `page_content` 필드에 뉴스 본문(또는 요약)을 포함하도록 크롤링 및 저장 로직 수정.\n  - `scout.py`: 다중 쿼리 전략으로 변경하고, `created_at_utc` 필터 및 결과 병합/중복 제거 로직 추가.\n\n## Questions to the User\n- Phase 1A (뉴스 본문 크롤링)의 네이버 rate limit/IP 차단 리스크에 대해 현재 시스템에서 사용 중인 프록시 서버, IP 로테이션, 분산 크롤링 등의 완화 전략이 있다면 구체적으로 설명해주세요.\n- `kure-v1` 모델 외에 한국어 뉴스 검색에 특화된 다른 임베딩 모델에 대한 사전 검토나 벤치마크 계획이 있는지 궁금합니다.\n- Phase 1A 적용 시 기존에 제목만으로 저장된 수백만 건의 뉴스 데이터에 대한 본문 재크롤링 및 업데이트 계획(마이그레이션 전략)이 수립되어 있습니까?",
  "decision": "neutral",
  "raw_output": true
}
```

</details>

---
## Cost Summary
| Model | Input | Output | Cost (USD) |
|-------|-------|--------|------------|
| Jennie (Gemini) | 2,003 | 1,662 | $0.0006 |
| Minji (Claude) | 3,744 | 2,069 | $0.2113 |
| Junho (OpenAI) | 0 | 0 | $0.0000 |
| Orchestrator (OpenAI) | 5,257 | 559 | $0.0011 |
| **Total** | - | - | **$0.2131** (≈309원) |
