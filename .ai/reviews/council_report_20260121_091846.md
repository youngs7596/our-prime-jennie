# Prime Council Report
- Date: 2026-01-21 09:20:31
- Query: 현재 상황: 뉴스 크롤러가 '뉴스 수집'과 'LLM 분석(감성점수)'을 동시에 수행하다보니, 분석 시간이 너무 오래 걸려 타임아웃이 발생하고 수집된 뉴스조차 DB에 저장되지 못하는 문제가 발생했습니다. (Batch Size 2000개 시 100분 소요 vs 스케줄 10분).

임시 조치:
1. 수집 직후 ChromaDB(본문 검색용)에 먼저 저장하여 데이터 유실 방지.
2. 분석은 '최신순 정렬' 후 상위 40개만 수행하도록 제한 (Micro-batching).

제안된 아키텍처 (Refactoring):
Monolithic Crawler를 3개의 마이크로서비스로 분리하고 Redis Streams(Pub/Sub) 도입.
1. Collector: 무한 루프로 수집 -> Redis Stream에 Push (매우 빠름).
2. Archiver: Stream Consume -> ChromaDB 저장 (빠름).
3. Analyzer: Stream Consume -> LLM 분석 -> MariaDB 저장 (느려도 됨, 비동기).

질문:
이 아키텍처 변화가 개인 트레이딩 봇 규모에서 적절한가요? 오버엔지니어링일까요? 
Redis Streams 도입 시 주의할 점이나, 더 나은 대안(예: 단순 DB 테이블을 큐로 사용)이 있을까요?
- Target: services/news-crawler/crawler.py

# Final Plan

## 1) 승인된 범위 (Approved scope)
- 뉴스 크롤러 아키텍처 분리 및 Redis Streams 도입 (단, 단계적 롤아웃 및 운영 오버헤드 최소화 조건)

## 2) 실행 순서가 있는 액션 스텝 (Action Steps)
1. **Collector 및 Archiver 우선 분리**: 뉴스 수집 로직을 `Collector` 서비스로, ChromaDB 저장 로직을 `Archiver` 서비스로 분리하여 먼저 배포합니다.
2. **Redis Streams 인프라 구축**: Redis Streams 인스턴스를 설정하고, Collector가 수집한 뉴스를 Stream에 발행하고 Archiver가 Stream에서 소비할 수 있도록 기본 연동을 구현합니다.
3. **Analyzer 서비스 개발 및 배포**: LLM 분석 로직을 `Analyzer` 서비스로 분리하고, Redis Streams에서 뉴스를 소비하여 분석 후 MariaDB에 저장하도록 구현합니다.
4. **Phase 1 검증**: Collector와 Archiver의 로그를 통해 수집된 뉴스 수와 저장된 뉴스 수를 비교하고, 지연 시간을 모니터링하여 1분 이내로 유지되는지 확인합니다.
5. **Phase 2 배포**: Analyzer 서비스를 추가하여 모든 뉴스에 대한 LLM 분석을 비동기적으로 수행하도록 구현합니다.
6. **성능 모니터링**: Redis Streams의 백로그와 Analyzer 서비스의 처리 속도를 지속적으로 모니터링합니다.
7. **리스크 관리**: 운영 오버헤드 및 분석 백로그 발생 가능성을 주기적으로 검토하고, 필요 시 조치를 취합니다.

## 3) 실험 (Experiments) 및 수용 기준 (Acceptance criteria)
- **실험 1**: Collector-Archiver 분리 및 Redis Streams 도입이 데이터 유실을 방지하고 원본 뉴스 데이터의 신선도를 개선할 것이라는 가설을 검증합니다.
  - **수용 기준**: 수집된 뉴스 대비 ChromaDB 저장 뉴스 비율 100% 달성, 수집부터 저장까지의 평균 지연 시간 1분 이내 유지.
  
- **실험 2**: Redis Streams와 Analyzer 서비스의 조합이 모든 수집 뉴스에 대한 LLM 분석을 비동기적으로 수행할 것이라는 가설을 검증합니다.
  - **수용 기준**: Redis Streams의 백로그가 특정 임계치(예: 1000개)를 넘지 않고 안정적으로 유지되며, 분석된 데이터의 평균 신선도가 1시간 이내로 유지됨.

## 4) 리스크 및 롤백 트리거 (Risk & rollback triggers)
- **리스크**:
  - 운영 복잡성 증가: 마이크로서비스 아키텍처 도입으로 인해 시스템 운영의 복잡도가 증가할 수 있습니다.
  - 분석 백로그 발생 가능성: Analyzer 서비스의 처리 속도가 Redis Streams에 쌓이는 뉴스 데이터의 속도를 따라가지 못할 경우, 분석 대기열이 지속적으로 증가할 수 있습니다.

- **롤백 트리거**:
  - 운영 오버헤드가 트레이딩 이점을 상회할 경우: 시스템 관리 및 유지보수에 드는 시간과 노력이 개선된 뉴스 분석을 통한 트레이딩 수익 증대 효과를 지속적으로 상회할 경우.
  - Analyzer 백로그가 3일 이상 지속적으로 해소되지 않을 경우: LLM 모델 최적화 또는 Analyzer 하드웨어 업그레이드 필요.

## Notes
- 제니와 민지의 의견은 준호의 결정을 우선하되, 각자의 이견은 보존하였습니다.

---
## Appendix: Raw JSON Outputs
<details><summary>Click to expand</summary>

### Jennie
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 85\n- scope: 뉴스 수집 및 분석 파이프라인 아키텍처 전반\n\n## Key Findings (<=5)\n1.  **치명적인 병목 현상:** 현재 모놀리식 구조에서 LLM 기반 뉴스 분석(감성 점수, 리스크 탐지)이 수집 및 저장 프로세스를 심각하게 지연시켜, 스케줄 타임아웃 및 **수집된 뉴스 데이터의 유실**이라는 결정적인 문제를 야기하고 있습니다. 이는 트레이딩 봇의 핵심적인 정보원 손실을 의미합니다.\n2.  **전략적 사각지대:** 임시 조치로 '최신순 상위 40개' 뉴스만 분석하는 것은 전체 수집 뉴스 중 극히 일부만을 다루게 되어, 대부분의 뉴스에 대한 감성 및 리스크 분석이 누락됩니다. 이는 **잠재적인 매매 기회(Best) 또는 위험 회피(Worst/Veto)를 놓칠 수 있는 중대한 전략적 사각지대**를 만듭니다.\n3.  **데이터 신선도 저하:** 분석 단계의 지연은 트레이딩 결정에 필요한 분석 데이터의 신선도를 떨어뜨려, 이미 시장에 반영된 정보를 기반으로 판단하게 만들 위험이 있습니다.\n4.  **아키텍처 분리 필요성:** 제안된 마이크로서비스 아키텍처(Collector, Archiver, Analyzer)는 느린 LLM 분석 작업을 빠른 수집 및 저장 작업으로부터 효과적으로 분리하여, 데이터 유실 방지 및 시스템 안정성 확보에 필수적입니다.\n5.  **Redis Streams의 적합성:** Redis Streams는 메시지 영속성, 컨슈머 그룹을 통한 작업 분배, 그리고 높은 처리량을 제공하여, 뉴스 데이터와 같이 연속적이고 대량의 스트림 데이터를 안정적으로 처리하고 여러 컨슈머(특히 Analyzer)가 비동기적으로 작업을 수행하기에 적합한 솔루션입니다. 단순 DB 테이블을 큐로 사용하는 것보다 훨씬 견고하고 확장성이 뛰어납니다.\n\n## Evidence\n- references:\n    - File: `services/news-crawler/crawler.py`\n    - Config Key: `MAX_SENTIMENT_DOCS_PER_RUN`\n    - Function: `process_unified_analysis`\n    - Log Snippet: `logger.warning(f\"⚠️ [Unified] 분석 대상({len(stock_docs)}개)이 제한({MAX_SENTIMENT_DOCS_PER_RUN}개)을 초과했습니다.\")`\n    - User Statement: \"Batch Size 2000개 시 100분 소요 vs 스케줄 10분\"\n    - User Statement: \"수집된 뉴스조차 DB에 저장되지 못하는 문제가 발생했습니다.\"\n    - Current Fix: `add_documents_to_chroma(new_documents_to_add)` (분석 전 ChromaDB 저장)\n- missing_data:\n    - **LLM 분석 처리량 메트릭:** Analyzer 서비스가 시간당 처리할 수 있는 문서 수 (예: `docs_processed_per_hour`) 및 평균 문서당 분석 시간 (`avg_analysis_latency_ms`)이 필요합니다. 이는 Redis Streams의 백로그 관리 및 Analyzer 서비스의 스케일링 전략 수립에 결정적인 영향을 미칩니다.\n    - **뉴스 수집량 메트릭:** 시간당 수집되는 평균 뉴스 문서 수 (`avg_news_collected_per_hour`)가 필요합니다. 이는 Redis Streams의 `MAXLEN` 설정 및 Archiver/Analyzer의 부하 예측에 중요합니다.\n\n## Risks & Veto Triggers\n- risks:\n    - **운영 복잡성 증가:** 마이크로서비스 아키텍처와 Redis Streams 도입은 배포, 모니터링, 디버깅 등 시스템 운영의 복잡도를 증가시킵니다. 개인 트레이딩 봇 규모에서 이러한 오버헤드가 과도하게 느껴질 수 있습니다.\n    - **분석 백로그 발생 가능성:** Analyzer 서비스의 처리 속도가 Redis Streams에 쌓이는 뉴스 데이터의 속도를 따라가지 못할 경우, 분석 대기열이 지속적으로 증가하여 분석 데이터의 신선도가 저하될 수 있습니다.\n    - **비용 증가:** Redis 인스턴스 및 추가적인 컴퓨팅 자원(각 서비스별)으로 인해 인프라 비용이 증가할 수 있습니다.\n- veto_if:\n    - **운영 오버헤드가 트레이딩 이점을 상회할 경우:** 시스템 관리 및 유지보수에 드는 시간과 노력이, 개선된 뉴스 분석을 통한 트레이딩 수익 증대 효과를 지속적으로 상회할 경우.\n    - **Analyzer 서비스의 백로그가 지속적으로 해소되지 않을 경우:** Analyzer 서비스가 Redis Streams의 메시지를 제때 처리하지 못하여, 분석 데이터의 신선도가 24시간 이상 지연되는 상황이 3일 이상 지속될 경우.\n\n## Recommendations\n- immediate_actions:\n    1.  **Collector 및 Archiver 우선 분리:** `crawler.py`에서 뉴스 수집 로직(KOSPI 200 Universe 로드, Naver/Google News 크롤링, 일반 경제 뉴스 크롤링)을 `Collector` 서비스로, ChromaDB 저장 로직(`add_documents_to_chroma`)을 `Archiver` 서비스로 분리하여 먼저 배포합니다. 이를 통해 모든 수집 뉴스가 ChromaDB에 안정적으로 저장되도록 보장합니다.\n    2.  **Redis Streams 인프라 구축:** Redis Streams 인스턴스를 설정하고, Collector가 수집한 뉴스를 Stream에 발행(Publish)하고 Archiver 및 Analyzer가 Stream에서 소비(Consume)할 수 있도록 기본 연동을 구현합니다.\n    3.  **Analyzer 서비스 개발 및 배포:** `process_unified_analysis` 로직을 `Analyzer` 서비스로 분리하고, Redis Streams에서 뉴스를 소비하여 LLM 분석 후 MariaDB에 저장하도록 구현합니다. 이때 `MAX_SENTIMENT_DOCS_PER_RUN` 제한을 제거하고 모든 뉴스를 분석 대상으로 삼도록 변경합니다.\n- experiments:\n    1.  **Hypothesis:** Collector-Archiver 분리 및 Redis Streams 도입은 뉴스 수집 및 ChromaDB 저장 과정에서의 데이터 유실을 완전히 방지하고, 원본 뉴스 데이터의 신선도를 획기적으로 개선할 것이다.\n        *   **Method:** 분리된 Collector 및 Archiver 서비스를 배포하고, Collector의 로그에서 수집된 총 뉴스 수와 Archiver의 로그 및 ChromaDB에서 확인되는 저장된 뉴스 수를 비교합니다. 또한, 수집 시점과 ChromaDB 저장 시점 간의 지연 시간을 모니터링합니다.\n        *   **Success Metrics:** 수집된 뉴스 대비 ChromaDB 저장 뉴스 비율 100% 달성. 수집부터 ChromaDB 저장까지의 평균 지연 시간 1분 이내 유지.\n    2.  **Hypothesis:** Redis Streams와 Analyzer 서비스의 조합은 모든 수집 뉴스에 대한 LLM 분석을 비동기적으로 수행하며, Analyzer 서비스의 처리량에 따라 유연하게 확장될 수 있다.\n        *   **Method:** Analyzer 서비스를 배포하고 Redis Streams의 백로그(Stream Length)와 Analyzer의 메시지 처리 속도를 모니터링합니다. Analyzer 인스턴스 수를 조절하며 백로그 변화를 관찰합니다.\n        *   **Success Metrics:** Redis Streams의 백로그가 특정 임계치(예: 1000개)를 넘지 않고 안정적으로 유지됨. Analyzer 서비스가 모든 뉴스를 분석하여 MariaDB에 저장하며, 분석된 데이터의 평균 신선도(수집 시점부터 분석 완료 시점까지)가 1시간 이내로 유지됨.\n- if_code_change_needed:\n    - `services/news-crawler/crawler.py`를 `collector.py`, `archiver.py`, `analyzer.py` 세 개의 독립적인 스크립트/서비스로 분리합니다.\n    - `collector.py`: 뉴스 수집 로직만 포함하며, 수집된 `Document` 객체를 직렬화하여 Redis Stream에 발행합니다.\n    - `archiver.py`: Redis Stream에서 뉴스를 소비하여 `text_splitter` 및 `embeddings`를 사용하여 ChromaDB에 저장합니다.\n    - `analyzer.py`: Redis Stream에서 뉴스를 소비하여 `jennie_brain.analyze_news_unified`를 호출하고, 결과를 MariaDB 및 Redis에 저장합니다. `MAX_SENTIMENT_DOCS_PER_RUN` 관련 로직을 제거합니다.\n\n## Questions to the User (optional, <=3)\n- 현재 트레이딩 전략에서 뉴스 감성/리스크 분석 결과가 트레이딩 결정에 반영되기까지 허용되는 최대 지연 시간(Latency)은 어느 정도인가요? (예: 10분 이내, 1시간 이내)\n- 현재 스케줄링 주기(10분) 동안 평균적으로 몇 건의 종목 뉴스가 수집되고 있나요? (일반 경제 뉴스 제외) 이는 Analyzer 서비스의 필요한 처리량을 추정하는 데 중요합니다.\n- Redis Streams 도입 시, Redis 인스턴스의 운영 및 모니터링을 위한 전담 인력 또는 자동화된 시스템(예: 클라우드 매니지드 서비스)이 준비되어 있나요?",
  "error": "JSON Parse Failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
  "raw_json_snippet": "{len(stock_docs)}개)이 제한({MAX_SENTIMENT_DOCS_PER_RUN}"
}
```
### Minji
```json
{
  "text": "# Council Output: Minji's Engineering Assessment\n\n---\n\n## Verdict\n- **decision:** approve_with_changes\n- **confidence:** 82\n- **scope:** 뉴스 크롤러 아키텍처 분리 + Redis Streams 도입 (단, 단계적 롤아웃 + 운영 오버헤드 최소화 조건)\n\n---\n\n## Key Findings (<=5)\n\n1. **현재 문제는 실제이며 심각함**\n   - 10분 스케줄 내 100분 분석 작업 = 데이터 유실 + 트레이딩 신호 손실\n   - 임시 조치(상위 40개만 분석)는 **전체 뉴스의 95%+ 분석 누락** → 전략적 사각지대\n   - 이미 ChromaDB 우선 저장으로 부분 완화했으나, 감성/리스크 분석 공백 여전\n\n2. **제안된 아키텍처는 \"오버엔지니어링\"이 아님**\n   - 개인 봇 규모(KOSPI 200, 10분 주기)에서도 **분리의 이점이 명확함**\n   - 수집(빠름) vs 분석(느림)의 근본적 속도 차이를 해결하는 유일한 방법\n   - 단순 DB 큐는 **폴링 오버헤드 + 동시성 문제**로 인해 부적합\n\n3. **Redis Streams는 이 사용 사례에 최적**\n   - 메시지 영속성(재시작 후 복구), 컨슈머 그룹(Analyzer 확장), 높은 처리량\n   - 단순 DB 테이블 큐 대비 **10배 이상 성능 우위**\n   - 개인 봇 규모에서도 관리 가능 (클라우드 매니지드 또는 Docker 컨테이너)\n\n4. **운영 오버헤드는 제한적 (올바른 구현 시)**\n   - 3개 서비스 = 3개 프로세스/컨테이너 관리 (기존 1개 → 3개)\n   - 모니터링 포인트 증가하나, 각 서비스 책임이 명확해져 **디버깅 난이도는 오히려 감소**\n   - Redis 운영: 클라우드 매니지드(GCP Memorystore, AWS ElastiCache) 사용 시 거의 무관\n\n5. **단계적 롤아웃 전략이 핵심**\n   - Phase 1: Collector + Archiver만 먼저 배포 (분석 제거)\n   - Phase 2: Analyzer 추가 (비동기, 독립적)\n   - 각 단계에서 안정성 검증 후 진행 → 리스크 최소화\n\n---\n\n## Evidence\n\n### References\n- **File:** `services/news-crawler/crawler.py`\n- **Problem Code:**\n  ```python\n  # Line ~1100\n  if len(stock_docs) > MAX_SENTIMENT_DOCS_PER_RUN:\n      logger.warning(f\"⚠️ [Unified] 분석 대상({len(stock_docs)}개)이 제한({MAX_SENTIMENT_DOCS_PER_RUN}개)을 초과했습니다.\")\n      stock_docs = stock_docs[:MAX_SENTIMENT_DOCS_PER_RUN]  # ← 95%+ 뉴스 버림\n  ```\n- **Config:** `MAX_SENTIMENT_DOCS_PER_RUN=40` (기본값)\n- **User Statement:** \"Batch Size 2000개 시 100분 소요 vs 스케줄 10분\"\n- **Current Mitigation:** `add_documents_to_chroma(new_documents_to_add)` (분석 전 저장)\n\n### Missing Data (결정에 영향을 미칠 정보)\n1. **LLM 분석 처리량:**\n   - 현재 `jennie_brain.analyze_news_unified()` 호출 시 **문서당 평균 지연 시간**은?\n   - 배치 크기별 처리 시간 곡선 (5개 vs 40개 vs 200개)\n   - → Analyzer 서비스의 필요 인스턴스 수 추정에 필수\n\n2. **뉴스 수집량 메트릭:**\n   - 10분 주기당 평균 수집 뉴스 수 (종목별 + 일반 경제)\n   - 피크 시간대 수집량 변동성\n   - → Redis Streams `MAXLEN` 설정 및 Analyzer 부하 예측에 필수\n\n3. **트레이딩 신호 반영 시간 요구사항:**\n   - 뉴스 감성/리스크 분석 결과가 트레이딩 결정에 반영되기까지 **허용 지연 시간**은?\n   - 예: 10분 이내 vs 1시간 이내 vs 당일 이내\n   - → Analyzer 처리 우선순위 및 SLA 설정에 영향\n\n---\n\n## Risks & Veto Triggers\n\n### Risks (관리 가능)\n\n| Risk | Severity | Mitigation |\n|------|----------|-----------|\n| **운영 복잡도 증가** | Medium | 각 서비스를 Docker 컨테이너화 + docker-compose로 통합 관리. 모니터링은 Prometheus + Grafana 간단 설정 |\n| **Redis 인스턴스 장애** | Medium | 클라우드 매니지드 서비스(GCP Memorystore) 사용 시 99.9% SLA 보장. 또는 Redis Sentinel 구성 |\n| **Analyzer 백로그 누적** | Medium-High | Analyzer 인스턴스 수를 동적으로 조절. Redis Streams 백로그 모니터링 알림 설정 |\n| **배포 복잡도** | Low | 기존 Cloud Scheduler 작업 3개로 확장 (Collector, Archiver, Analyzer 각각). 또는 Kubernetes Job으로 통합 |\n| **개발 시간 증가** | Low | 기존 코드 분리만으로 충분. 새로운 로직 추가 최소화 |\n\n### Veto Triggers (이 경우 단순 DB 큐 고려)\n\n- ❌ **Redis 운영 불가능한 환경** (예: 클라우드 접근 제한, 온프레미스 전용)\n  - → 대안: 단순 MariaDB 테이블 큐 (아래 비교 참고)\n  \n- ❌ **분석 결과 신선도 요구사항이 24시간 이상**\n  - → 현재 아키텍처(비동기 Analyzer)로도 충분. 복잡도 증가 불필요\n  \n- ❌ **Analyzer 백로그가 3일 이상 지속적으로 해소되지 않음**\n  - → LLM 모델 최적화 또는 Analyzer 하드웨어 업그레이드 필요. 아키텍처 재검토\n\n---\n\n## Recommendations\n\n### Immediate Actions (우선순위 순)\n\n#### 1️⃣ **Phase 1: Collector + Archiver 분리 (분석 제거)**\n**목표:** 모든 수집 뉴스가 ChromaDB에 안정적으로 저장되도록 보장\n\n**구현 범위 (최소):**\n- `collector.py`: 기존 `run_collection_job()` 중 수집 로직만 추출\n  - 뉴스 수집 후 `Document` 객체를 JSON 직렬화하여 **Redis Stream에 발행**\n  - 분석 로직 제거 (`process_unified_analysis` 호출 제거)\n  \n- `archiver.py`: 기존 `add_documents_to_chroma()` 로직 추출\n  - Redis Stream에서 뉴스 메시지 소비\n  - ChromaDB에 저장\n  - 처리 완료 후 Stream ACK\n\n**코드 스켈레톤:**\n```python\n# collector.py\nimport redis\nimport json\nfrom datetime import datetime, timezone\n\nredis_client = redis.Redis(host='localhost', port=6379, decode_responses=False)\nSTREAM_NAME = \"news:raw\"\n\ndef run_collector():\n    \"\"\"뉴스 수집만 수행\"\"\"\n    all_docs = []\n    \n    # 기존 수집 로직 (분석 제거)\n    general_news_docs = crawl_general_news()\n    all_docs.extend(general_news_docs)\n    \n    universe = get_kospi_200_universe()\n    with ThreadPoolExecutor(max_workers=10) as executor:\n        # ... 기존 병렬 크롤링 ...\n        all_docs.extend(fetched_docs)\n    \n    # ✅ Redis Stream에 발행 (분석 제거)\n    for doc in all_docs:\n        msg = {\n            \"page_content\": doc.page_content,\n            \"metadata\": json.dumps(doc.metadata, default=str)\n        }\n        redis_client.xadd(STREAM_NAME, msg)\n        logger.info(f\"✅ Stream에 발행: {doc.metadata.get('source_url')}\")\n    \n    logger.info(f\"✅ Collector 완료: {len(all_docs)}개 뉴스 발행\")\n\nif __name__ == \"__main__\":\n    run_collector()\n```\n\n```python\n# archiver.py\nimport redis\nimport json\nfrom langchain_core.documents import Document\n\nredis_client = redis.Redis(host='localhost', port=6379, decode_responses=False)\nSTREAM_NAME = \"news:raw\"\nCONSUMER_GROUP = \"archiver_group\"\n\ndef run_archiver():\n    \"\"\"Redis Stream에서 뉴스를 소비하여 ChromaDB에 저장\"\"\"\n    \n    # Consumer Group 생성 (첫 실행 시)\n    try:\n        redis_client.xgroup_create(STREAM_NAME, CONSUMER_GROUP, id='0', mkstream=True)\n    except redis.ResponseError:\n        pass  # 이미 존재\n    \n    while True:\n        # Stream에서 메시지 읽기 (블로킹)\n        messages = redis_client.xreadgroup(\n            CONSUMER_GROUP, \n            \"archiver_1\", \n            {STREAM_NAME: '>'}, \n            count=10, \n            block=1000\n        )\n        \n        if not messages:\n            logger.debug(\"Stream에 새 메시지 없음, 대기 중...\")\n            continue\n        \n        for stream_name, msg_list in messages:\n            for msg_id, msg_data in msg_list:\n                try:\n                    # 메시지 역직렬화\n                    doc = Document(\n                        page_content=msg_data[b'page_content'].decode(),\n                        metadata=json.loads(msg_data[b'metadata'].decode())\n                    )\n                    \n                    # ChromaDB 저장\n                    splitted = text_splitter.split_documents([doc])\n                    vectorstore.add_documents(splitted)\n                    \n                    # ACK (처리 완료)\n                    redis_client.xack(STREAM_NAME, CONSUMER_GROUP, msg_id)\n                    logger.info(f\"✅ Archiver: {doc.metadata.get('source_url')} 저장 완료\")\n                    \n                except Exception as e:\n                    logger.error(f\"❌ Archiver 오류: {e}\")\n                    # 실패한 메시지는 재시도 대기 (xreadgroup 자동 처리)\n\nif __name__ == \"__main__\":\n    run_archiver()\n```\n\n**배포:**\n- Cloud Scheduler 작업 수정:\n  - 기존: `python crawler.py` (10분 주기)\n  - 변경: `python collector.py` (10분 주기) + `python archiver.py` (지속 실행)\n\n**검증 (Phase 1 완료 기준):**\n- ✅ Collector 로그: 10분마다 \"X개 뉴스 발행\" 확인\n- ✅ Archiver 로그: \"X개 저장 완료\" 확인\n- ✅ ChromaDB: 수집 뉴스 수 = 저장 뉴스 수 (100% 일치)\n- ✅ 수집부터 저장까지 지연 시간 < 1분\n\n---\n\n#### 2️⃣ **Phase 2: Analyzer 서비스 추가 (비동기 분석)**\n**목표:** 모든 뉴스에 대한 LLM 분석 수행 (시간 제약 없음)\n\n**구현 범위:**\n- `analyzer.py`: 기존 `process_unified_analysis()` 로직 추출\n  - Redis Stream에서 뉴스 소비 (Archiver와 동일한 Stream 또는 별도 Stream)\n  - `jennie_brain.analyze_news_unified()` 호출\n  - 결과를 MariaDB + Redis에 저장\n  - **`MAX_SENTIMENT_DOCS_PER_RUN` 제한 제거** (모든 뉴스 분석)\n\n**코드 스켈레톤:**\n```python\n# analyzer.py\ndef run_analyzer():\n    \"\"\"Redis Stream에서 뉴스를 소비하여 LLM 분석\"\"\"\n    \n    # Consumer Group 생성\n    try:\n        redis_client.xgroup_create(STREAM_NAME, \"analyzer_group\", id='0', mkstream=True)\n    except redis.ResponseError:\n        pass\n    \n    while True:\n        messages = redis_client.xreadgroup(\n            \"analyzer_group\", \n            \"analyzer_1\", \n            {STREAM_NAME: '>'}, \n            count=5,  # 배치 크기 (LLM 처리 시간 고려)\n            block=5000\n        )\n        \n        if not messages:\n            continue\n        \n        batch_items = []\n        msg_ids = []\n        \n        for stream_name, msg_list in messages:\n            for msg_id, msg_data in msg_list:\n                doc = Document(\n                    page_content=msg_data[b'page_content'].decode(),\n                    metadata=json.loads(msg_data[b'metadata'].decode())\n                )\n                \n                # 배치 준비\n                batch_items.append({\n                    \"id\": len(batch_items),\n                    \"title\": doc.page_content.",
  "error": "JSON Parse Failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
  "raw_json_snippet": "{len(stock_docs)}개)이 제한({MAX_SENTIMENT_DOCS_PER_RUN}개)을 초과했습니다.\")\n      stock_docs = stock_docs[:MAX_SENTIMENT_DOCS_PER_RUN]  # ← 95%+ 뉴스 버림\n  ```\n- **Config:** `MAX_SENTIMENT_DOCS_PER_RUN=40` (기본값)\n-"
}
```
### Junho
```json
{
  "text": "## Verdict\n- decision: approve_with_changes\n- confidence: 90\n- scope: 뉴스 크롤러 아키텍처 분리 및 Redis Streams 도입 (단, 단계적 롤아웃 및 운영 오버헤드 최소화 조건)\n\n## Key Findings (<=5)\n1. **현재 문제의 심각성**: 뉴스 수집과 LLM 분석이 동시에 진행되면서 분석 시간이 길어져 데이터 유실과 타임아웃 문제가 발생하고 있습니다. 이는 트레이딩 봇의 핵심 정보 손실로 이어질 수 있습니다.\n2. **아키텍처 분리의 필요성**: 수집과 분석의 속도 차이를 해결하기 위해 마이크로서비스 아키텍처로 분리하는 것이 필요합니다. 이는 데이터 유실 방지와 시스템 안정성을 높이는 데 기여할 것입니다.\n3. **Redis Streams의 적합성**: Redis Streams는 메시지 영속성과 높은 처리량을 제공하여 뉴스 데이터와 같은 연속적이고 대량의 스트림 데이터를 안정적으로 처리하는 데 적합합니다.\n4. **운영 오버헤드 관리 가능성**: 마이크로서비스 아키텍처 도입 시 운영 복잡도가 증가할 수 있으나, 각 서비스의 책임이 명확해져 디버깅 난이도가 오히려 감소할 수 있습니다.\n5. **단계적 롤아웃 전략의 중요성**: Phase 1에서 Collector와 Archiver를 먼저 배포하고, 안정성을 검증한 후 Analyzer를 추가하는 방식으로 리스크를 최소화할 수 있습니다.\n\n## Evidence\n- references:\n    - File: `services/news-crawler/crawler.py`\n    - User Statement: \"Batch Size 2000개 시 100분 소요 vs 스케줄 10분\"\n    - Current Fix: `add_documents_to_chroma(new_documents_to_add)` (분석 전 ChromaDB 저장)\n\n## Risks & Veto Triggers\n- risks:\n    - **운영 복잡성 증가**: 마이크로서비스 아키텍처와 Redis Streams 도입으로 인해 시스템 운영의 복잡도가 증가할 수 있습니다.\n    - **분석 백로그 발생 가능성**: Analyzer 서비스의 처리 속도가 Redis Streams에 쌓이는 뉴스 데이터의 속도를 따라가지 못할 경우, 분석 대기열이 지속적으로 증가할 수 있습니다.\n- veto_if:\n    - **운영 오버헤드가 트레이딩 이점을 상회할 경우**: 시스템 관리 및 유지보수에 드는 시간과 노력이 개선된 뉴스 분석을 통한 트레이딩 수익 증대 효과를 지속적으로 상회할 경우.\n\n## Recommendations\n- immediate_actions:\n    1. **Collector 및 Archiver 우선 분리**: 뉴스 수집 로직을 Collector 서비스로, ChromaDB 저장 로직을 Archiver 서비스로 분리하여 먼저 배포합니다.\n    2. **Redis Streams 인프라 구축**: Redis Streams 인스턴스를 설정하고, Collector가 수집한 뉴스를 Stream에 발행하고 Archiver가 Stream에서 소비할 수 있도록 기본 연동을 구현합니다.\n    3. **Analyzer 서비스 개발 및 배포**: LLM 분석 로직을 Analyzer 서비스로 분리하고, Redis Streams에서 뉴스를 소비하여 분석 후 MariaDB에 저장하도록 구현합니다.\n- experiments:\n    1. **Hypothesis**: Collector-Archiver 분리 및 Redis Streams 도입은 뉴스 수집 및 ChromaDB 저장 과정에서의 데이터 유실을 방지하고, 원본 뉴스 데이터의 신선도를 개선할 것이다.\n    2. **Hypothesis**: Redis Streams와 Analyzer 서비스의 조합은 모든 수집 뉴스에 대한 LLM 분석을 비동기적으로 수행하며, Analyzer 서비스의 처리량에 따라 유연하게 확장될 수 있다.\n\n## Questions to the User (optional, <=3)\n- 현재 트레이딩 전략에서 뉴스 감성/리스크 분석 결과가 트레이딩 결정에 반영되기까지 허용되는 최대 지연 시간(Latency)은 어느 정도인가요?\n- 현재 스케줄링 주기(10분) 동안 평균적으로 몇 건의 종목 뉴스가 수집되고 있나요?\n- Redis Streams 도입 시, Redis 인스턴스의 운영 및 모니터링을 위한 전담 인력 또는 자동화된 시스템이 준비되어 있나요?",
  "error": "No JSON found in response"
}
```

</details>

---
## Cost Summary
| Model | Input | Output | Cost (USD) |
|-------|-------|--------|------------|
| Jennie (Gemini) | 15,273 | 1,610 | $0.0016 |
| Minji (Claude) | 16,967 | 2,677 | $0.4553 |
| Junho (OpenAI) | 0 | 0 | $0.0000 |
| Orchestrator (OpenAI) | 5,560 | 578 | $0.0012 |
| **Total** | - | - | **$0.4581** (≈664원) |
