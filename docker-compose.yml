name: my-prime-jennie

services:
  # ============================================================================
  # 0. Messaging / Supporting Services
  # ============================================================================
  rabbitmq:
    image: rabbitmq:3.13-management
    profiles: [ "infra" ]
    environment:
      - RABBITMQ_DEFAULT_USER=guest
      - RABBITMQ_DEFAULT_PASS=guest
      - RABBIT_SERVER_ADDITIONAL_ERL_ARGS="-+sbwt none -+sbwtdcpu none -+sbwtdio none"
    ports:
      - "5672:5672"
      - "15672:15672"
    restart: always
    healthcheck:
      test: [ "CMD", "rabbitmq-diagnostics", "ping" ]
      interval: 5s
      timeout: 3s
      retries: 10
      start_period: 15s
    networks:
      - msa-network
    labels:
      - app=rabbitmq
      - stack=my-prime-jennie

  # ============================================================================
  # 0. Infrastructure Dependencies (ChromaDB & Redis)
  # ============================================================================
  qdrant:
    image: qdrant/qdrant:latest
    profiles: [ "infra" ]
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - /docker_data/qdrant_data:/qdrant/storage
    restart: always
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: [ "CMD-SHELL", "bash -c 'cat < /dev/tcp/localhost/6333'" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - msa-network
    labels:
      - app=qdrant
      - stack=my-prime-jennie

  mariadb:
    image: mariadb:10.11
    profiles: [ "infra" ]
    environment:
      - MARIADB_ROOT_PASSWORD=${MARIADB_PASSWORD:-q1w2e3R$}
      - MARIADB_USER=${MARIADB_USER:-jennie}
      - MARIADB_PASSWORD=${MARIADB_PASSWORD:-q1w2e3R$}
      - MARIADB_DATABASE=${MARIADB_DBNAME:-jennie_db}
    command: --lower_case_table_names=1
    ports:
      - "3307:3306"
    volumes:
      - /docker_data/mariadb_data:/var/lib/mysql
      - ./docker/init:/docker-entrypoint-initdb.d
    restart: always
    healthcheck:
      test: [ "CMD", "healthcheck.sh", "--connect", "--innodb_initialized" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - msa-network
    labels:
      - app=mariadb
      - stack=my-prime-jennie

  redis:
    image: redis:alpine
    profiles: [ "infra" ]
    labels:
      - app=redis
      - stack=my-prime-jennie
    ports:
      - "6379:6379"
    volumes:
      - /docker_data/redis_data:/data
    restart: always
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - msa-network

  # ============================================================================
  #  \\u2601\\ufe0f Observability Stack (Loki + Promtail + Grafana)
  # ============================================================================
  loki:
    image: grafana/loki:2.9.4
    profiles: [ "infra" ]
    command:
      - -config.file=/etc/loki/local-config.yaml
      - -distributor.replication-factor=1
      - -replication-factor=1
    user: "0"
    ports:
      - "3400:3100"
    volumes:
      - /docker_data/loki/local-config.yaml:/etc/loki/local-config.yaml:ro
      - /docker_data/loki_data:/tmp/loki
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: always
    networks:
      - msa-network
    labels:
      - app=loki
      - stack=my-prime-jennie

  promtail:
    image: grafana/promtail:3.0.0
    profiles: [ "infra" ]
    command: -config.file=/etc/promtail/config.yaml
    volumes:
      - /docker_data/promtail/config.yaml:/etc/promtail/config.yaml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
    depends_on:
      loki:
        condition: service_healthy
    networks:
      - msa-network
    labels:
      - app=promtail
      - stack=my-prime-jennie

  grafana:
    image: grafana/grafana:11.3.0
    profiles: [ "infra" ]
    user: "0"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_USERS_DEFAULT_THEME=dark
    ports:
      - "3300:3000"
    volumes:
      - /docker_data/grafana_data:/var/lib/grafana
      - ./observability/grafana/provisioning:/etc/grafana/provisioning:ro
    restart: always
    depends_on:
      loki:
        condition: service_healthy
    networks:
      - msa-network
    labels:
      - app=grafana
      - stack=my-prime-jennie

  # ============================================================================
  # 0-bis. Scheduler Service (Legacy - Removed in favor of Airflow)
  # ============================================================================
  # scheduler-service: ... removed ...
  # scheduler-worker: ... removed ...

  scheduler-service-mock:
    build:
      context: .
      dockerfile: services/scheduler-service/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    environment:
      - PORT=9095
      - RABBITMQ_URL=amqp://guest:guest@localhost:5672/
    volumes:
      - /docker_data/scheduler_data:/app/data
    labels:
      - app=scheduler-service-mock
      - stack=my-prime-jennie
    network_mode: host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      kis-gateway-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:9095/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    command: [ "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "9095" ]

  # ============================================================================
  # 1. KIS Mock Server (간단한 HTTP REST API 버전)
  # WebSocket은 Cloud Run 환경에서만 테스트 (DB 의존성 때문)
  # ============================================================================
  kis-mock:
    build:
      context: .
      dockerfile: docker/kis-mock/Dockerfile
    profiles: [ "mock" ]
    environment:
      - PORT=9443
    network_mode: host
    labels:
      - app=kis-mock
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import requests; requests.get('http://localhost:9443/health').raise_for_status()" ]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 10s

  # ============================================================================
  # 2. KIS Gateway (토큰 관리 및 API Rate Limiting)
  # ============================================================================
  kis-gateway:
    build:
      context: .
      dockerfile: services/kis-gateway/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
      - /docker_data/kis_tokens:/app/tokens
    environment:
      - PORT=8080
      - SECRETS_FILE=/app/config/secrets.json
      - GUNICORN_CMD_ARGS=--timeout 600
      - KIS_TOKEN_FILE_PATH=/app/tokens/kis_token.json
    # WSL2 mirrored mode: 127.0.0.1로 MariaDB/Redis 접근
    network_mode: host
    restart: unless-stopped
    labels:
      - app=kis-gateway
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import requests; requests.get('http://localhost:8080/health').raise_for_status()" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  kis-gateway-mock:
    build:
      context: .
      dockerfile: services/kis-gateway/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9080
      - SECRETS_FILE=/app/config/secrets.json
      - GUNICORN_CMD_ARGS=--timeout 600
      - KIS_BASE_URL_MOCK=http://localhost:9443
    network_mode: host
    labels:
      - app=kis-gateway-mock
      - stack=my-prime-jennie
    depends_on:
      kis-mock:
        condition: service_healthy
    command: [ "gunicorn", "--bind", "0.0.0.0:9080", "--workers", "1", "--threads", "1", "--timeout", "600", "--chdir", "/app/kis-gateway", "main:app" ]
    healthcheck:
      test: [ "CMD", "python", "-c", "import requests; requests.get('http://localhost:9080/health').raise_for_status()" ]
      interval: 10s
      timeout: 5s
      retries: 3

  # ============================================================================
  # 3. Buy Scanner (매수 신호 탐지)
  # ============================================================================
  buy-scanner:
    build:
      context: .
      dockerfile: services/buy-scanner/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=8081
      - SECRETS_FILE=/app/config/secrets.json
      # WebSocket 모드 활성화 (실제 KIS WebSocket 연결)
      - USE_WEBSOCKET_MODE=true
      # ⭐ Redis Streams 모드: Gateway 통해 공유 WebSocket 사용
      - USE_REDIS_STREAMS=true
      - KIS_GATEWAY_URL=http://127.0.0.1:8080
      # Gateway를 통한 토큰 발급 (Access Token + WebSocket Approval Key 충돌 방지)
      - KIS_TOKEN_PROVIDER_URL=http://127.0.0.1:8080/api/token
      - KIS_WS_APPROVAL_KEY_PROVIDER_URL=http://127.0.0.1:8080/api/ws-approval-key

    # WSL2 mirrored mode: 127.0.0.1로 Windows MariaDB 접근
    network_mode: host
    restart: unless-stopped
    # Graceful Shutdown: SIGTERM 수신 후 30초 대기
    stop_grace_period: 30s
    labels:
      - app=buy-scanner
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "curl", "-sf", "http://localhost:8081/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 40s

  buy-scanner-mock:
    build:
      context: .
      dockerfile: services/buy-scanner/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9081
      - SECRETS_FILE=/app/config/secrets.json
      - KIS_GATEWAY_URL=http://localhost:9080
      - RABBITMQ_URL=amqp://guest:guest@localhost:5672/
      # WebSocket 모드 활성화
      - USE_WEBSOCKET_MODE=true
      - MOCK_SKIP_TIME_CHECK=true
      - KIS_BASE_URL_MOCK=http://localhost:9443
    network_mode: host
    labels:
      - app=buy-scanner-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      kis-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 4. Buy Executor (매수 실행)
  # ============================================================================
  buy-executor:
    build:
      context: .
      dockerfile: services/buy-executor/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=8082
      - SECRETS_FILE=/app/config/secrets.json
    # WSL2 mirrored mode: 127.0.0.1로 Windows MariaDB 접근
    network_mode: host
    restart: unless-stopped
    # Graceful Shutdown: SIGTERM 수신 후 30초 대기 (주문 완료 대기)
    stop_grace_period: 30s
    labels:
      - app=buy-executor
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "curl", "-sf", "http://localhost:8082/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 40s

  buy-executor-mock:
    build:
      context: .
      dockerfile: services/buy-executor/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9082
      - SECRETS_FILE=/app/config/secrets.json
      - KIS_GATEWAY_URL=http://localhost:9080
      - RABBITMQ_URL=amqp://guest:guest@localhost:5672/
    network_mode: host
    labels:
      - app=buy-executor-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 5. Sell Executor (매도 실행)
  # ============================================================================
  sell-executor:
    build:
      context: .
      dockerfile: services/sell-executor/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=8083
      - SECRETS_FILE=/app/config/secrets.json
    # WSL2 mirrored mode: 127.0.0.1로 Windows MariaDB 접근
    network_mode: host
    restart: unless-stopped
    # Graceful Shutdown: SIGTERM 수신 후 30초 대기 (주문 완료 대기)
    stop_grace_period: 30s
    labels:
      - app=sell-executor
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "curl", "-sf", "http://localhost:8083/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 40s

  sell-executor-mock:
    build:
      context: .
      dockerfile: services/sell-executor/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9083
      - SECRETS_FILE=/app/config/secrets.json
      - KIS_GATEWAY_URL=http://localhost:9080
      - RABBITMQ_URL=amqp://guest:guest@localhost:5672/
    network_mode: host
    labels:
      - app=sell-executor-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 5.5. Command Handler (Telegram 명령 처리)
  # ============================================================================
  command-handler:
    build:
      context: .
      dockerfile: services/command-handler/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - PORT=8091
      - SECRETS_FILE=/app/config/secrets.json
      - AUTO_START_POLLING=true
      - POLL_INTERVAL_SECONDS=5
    network_mode: host
    restart: unless-stopped
    labels:
      - app=command-handler
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8091/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  command-handler-mock:
    build:
      context: .
      dockerfile: services/command-handler/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9091
      - SECRETS_FILE=/app/config/secrets.json
      - AUTO_START_POLLING=true
      - POLL_INTERVAL_SECONDS=5
      - KIS_GATEWAY_URL=http://localhost:9080
    network_mode: host
    labels:
      - app=command-handler-mock
      - stack=my-prime-jennie
    depends_on:
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 6. Price Monitor (가격 모니터링)
  # ============================================================================
  price-monitor:
    build:
      context: .
      dockerfile: services/price-monitor/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=8088
      - SECRETS_FILE=/app/config/secrets.json
      - GUNICORN_CMD_ARGS=--timeout 600
      # ⭐ Redis Streams 모드: Gateway 통해 공유 WebSocket 사용
      - USE_REDIS_STREAMS=true
      - KIS_GATEWAY_URL=http://127.0.0.1:8080
      - KIS_TOKEN_PROVIDER_URL=http://127.0.0.1:8080/api/token
      # Gateway를 통한 WebSocket Approval Key 발급 (토큰 충돌 방지)
      - KIS_WS_APPROVAL_KEY_PROVIDER_URL=http://127.0.0.1:8080/api/ws-approval-key

    # WSL2 mirrored mode: 127.0.0.1로 Windows MariaDB 접근
    network_mode: host
    restart: unless-stopped
    # Graceful Shutdown: SIGTERM 수신 후 30초 대기
    stop_grace_period: 30s
    labels:
      - app=price-monitor
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "curl", "-sf", "http://localhost:8088/health" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 40s

  price-monitor-mock:
    build:
      context: .
      dockerfile: services/price-monitor/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9088
      - SECRETS_FILE=/app/config/secrets.json
      - GUNICORN_CMD_ARGS=--timeout 600
      - KIS_GATEWAY_URL=http://localhost:9080
      - KIS_TOKEN_PROVIDER_URL=http://localhost:9080/api/token
      - REDIS_URL=redis://localhost:6379
      - RABBITMQ_URL=amqp://guest:guest@localhost:5672/
    network_mode: host
    labels:
      - app=price-monitor-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 7. Daily Briefing (일일 브리핑)
  # ============================================================================
  daily-briefing:
    build:
      context: .
      dockerfile: services/daily-briefing/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=8086
      - SECRETS_FILE=/app/config/secrets.json
    # WSL2 mirrored mode: 127.0.0.1로 Windows MariaDB 접근
    network_mode: host
    restart: unless-stopped
    labels:
      - app=daily-briefing
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8086/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  daily-briefing-mock:
    build:
      context: .
      dockerfile: services/daily-briefing/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9086
      - SECRETS_FILE=/app/config/secrets.json
      - KIS_GATEWAY_URL=http://localhost:9080
    network_mode: host
    labels:
      - app=daily-briefing-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 8. Scout Job (종목 발굴)
  # ============================================================================
  scout-job:
    build:
      context: .
      dockerfile: services/scout-job/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
      - ./services/scout-job:/app/services/scout-job
      - ./shared:/app/shared
      - /docker_data/llm_debug_logs:/app/logs # [v1.4] LLM 디버그 로그
    environment:
      - PORT=8087
      - SECRETS_FILE=/app/config/secrets.json
      - USE_OLLAMA_GATEWAY=true
      - OLLAMA_GATEWAY_URL=http://localhost:11500
      - TIER_REASONING_PROVIDER=deepseek_cloud
      - TIER_THINKING_PROVIDER=deepseek_cloud
      - DISABLE_MARKET_OPEN_CHECK=false
      - ENABLE_RAG=true
      - RAG_EMBEDDING_PROVIDER=local
      - LLM_DEBUG_ENABLED=true # [v1.5] 디버그 로깅 활성화
      - LLM_DEBUG_LOG_PATH=/app/logs/llm_interactions.jsonl
      - ENABLE_SCOUT_JOB_WORKER=false # API 서버에서는 워커 비활성화
      - ENABLE_STARTUP_ONESHOT=true
      - QUANT_SCORER_VERSION=v2 # v1: 현재 수준 기반, v2: 잠재력 기반
    network_mode: host
    restart: unless-stopped
    labels:
      - app=scout-job
      - stack=my-prime-jennie
    container_name: scout-job
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8087/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  scout-worker:
    build:
      context: .
      dockerfile: services/scout-job/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
      - ./services/scout-job:/app/services/scout-job
      - ./shared:/app/shared
      - /docker_data/llm_debug_logs:/app/logs
    environment:
      - SECRETS_FILE=/app/config/secrets.json
      - USE_OLLAMA_GATEWAY=true
      - OLLAMA_GATEWAY_URL=http://localhost:11500
      - TIER_REASONING_PROVIDER=deepseek_cloud
      - TIER_THINKING_PROVIDER=deepseek_cloud
      - DISABLE_MARKET_OPEN_CHECK=false
      - ENABLE_RAG=true
      - LLM_DEBUG_ENABLED=true
      - LLM_DEBUG_LOG_PATH=/app/logs/llm_interactions.jsonl
      - ENABLE_SCOUT_JOB_WORKER=true # 전용 워커 프로세스
      - ENABLE_STARTUP_ONESHOT=false
      - QUANT_SCORER_VERSION=v2 # v1: 현재 수준 기반, v2: 잠재력 기반
    network_mode: host
    restart: unless-stopped
    command: [ "python", "main.py" ] # Gunicorn 없이 직접 실행 (포트 바인딩 필요 없음)
    labels:
      - app=scout-worker
      - stack=my-prime-jennie
    depends_on:
      scout-job:
        condition: service_healthy

  scout-job-mock:
    build:
      context: .
      dockerfile: services/scout-job/Dockerfile
    profiles: [ "mock" ]
    env_file:
      - infrastructure/env-vars-mock.yaml
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    environment:
      - PORT=9087
      - SECRETS_FILE=/app/config/secrets.json
      - KIS_GATEWAY_URL=http://localhost:9080
      - CHROMA_SERVER_HOST=localhost
      - REDIS_URL=redis://localhost:6379
    network_mode: host
    labels:
      - app=scout-job-mock
      - stack=my-prime-jennie
    depends_on:
      scheduler-service-mock:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
        required: false
      redis:
        condition: service_healthy
        required: false

  # ============================================================================
  # 9. Dashboard (React + FastAPI)
  # ============================================================================
  dashboard-backend:
    build:
      context: .
      dockerfile: services/dashboard/backend/Dockerfile
    profiles: [ "real" ]
    network_mode: host
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - JWT_SECRET=${JWT_SECRET:-your-jwt-secret-here}
      - REDIS_URL=redis://localhost:6379/0
      - KIS_GATEWAY_URL=http://localhost:8080
      - SECRETS_FILE=/app/config/secrets.json
      - MARIADB_HOST=127.0.0.1
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    healthcheck:
      test: [ "CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8090/health')" ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: always
    labels:
      - app=dashboard-backend
      - stack=my-prime-jennie
    container_name: dashboard-backend

  dashboard-frontend:
    build:
      context: ./services/dashboard/frontend
      dockerfile: Dockerfile
      args:
        - VITE_API_URL=/api
    container_name: dashboard-frontend
    profiles: [ "real" ]
    network_mode: host
    depends_on:
      dashboard-backend:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "sh", "-c", "pgrep nginx > /dev/null" ]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: always
    labels:
      - app=dashboard-frontend
      - stack=my-prime-jennie

  # Cloudflare Tunnel - 외부 접근을 위한 보안 터널 (상시 구동)
  # secrets.json의 cloudflare-tunnel-token 사용
  cloudflared:
    build:
      context: ./infrastructure/cloudflared
      dockerfile: Dockerfile
    profiles: [ "infra" ]
    network_mode: host
    volumes:
      - ./secrets.json:/config/secrets.json:ro
    restart: on-failure # 토큰 없으면 exit 0으로 종료, 재시작 안함
    labels:
      - app=cloudflared
      - stack=my-prime-jennie

  # ============================================================================
  # CI - Jenkins (Dockerized) - 상시 구동
  # ============================================================================
  jenkins:
    build:
      context: ./docker/jenkins
      dockerfile: Dockerfile
    image: my-jenkins:latest
    profiles: [ "ci" ] # Jenkins는 별도 프로파일 (내부 CI용, 신규 설치 불필요)
    user: "0" # root로 실행해 docker.sock 접근 허용
    environment:
      - TZ=Asia/Seoul
      - JAVA_OPTS=-Xmx2048m -Xms1024m
    ports:
      - "8180:8080" # 호스트 8180 → Jenkins 8080
    volumes:
      - /docker_data/jenkins_home:/var/jenkins_home
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/youngs75/projects/my-prime-jennie:/home/youngs75/projects/my-prime-jennie
    restart: unless-stopped
    labels:
      - app=jenkins
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD-SHELL", "curl -f -s http://localhost:8080/login || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - msa-network

  # ============================================================================
  # 11. AI/LLM Services
  # ============================================================================

  # LLM Gateway - 중앙화된 Local LLM 요청 처리 (Ollama/vLLM 투명 전환)
  ollama-gateway:
    build:
      context: .
      dockerfile: services/ollama-gateway/Dockerfile
    profiles: [ "real" ]
    network_mode: host
    depends_on:
      vllm-llm:
        condition: service_healthy
        required: false
      vllm-embed:
        condition: service_healthy
        required: false
    environment:
      - BACKEND_MODE=vllm
      - VLLM_LLM_URL=http://localhost:8001
      - VLLM_EMBED_URL=http://localhost:8002
      - VLLM_MAX_MODEL_LEN=4096
      - OLLAMA_HOST=http://localhost:11434
      - REDIS_URL=redis://localhost:6379/0
      # vLLM continuous batching → Ollama 대비 rate limit 대폭 완화
      - OLLAMA_RATE_LIMIT=300 per minute
      - OLLAMA_RATE_LIMIT_FAST=600 per minute
      - OLLAMA_RATE_LIMIT_EMBED=6000 per minute
      - OLLAMA_FAST_MODELS=exaone
      - OLLAMA_CIRCUIT_FAIL_MAX=5
      - OLLAMA_CIRCUIT_RESET_TIMEOUT=120
      - OLLAMA_MAX_CONCURRENT_REQUESTS=10
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    restart: unless-stopped
    labels:
      - app=ollama-gateway
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import requests; requests.get('http://localhost:11500/health').raise_for_status()" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  ollama-gateway-mock:
    build:
      context: .
      dockerfile: services/ollama-gateway/Dockerfile
    profiles: [ "mock" ]
    network_mode: host
    environment:
      - PORT=11501
      - OLLAMA_HOST=http://localhost:11434
      - REDIS_URL=redis://localhost:6379/0
      - OLLAMA_RATE_LIMIT=1 per 5 seconds
    restart: unless-stopped
    labels:
      - app=ollama-gateway-mock
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "python", "-c", "import requests; requests.get('http://localhost:11501/health').raise_for_status()" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # vLLM LLM Server (EXAONE 4.0 32B AWQ) - 메인 추론 엔진
  vllm-llm:
    image: vllm/vllm-openai:latest
    profiles: [ "infra" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - /docker_data/huggingface_cache:/root/.cache/huggingface
    ports:
      - "8001:8000"
    ipc: host
    command: >
      LGAI-EXAONE/EXAONE-4.0-32B-AWQ
      --quantization awq_marlin
      --dtype half
      --max-model-len 4096
      --gpu-memory-utilization 0.90
      --trust-remote-code
    restart: unless-stopped
    labels:
      - app=vllm-llm
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/v1/models')\"" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # vLLM Embedding Server (KURE-v1) - 임베딩 전용
  vllm-embed:
    image: vllm/vllm-openai:latest
    profiles: [ "infra" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    volumes:
      - /docker_data/huggingface_cache:/root/.cache/huggingface
    ports:
      - "8002:8000"
    ipc: host
    command: >
      nlpai-lab/KURE-v1
      --dtype half
      --max-model-len 256
      --gpu-memory-utilization 0.05
      --trust-remote-code
      --enforce-eager
    restart: unless-stopped
    labels:
      - app=vllm-embed
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8000/v1/models')\"" ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

  # Ollama (Legacy) - BACKEND_MODE=ollama 시에만 사용
  ollama:
    image: ollama/ollama:latest
    profiles: [ "gpu-legacy" ]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    ports:
      - "11434:11434"
    volumes:
      - /docker_data/ollama_data:/root/.ollama
    environment:
      - OLLAMA_MAX_LOADED_MODELS=3
      - OLLAMA_NUM_PARALLEL=3
      - OLLAMA_KEEP_ALIVE=5m
    restart: unless-stopped
    networks:
      - msa-network
    labels:
      - app=ollama
      - stack=my-prime-jennie
    healthcheck:
      test: [ "CMD", "ollama", "list" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # ============================================================================
  # 9. Airflow Infrastructure (Consolidated Scheduler)
  # ============================================================================
  airflow-webserver:
    build:
      context: .
      dockerfile: services/airflow/Dockerfile
    profiles: [ "real" ]
    networks:
      - msa-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      # Use PyMySQL driver to avoid C-extension build dependencies
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=mysql+pymysql://root:q1w2e3R$@mariadb:3306/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-t7i2p3o4k5e6n7_g8e9n0e1r2a3t4e5d6=}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__RBAC=True
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs/airflow:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./shared:/opt/airflow/shared
      - ./services:/opt/airflow/services
      - ./infrastructure:/opt/airflow/infrastructure
      - ./config:/opt/airflow/config
      - ./scripts:/opt/airflow/scripts
      - ./secrets.json:/opt/airflow/secrets.json
    ports:
      - "8085:8080"
    command: webserver
    healthcheck:
      test: [ "CMD", "curl", "--fail", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 30s
      retries: 5
    restart: always

  airflow-scheduler:
    build:
      context: .
      dockerfile: services/airflow/Dockerfile
    profiles: [ "real" ]
    depends_on:
      airflow-webserver:
        condition: service_healthy
    networks:
      - msa-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=mysql+pymysql://root:q1w2e3R$@mariadb:3306/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-t7i2p3o4k5e6n7_g8e9n0e1r2a3t4e5d6=}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs/airflow:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./shared:/opt/airflow/shared
      - ./services:/opt/airflow/services
      - ./infrastructure:/opt/airflow/infrastructure
      - ./config:/opt/airflow/config
      - ./secrets.json:/opt/airflow/secrets.json
      - ./scripts:/opt/airflow/scripts
      - ./.telegram_sessions:/opt/airflow/.telegram_sessions
      # Mount docker socket to allow triggering other containers
      - /var/run/docker.sock:/var/run/docker.sock
    command: scheduler
    healthcheck:
      test: [ "CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"' ]
      interval: 30s
      timeout: 30s
      retries: 5
    restart: always

  # ============================================================================
  # 12. News Pipeline (Pub/Sub Architecture)
  # ============================================================================

  # News Collector - 뉴스 수집 전용 (Producer)
  news-collector:
    build:
      context: .
      dockerfile: services/news-collector/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - REDIS_URL=redis://localhost:6379/0
      - ENABLE_NEWS_ANALYSIS=true
    network_mode: host
    restart: unless-stopped
    labels:
      - app=news-collector
      - stack=my-prime-jennie
    container_name: news-collector

  # News Archiver - ChromaDB 저장 전용 (Consumer A)
  news-archiver:
    build:
      context: .
      dockerfile: services/news-archiver/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - REDIS_URL=redis://localhost:6379/0
      - CHROMA_SERVER_HOST=localhost
      - CHROMA_SERVER_PORT=8000
      - OLLAMA_BASE_URL=http://localhost:11500  # Gateway 경유 (embed rate limit 3000/min)
    network_mode: host
    restart: unless-stopped
    labels:
      - app=news-archiver
      - stack=my-prime-jennie
    depends_on:
      - news-collector

  # News Analyzer - LLM 분석 전용 (Consumer B)
  news-analyzer:
    build:
      context: .
      dockerfile: services/news-analyzer/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - REDIS_URL=redis://localhost:6379/0
      - USE_OLLAMA_GATEWAY=true
      - OLLAMA_GATEWAY_URL=http://localhost:11500
      - SECRETS_FILE=/app/config/secrets.json
    volumes:
      - ./secrets.json:/app/config/secrets.json:ro
    network_mode: host
    restart: unless-stopped
    labels:
      - app=news-analyzer
      - stack=my-prime-jennie
    depends_on:
      - news-collector

  # ============================================================================
  # Macro Insight Services (텔레그램 매크로 정보 수집/분석)
  # 3현자 Council 권고: 외부 정보 가중치 ≤10%, RISK_OFF 단독 발동 금지
  # ============================================================================

  # Telegram Collector - 증권사 리서치 채널 메시지 수집
  telegram-collector:
    build:
      context: .
      dockerfile: services/telegram-collector/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - REDIS_URL=redis://localhost:6379/0
      - TELEGRAM_SESSION_NAME=telegram_collector
      - TELEGRAM_MAX_MESSAGES=50
      - TELEGRAM_MESSAGE_AGE_HOURS=24
    volumes:
      - ./.telegram_sessions:/app/.telegram_sessions
      - ./secrets.json:/app/secrets.json:ro
    network_mode: host
    restart: unless-stopped
    labels:
      - app=telegram-collector
      - stack=my-prime-jennie
    container_name: telegram-collector

  # Macro Aggregator - 매크로 신호 분석 및 집계
  macro-aggregator:
    build:
      context: .
      dockerfile: services/macro-aggregator/Dockerfile
    profiles: [ "real" ]
    env_file:
      - infrastructure/env-vars-wsl.yaml
    environment:
      - REDIS_URL=redis://localhost:6379/0
      - MACRO_CONSUMER_NAME=macro_aggregator_1
      - MACRO_LLM_MODE=auto # auto: 장외 시간에만 gpt-oss LLM 사용
    network_mode: host
    restart: unless-stopped
    labels:
      - app=macro-aggregator
      - stack=my-prime-jennie
    depends_on:
      - telegram-collector
    container_name: macro-aggregator

networks:
  msa-network:
    driver: bridge
