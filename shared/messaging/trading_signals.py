"""
shared/messaging/trading_signals.py
------------------------------------
Redis Streams ê¸°ë°˜ íŠ¸ë ˆì´ë”© ì‹œê·¸ë„ ë©”ì‹œì§•.
RabbitMQ(pika)ë¥¼ ëŒ€ì²´í•˜ì—¬ buy-signals, sell-orders, jobs.scout íë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì‚¬ìš© ì˜ˆì‹œ:
---------
>>> from shared.messaging.trading_signals import TradingSignalPublisher, TradingSignalWorker
>>>
>>> # ë°œí–‰
>>> pub = TradingSignalPublisher(redis_url, STREAM_BUY_SIGNALS)
>>> pub.publish({'stock_code': '005930', 'signal': 'RSI_OVERSOLD'})
>>>
>>> # ì†Œë¹„
>>> def handler(message):
...     print(f"Received: {message}")
>>> worker = TradingSignalWorker(redis_url, STREAM_BUY_SIGNALS, GROUP_BUY_EXECUTOR, "worker-1", handler)
>>> worker.start()
"""

import json
import logging
import os
import threading
import time
from typing import Callable, Dict, Optional

import redis

logger = logging.getLogger(__name__)

# ==============================================================================
# Stream & Consumer Group Names
# ==============================================================================

STREAM_BUY_SIGNALS = "stream:buy-signals"
STREAM_SELL_ORDERS = "stream:sell-orders"
STREAM_JOBS_SCOUT = "stream:jobs:scout"

GROUP_BUY_EXECUTOR = "group_buy_executor"
GROUP_SELL_EXECUTOR = "group_sell_executor"
GROUP_SCOUT_WORKER = "group_scout_worker"

# Scheduler-service ë™ì  íìš© prefix
STREAM_JOBS_PREFIX = "stream:jobs:"

# ==============================================================================
# Defaults
# ==============================================================================

RECONNECT_DELAY = 5  # ì´ˆê¸° ì¬ì—°ê²° ëŒ€ê¸° (ì´ˆ)
MAX_RECONNECT_DELAY = 60  # ìµœëŒ€ ì¬ì—°ê²° ëŒ€ê¸° (ì´ˆ)


class TradingSignalPublisher:
    """Redis Streams ê¸°ë°˜ ë©”ì‹œì§€ ë°œí–‰ í´ë˜ìŠ¤ (RabbitMQPublisher ëŒ€ì²´)"""

    def __init__(self, redis_url: str, stream_name: str):
        self.redis_url = redis_url
        self.stream_name = stream_name
        self._client: Optional[redis.Redis] = None

    def _get_client(self) -> redis.Redis:
        if self._client is None:
            self._client = redis.from_url(self.redis_url, decode_responses=True)
        return self._client

    def publish(
        self,
        payload: dict,
        delay_seconds: int = 0,
        headers: Optional[Dict] = None,
        message_ttl_ms: Optional[int] = None,
    ) -> Optional[str]:
        """ë©”ì‹œì§€ë¥¼ Redis Streamì— ë°œí–‰í•˜ê³  ë©”ì‹œì§€ IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        delay_seconds, headers, message_ttl_ms ëŠ” RabbitMQ í˜¸í™˜ ì‹œê·¸ë‹ˆì²˜ì´ë©°
        Redis Streamsì—ì„œëŠ” ë¬´ì‹œë©ë‹ˆë‹¤ (at-most-once ì‹œë§¨í‹±).
        """
        try:
            client = self._get_client()
            data = {
                "payload": json.dumps(payload, ensure_ascii=False, default=str),
            }
            msg_id = client.xadd(self.stream_name, data)
            logger.info(
                "âœ… Redis Stream ë©”ì‹œì§€ ë°œí–‰: %s (stream=%s)",
                msg_id,
                self.stream_name,
            )
            return msg_id
        except Exception as e:
            logger.error(f"âŒ Redis Stream ë©”ì‹œì§€ ë°œí–‰ ì‹¤íŒ¨: {e}", exc_info=True)
            # ì—°ê²° ë¦¬ì…‹í•˜ì—¬ ë‹¤ìŒ í˜¸ì¶œ ì‹œ ì¬ì—°ê²°
            self._client = None
            return None

    def close(self):
        if self._client:
            try:
                self._client.close()
            except Exception:
                pass
            self._client = None


class TradingSignalWorker:
    """Redis Streams ê¸°ë°˜ ë©”ì‹œì§€ ì†Œë¹„ ì›Œì»¤ (RabbitMQWorker ëŒ€ì²´)

    ê¸°ì¡´ RabbitMQWorkerì™€ ë™ì¼í•œ at-most-once ì‹œë§¨í‹±:
    - handler í˜¸ì¶œ ì „ ACK (ì¥ì‹œê°„ ì²˜ë¦¬ ì¤‘ ì—°ê²° ëŠê¹€ìœ¼ë¡œ ì¸í•œ ì¬ì²˜ë¦¬ ë°©ì§€)
    - handler ì‹¤íŒ¨ ì‹œ ë©”ì‹œì§€ ìœ ì‹¤ í—ˆìš© (Scout Job ë“±ì€ ìì²´ ì¤‘ë³µ ë°©ì§€ ë‚´ì¥)
    """

    def __init__(
        self,
        redis_url: str,
        stream_name: str,
        group_name: str,
        consumer_name: str,
        handler: Callable[[Dict], None],
    ):
        self.redis_url = redis_url
        self.stream_name = stream_name
        self.group_name = group_name
        self.consumer_name = consumer_name
        self.handler = handler
        self._stop_event = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._reconnect_count = 0

    def start(self):
        if self._thread and self._thread.is_alive():
            return
        self._stop_event.clear()
        self._thread = threading.Thread(target=self._run, daemon=True)
        self._thread.start()
        logger.info(
            "âœ… Redis Stream ì›Œì»¤ ì‹œì‘: stream=%s, group=%s, consumer=%s",
            self.stream_name,
            self.group_name,
            self.consumer_name,
        )

    def stop(self):
        logger.info("ğŸ›‘ Redis Stream ì›Œì»¤ ì¢…ë£Œ ìš”ì²­...")
        self._stop_event.set()
        if self._thread:
            self._thread.join(timeout=5)

    def _ensure_group(self, client: redis.Redis):
        """Consumer Groupì´ ì—†ìœ¼ë©´ ìƒì„± (ìŠ¤íŠ¸ë¦¼ë„ ìë™ ìƒì„±)"""
        try:
            client.xgroup_create(
                self.stream_name, self.group_name, id="0", mkstream=True
            )
            logger.info(
                "âœ… Consumer Group ìƒì„±: %s on %s",
                self.group_name,
                self.stream_name,
            )
        except redis.ResponseError as e:
            if "BUSYGROUP" in str(e):
                pass  # ì´ë¯¸ ì¡´ì¬
            else:
                raise

    def _run(self):
        while not self._stop_event.is_set():
            client = None
            try:
                client = redis.from_url(self.redis_url, decode_responses=True)
                self._ensure_group(client)
                self._reconnect_count = 0
                logger.info(
                    "âœ… Redis Stream ì—°ê²° ì„±ê³µ (stream=%s)", self.stream_name
                )

                # Phase 1: ë¯¸ì²˜ë¦¬ pending ë©”ì‹œì§€ ë³µêµ¬
                self._recover_pending(client)

                # Phase 2: ìƒˆ ë©”ì‹œì§€ ì†Œë¹„ ë£¨í”„
                while not self._stop_event.is_set():
                    try:
                        results = client.xreadgroup(
                            self.group_name,
                            self.consumer_name,
                            {self.stream_name: ">"},
                            count=1,
                            block=1000,  # 1ì´ˆ ë¸”ë¡œí‚¹ (stop_event ì²´í¬ ì£¼ê¸°)
                        )
                    except redis.ConnectionError:
                        logger.warning("âš ï¸ Redis ì—°ê²° ëŠê¹€ ê°ì§€, ì¬ì—°ê²° ì‹œë„...")
                        break

                    if not results:
                        continue

                    for _stream, messages in results:
                        for msg_id, data in messages:
                            self._process_message(client, msg_id, data)

            except redis.ConnectionError as e:
                self._handle_reconnect(e)
            except Exception as exc:
                self._handle_reconnect(exc)
            finally:
                if client:
                    try:
                        client.close()
                    except Exception:
                        pass

        logger.info("ğŸ›‘ Redis Stream ì›Œì»¤ ì¢…ë£Œ ì™„ë£Œ (stream=%s)", self.stream_name)

    def _recover_pending(self, client: redis.Redis):
        """ë¯¸í™•ì¸(pending) ë©”ì‹œì§€ ë³µêµ¬ ì²˜ë¦¬"""
        try:
            results = client.xreadgroup(
                self.group_name,
                self.consumer_name,
                {self.stream_name: "0"},  # "0" = pending messages
                count=100,
            )
            if not results:
                return

            for _stream, messages in results:
                if not messages:
                    continue
                logger.info(
                    "ğŸ”„ Pending ë©”ì‹œì§€ ë³µêµ¬: %dê±´ (stream=%s)",
                    len(messages),
                    self.stream_name,
                )
                for msg_id, data in messages:
                    if data:  # dataê°€ ë¹ˆ dictì´ë©´ ì´ë¯¸ ì²˜ë¦¬ëœ ê²ƒ
                        self._process_message(client, msg_id, data)
                    else:
                        # ì´ë¯¸ ACKëœ ë©”ì‹œì§€ (ë¹ˆ ë°ì´í„°) â€” ìŠ¤í‚µ
                        client.xack(self.stream_name, self.group_name, msg_id)
        except Exception as e:
            logger.warning(f"âš ï¸ Pending ë©”ì‹œì§€ ë³µêµ¬ ì‹¤íŒ¨: {e}")

    def _process_message(self, client: redis.Redis, msg_id: str, data: dict):
        """ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬ (ACK-first, at-most-once)"""
        try:
            # 1. ACK ë¨¼ì € (at-most-once: ì¥ì‹œê°„ ì²˜ë¦¬ ì¤‘ ì—°ê²° ëŠê¹€ ë°©ì§€)
            client.xack(self.stream_name, self.group_name, msg_id)

            # 2. Payload íŒŒì‹±
            raw = data.get("payload", "{}")
            payload = json.loads(raw)
            logger.info("ğŸ“¥ Redis Stream ë©”ì‹œì§€ ìˆ˜ì‹ : %s (stream=%s)", msg_id, self.stream_name)

            # 3. Handler ì‹¤í–‰
            self.handler(payload)

        except json.JSONDecodeError as e:
            logger.error(f"âŒ ë©”ì‹œì§€ JSON íŒŒì‹± ì‹¤íŒ¨ (msg_id={msg_id}): {e}")
        except Exception as e:
            # handler ì‹¤íŒ¨ â€” ì´ë¯¸ ACKë¨, ë¡œê·¸ë§Œ ë‚¨ê¹€
            logger.exception("âŒ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨ (ì´ë¯¸ ACKë¨, msg_id=%s)", msg_id)

    def _handle_reconnect(self, error):
        self._reconnect_count += 1
        delay = min(RECONNECT_DELAY * self._reconnect_count, MAX_RECONNECT_DELAY)
        logger.warning(
            "âš ï¸ Redis Stream ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ #%d). %dì´ˆ í›„ ì¬ì‹œë„. ì˜¤ë¥˜: %s",
            self._reconnect_count,
            delay,
            error,
        )
        # stop_eventë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ê¸° ì¤‘ì—ë„ ë¹ ë¥´ê²Œ ì¢…ë£Œ ê°€ëŠ¥
        self._stop_event.wait(timeout=delay)
