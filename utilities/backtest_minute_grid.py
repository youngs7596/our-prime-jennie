#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
backtest_minute_grid.py
-----------------------

ë¶„ë´‰ ë°±í…ŒìŠ¤íŠ¸ ê·¸ë¦¬ë“œ ì„œì¹˜

ë‹¤ì–‘í•œ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•˜ì—¬ ìµœì ì˜ ì„¤ì •ì„ ì°¾ìŠµë‹ˆë‹¤.

Usage:
    python utilities/backtest_minute_grid.py
    python utilities/backtest_minute_grid.py --parallel 4
    python utilities/backtest_minute_grid.py --quick  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ì¡°í•© ì¶•ì†Œ)
"""

from __future__ import annotations

import argparse
import csv
import itertools
import json
import logging
import os
import sys
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import Dict, List, Any, Optional
from concurrent.futures import ProcessPoolExecutor, as_completed
import copy

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


# =============================================================================
# ê·¸ë¦¬ë“œ íŒŒë¼ë¯¸í„° ì •ì˜
# =============================================================================

@dataclass
class GridParams:
    """ê·¸ë¦¬ë“œ ì„œì¹˜ íŒŒë¼ë¯¸í„°"""

    # === ì§„ì… ê´€ë ¨ ===
    # RSI ê³¼ì—´ ì°¨ë‹¨ ì„ê³„ê°’ (ì´ ê°’ ì´ˆê³¼ ì‹œ ì§„ì… ê¸ˆì§€)
    rsi_max_threshold: float = 75.0

    # ê³¨ë“ í¬ë¡œìŠ¤ ìµœì†Œ ê±°ë˜ëŸ‰ ë¹„ìœ¨
    golden_cross_min_volume: float = 1.5

    # ëª¨ë©˜í…€ ì§„ì… ì„ê³„ê°’ (%)
    momentum_threshold: float = 3.0

    # No-Trade Window ì¢…ë£Œ ì‹œê°„ (ë¶„, 9ì‹œ ê¸°ì¤€)
    no_trade_end_minutes: int = 15  # 09:15

    # Danger Zone í™œì„±í™”
    danger_zone_enabled: bool = True

    # === ì²­ì‚° ê´€ë ¨ ===
    # ê³ ì • ì†ì ˆ ë¹„ìœ¨ (%)
    fixed_stop_loss_pct: float = -6.0

    # Trailing TP í™œì„±í™” ë¹„ìœ¨ (%)
    trailing_activation_pct: float = 5.0

    # Trailing TP ê³ ì  ëŒ€ë¹„ í•˜ë½ ë¹„ìœ¨ (%)
    trailing_drop_pct: float = 3.5

    # Scale-out í™œì„±í™”
    scale_out_enabled: bool = True

    # RSI ê³¼ë§¤ìˆ˜ ë§¤ë„ ì„ê³„ê°’
    rsi_overbought_sell: float = 75.0

    # ATR Stop ë°°ìˆ˜
    atr_multiplier: float = 2.0

    # === í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ ===
    # ìµœëŒ€ ë™ì‹œ í¬ì§€ì…˜ ìˆ˜
    max_positions: int = 5

    # í¬ì§€ì…˜ í¬ê¸° (%)
    position_size_pct: float = 20.0

    def to_dict(self) -> dict:
        return asdict(self)

    def get_key(self) -> str:
        """ê³ ìœ  í‚¤ ìƒì„±"""
        return (
            f"rsi{self.rsi_max_threshold}_"
            f"gcvol{self.golden_cross_min_volume}_"
            f"mom{self.momentum_threshold}_"
            f"ntw{self.no_trade_end_minutes}_"
            f"dz{int(self.danger_zone_enabled)}_"
            f"sl{abs(self.fixed_stop_loss_pct)}_"
            f"ttp{self.trailing_activation_pct}_"
            f"drop{self.trailing_drop_pct}_"
            f"so{int(self.scale_out_enabled)}_"
            f"rsisell{self.rsi_overbought_sell}_"
            f"atr{self.atr_multiplier}_"
            f"pos{self.max_positions}_"
            f"size{self.position_size_pct}"
        )


# =============================================================================
# ê·¸ë¦¬ë“œ ì„œì¹˜ ì„¤ì •
# =============================================================================

# ì „ì²´ ê·¸ë¦¬ë“œ (ë§ì€ ì¡°í•©)
FULL_GRID = {
    # ì§„ì… ê´€ë ¨
    'rsi_max_threshold': [70, 75, 80],
    'golden_cross_min_volume': [1.0, 1.5, 2.0],
    'momentum_threshold': [2.0, 3.0, 4.0],
    'no_trade_end_minutes': [10, 15, 30],
    'danger_zone_enabled': [True, False],

    # ì²­ì‚° ê´€ë ¨
    'fixed_stop_loss_pct': [-4.0, -5.0, -6.0, -7.0],
    'trailing_activation_pct': [4.0, 5.0, 6.0],
    'trailing_drop_pct': [2.5, 3.0, 3.5],
    'scale_out_enabled': [True, False],
    'rsi_overbought_sell': [70, 75, 80],
    'atr_multiplier': [1.5, 2.0, 2.5],

    # í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨
    'max_positions': [3, 5, 7],
    'position_size_pct': [15.0, 20.0, 25.0],
}

# ë¹ ë¥¸ ê·¸ë¦¬ë“œ (í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ)
QUICK_GRID = {
    # ì§„ì… ê´€ë ¨ (ê°€ì¥ ì˜í–¥ë ¥ í° íŒŒë¼ë¯¸í„°)
    'rsi_max_threshold': [70, 75, 80],
    'golden_cross_min_volume': [1.0, 1.5],
    'momentum_threshold': [2.0, 3.0],
    'danger_zone_enabled': [True, False],

    # ì²­ì‚° ê´€ë ¨
    'fixed_stop_loss_pct': [-5.0, -6.0, -7.0],
    'trailing_activation_pct': [4.0, 5.0],
    'trailing_drop_pct': [3.0, 3.5],
    'scale_out_enabled': [True],

    # í¬íŠ¸í´ë¦¬ì˜¤
    'max_positions': [5],
    'position_size_pct': [20.0],
}

# í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ (ìµœì†Œ ì¡°í•©)
MINIMAL_GRID = {
    'rsi_max_threshold': [70, 75, 80],
    'fixed_stop_loss_pct': [-5.0, -6.0, -7.0],
    'trailing_activation_pct': [4.0, 5.0, 6.0],
    'danger_zone_enabled': [True, False],
}


def generate_param_combinations(grid: Dict[str, List]) -> List[GridParams]:
    """íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±"""
    keys = list(grid.keys())
    values = list(grid.values())

    combinations = []
    for combo in itertools.product(*values):
        params_dict = dict(zip(keys, combo))
        params = GridParams(**params_dict)
        combinations.append(params)

    return combinations


# =============================================================================
# ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë‹¨ì¼)
# =============================================================================

def run_single_backtest(
    params: GridParams,
    start_date: str,
    end_date: str,
    initial_capital: float,
    use_watchlist: bool,
) -> Dict[str, Any]:
    """ë‹¨ì¼ íŒŒë¼ë¯¸í„° ì¡°í•©ìœ¼ë¡œ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""

    # ì—¬ê¸°ì„œ importí•´ì•¼ ë©€í‹°í”„ë¡œì„¸ì‹±ì—ì„œ ë™ì‘
    from utilities.backtest_minute_realistic import (
        MinuteRealisticBacktester,
        EntrySignalChecker,
        BacktestBarAggregator,
        MIN_BARS_REQUIRED,
    )
    from utilities.sell_logic_unified import SellConfig
    from shared import database
    from datetime import datetime as dt

    # íŒŒë¼ë¯¸í„° í‚¤
    param_key = params.get_key()

    try:
        # DB ì—°ê²°
        connection = database.get_db_connection()
        if not connection:
            return {
                'params': params.to_dict(),
                'param_key': param_key,
                'error': 'DB ì—°ê²° ì‹¤íŒ¨',
            }

        try:
            # ë°±í…ŒìŠ¤í„° ìƒì„± (ì»¤ìŠ¤í…€ ì„¤ì • ì ìš©)
            backtester = MinuteRealisticBacktester(
                initial_capital=initial_capital,
                max_positions=params.max_positions,
                position_size_pct=params.position_size_pct,
                verbose=False,
            )

            # === ì§„ì… ë¡œì§ íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ ===
            # EntrySignalChecker ë‚´ë¶€ ìƒìˆ˜ ëŒ€ì²´ë¥¼ ìœ„í•´ monkey-patching
            import utilities.backtest_minute_realistic as bt_module

            # ì›ë³¸ ê°’ ë°±ì—…
            orig_rsi_max = bt_module.RSI_MAX_THRESHOLD
            orig_gc_vol = bt_module.GOLDEN_CROSS_MIN_VOLUME_RATIO
            orig_no_trade_end = bt_module.NO_TRADE_END
            orig_danger_start = bt_module.DANGER_ZONE_START
            orig_danger_end = bt_module.DANGER_ZONE_END

            # íŒŒë¼ë¯¸í„° ì ìš©
            bt_module.RSI_MAX_THRESHOLD = params.rsi_max_threshold
            bt_module.GOLDEN_CROSS_MIN_VOLUME_RATIO = params.golden_cross_min_volume

            from datetime import time as dt_time
            bt_module.NO_TRADE_END = dt_time(9, params.no_trade_end_minutes)

            if not params.danger_zone_enabled:
                # Danger Zone ë¹„í™œì„±í™”: ì‹œì‘=ì¢…ë£Œë¡œ ì„¤ì •
                bt_module.DANGER_ZONE_START = dt_time(15, 0)
                bt_module.DANGER_ZONE_END = dt_time(15, 0)

            # EntrySignalChecker ì¬ìƒì„±
            backtester.entry_checker = EntrySignalChecker()

            # ëª¨ë©˜í…€ ì„ê³„ê°’ì€ _check_momentum ë©”ì„œë“œ ë‚´ë¶€ì—ì„œ ì‚¬ìš©
            # í´ë˜ìŠ¤ ì†ì„±ìœ¼ë¡œ ì¶”ê°€
            backtester.entry_checker._momentum_threshold = params.momentum_threshold

            # _check_momentum ë©”ì„œë“œ ì˜¤ë²„ë¼ì´ë“œ
            original_check_momentum = backtester.entry_checker._check_momentum
            def patched_check_momentum(bars):
                from typing import List, Tuple, Optional
                closes = [b.close for b in bars]
                threshold = params.momentum_threshold
                if len(closes) < 2:
                    return None
                if closes[0] <= 0:
                    return None
                momentum = ((closes[-1] - closes[0]) / closes[0]) * 100
                if momentum >= threshold:
                    reason = f"Momentum={momentum:.1f}% >= {threshold}%"
                    return ("MOMENTUM", reason)
                return None

            backtester.entry_checker._check_momentum = patched_check_momentum

            # === ì²­ì‚° ë¡œì§ íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ ===
            backtester.sell_config.fixed_stop_loss_pct = params.fixed_stop_loss_pct
            backtester.sell_config.trailing_activation_pct = params.trailing_activation_pct
            backtester.sell_config.trailing_drop_from_high_pct = params.trailing_drop_pct
            backtester.sell_config.scale_out_enabled = params.scale_out_enabled
            backtester.sell_config.rsi_overbought_threshold = params.rsi_overbought_sell
            backtester.sell_config.atr_multiplier = params.atr_multiplier

            # ë°ì´í„° ë¡œë“œ
            start_dt = dt.strptime(start_date, "%Y-%m-%d")
            end_dt = dt.strptime(end_date, "%Y-%m-%d")

            success = backtester.load_data(
                connection=connection,
                start_date=start_dt,
                end_date=end_dt,
                stock_codes=None,
                use_watchlist_history=use_watchlist,
            )

            if not success:
                # ì›ë³¸ ê°’ ë³µì›
                bt_module.RSI_MAX_THRESHOLD = orig_rsi_max
                bt_module.GOLDEN_CROSS_MIN_VOLUME_RATIO = orig_gc_vol
                bt_module.NO_TRADE_END = orig_no_trade_end
                bt_module.DANGER_ZONE_START = orig_danger_start
                bt_module.DANGER_ZONE_END = orig_danger_end

                return {
                    'params': params.to_dict(),
                    'param_key': param_key,
                    'error': 'ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨',
                }

            # ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            results = backtester.run()

            # ì›ë³¸ ê°’ ë³µì›
            bt_module.RSI_MAX_THRESHOLD = orig_rsi_max
            bt_module.GOLDEN_CROSS_MIN_VOLUME_RATIO = orig_gc_vol
            bt_module.NO_TRADE_END = orig_no_trade_end
            bt_module.DANGER_ZONE_START = orig_danger_start
            bt_module.DANGER_ZONE_END = orig_danger_end

            # ê²°ê³¼ ì •ë¦¬
            summary = results.get('summary', {})

            return {
                'params': params.to_dict(),
                'param_key': param_key,
                'total_trades': summary.get('total_trades', 0),
                'win_rate': summary.get('win_rate', 0),
                'total_pnl': summary.get('total_pnl', 0),
                'total_return_pct': summary.get('total_return_pct', 0),
                'mdd_pct': summary.get('mdd_pct', 0),
                'avg_holding_minutes': summary.get('avg_holding_minutes', 0),
                'final_capital': summary.get('final_capital', 0),
                'sharpe_ratio': _calculate_sharpe(results.get('daily_equity', [])),
                'profit_factor': _calculate_profit_factor(results.get('trades', [])),
                'error': None,
            }

        finally:
            connection.close()

    except Exception as e:
        return {
            'params': params.to_dict(),
            'param_key': param_key,
            'error': str(e),
        }


def _calculate_sharpe(daily_equity: List[dict], risk_free_rate: float = 0.035) -> float:
    """ìƒ¤í”„ ë¹„ìœ¨ ê³„ì‚° (ì—°ìœ¨í™”)"""
    if len(daily_equity) < 2:
        return 0.0

    equities = [d['equity'] for d in daily_equity]
    returns = []
    for i in range(1, len(equities)):
        if equities[i-1] > 0:
            daily_return = (equities[i] - equities[i-1]) / equities[i-1]
            returns.append(daily_return)

    if not returns:
        return 0.0

    import numpy as np
    mean_return = np.mean(returns)
    std_return = np.std(returns)

    if std_return == 0:
        return 0.0

    # ì—°ìœ¨í™” (252 ê±°ë˜ì¼ ê¸°ì¤€)
    annual_return = mean_return * 252
    annual_std = std_return * np.sqrt(252)

    sharpe = (annual_return - risk_free_rate) / annual_std
    return round(sharpe, 3)


def _calculate_profit_factor(trades: List[dict]) -> float:
    """Profit Factor ê³„ì‚° (ì´ ì´ìµ / ì´ ì†ì‹¤)"""
    if not trades:
        return 0.0

    total_profit = sum(t['pnl'] for t in trades if t['pnl'] > 0)
    total_loss = abs(sum(t['pnl'] for t in trades if t['pnl'] < 0))

    if total_loss == 0:
        return float('inf') if total_profit > 0 else 0.0

    return round(total_profit / total_loss, 3)


# =============================================================================
# ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
# =============================================================================

def run_grid_search(
    grid: Dict[str, List],
    start_date: str,
    end_date: str,
    initial_capital: float,
    use_watchlist: bool,
    parallel: int = 1,
    output_dir: str = "logs/backtest/grid",
) -> List[Dict[str, Any]]:
    """ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰"""

    # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
    combinations = generate_param_combinations(grid)
    total_combos = len(combinations)

    logger.info(f"ğŸ“Š ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹œì‘")
    logger.info(f"   ì´ ì¡°í•© ìˆ˜: {total_combos}")
    logger.info(f"   ë³‘ë ¬ ì²˜ë¦¬: {parallel}ê°œ í”„ë¡œì„¸ìŠ¤")

    results = []

    if parallel > 1:
        # ë³‘ë ¬ ì‹¤í–‰
        with ProcessPoolExecutor(max_workers=parallel) as executor:
            futures = {
                executor.submit(
                    run_single_backtest,
                    params,
                    start_date,
                    end_date,
                    initial_capital,
                    use_watchlist,
                ): params
                for params in combinations
            }

            completed = 0
            for future in as_completed(futures):
                completed += 1
                result = future.result()
                results.append(result)

                if result.get('error'):
                    logger.warning(f"   [{completed}/{total_combos}] ì˜¤ë¥˜: {result['error']}")
                else:
                    logger.info(
                        f"   [{completed}/{total_combos}] "
                        f"ìˆ˜ìµë¥ : {result['total_return_pct']:.2f}%, "
                        f"ìŠ¹ë¥ : {result['win_rate']:.1f}%, "
                        f"MDD: {result['mdd_pct']:.2f}%"
                    )
    else:
        # ìˆœì°¨ ì‹¤í–‰
        for idx, params in enumerate(combinations, 1):
            result = run_single_backtest(
                params,
                start_date,
                end_date,
                initial_capital,
                use_watchlist,
            )
            results.append(result)

            if result.get('error'):
                logger.warning(f"   [{idx}/{total_combos}] ì˜¤ë¥˜: {result['error']}")
            else:
                logger.info(
                    f"   [{idx}/{total_combos}] "
                    f"ìˆ˜ìµë¥ : {result['total_return_pct']:.2f}%, "
                    f"ìŠ¹ë¥ : {result['win_rate']:.1f}%, "
                    f"MDD: {result['mdd_pct']:.2f}%"
                )

    return results


def analyze_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """ê²°ê³¼ ë¶„ì„"""

    # ì˜¤ë¥˜ ì œì™¸
    valid_results = [r for r in results if not r.get('error')]

    if not valid_results:
        return {'error': 'ìœ íš¨í•œ ê²°ê³¼ ì—†ìŒ'}

    # ì •ë ¬ ê¸°ì¤€ë³„ Top 5
    analysis = {
        'total_combinations': len(results),
        'valid_combinations': len(valid_results),
        'error_count': len(results) - len(valid_results),
    }

    # ìˆ˜ìµë¥  ê¸°ì¤€ Top 5
    by_return = sorted(valid_results, key=lambda x: x['total_return_pct'], reverse=True)
    analysis['top5_by_return'] = by_return[:5]

    # ìŠ¹ë¥  ê¸°ì¤€ Top 5
    by_winrate = sorted(valid_results, key=lambda x: x['win_rate'], reverse=True)
    analysis['top5_by_winrate'] = by_winrate[:5]

    # ìƒ¤í”„ ë¹„ìœ¨ ê¸°ì¤€ Top 5
    by_sharpe = sorted(valid_results, key=lambda x: x.get('sharpe_ratio', 0), reverse=True)
    analysis['top5_by_sharpe'] = by_sharpe[:5]

    # MDD ê¸°ì¤€ Top 5 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    by_mdd = sorted(valid_results, key=lambda x: x['mdd_pct'])
    analysis['top5_by_low_mdd'] = by_mdd[:5]

    # Profit Factor ê¸°ì¤€ Top 5
    by_pf = sorted(valid_results, key=lambda x: x.get('profit_factor', 0), reverse=True)
    analysis['top5_by_profit_factor'] = by_pf[:5]

    # ì¢…í•© ì ìˆ˜ (ìˆ˜ìµë¥  * ìŠ¹ë¥  / MDD)
    for r in valid_results:
        mdd = max(r['mdd_pct'], 0.01)  # 0 ë°©ì§€
        r['composite_score'] = (r['total_return_pct'] * r['win_rate']) / mdd

    by_composite = sorted(valid_results, key=lambda x: x['composite_score'], reverse=True)
    analysis['top5_by_composite'] = by_composite[:5]

    # íŒŒë¼ë¯¸í„°ë³„ ì˜í–¥ ë¶„ì„
    analysis['param_impact'] = _analyze_param_impact(valid_results)

    return analysis


def _analyze_param_impact(results: List[Dict[str, Any]]) -> Dict[str, Dict]:
    """íŒŒë¼ë¯¸í„°ë³„ ì˜í–¥ ë¶„ì„"""
    import numpy as np

    impact = {}

    # ê° íŒŒë¼ë¯¸í„°ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ í‰ê·  ìˆ˜ìµë¥  ë¹„êµ
    param_names = [
        'rsi_max_threshold', 'golden_cross_min_volume', 'momentum_threshold',
        'no_trade_end_minutes', 'danger_zone_enabled', 'fixed_stop_loss_pct',
        'trailing_activation_pct', 'trailing_drop_pct', 'scale_out_enabled',
        'rsi_overbought_sell', 'atr_multiplier', 'max_positions', 'position_size_pct'
    ]

    for param_name in param_names:
        # íŒŒë¼ë¯¸í„° ê°’ë³„ ê·¸ë£¹í™”
        groups = {}
        for r in results:
            param_value = r['params'].get(param_name)
            if param_value is not None:
                key = str(param_value)
                if key not in groups:
                    groups[key] = []
                groups[key].append(r['total_return_pct'])

        if groups:
            # ê° ê·¸ë£¹ì˜ í‰ê·  ìˆ˜ìµë¥ 
            group_stats = {}
            for value, returns in groups.items():
                group_stats[value] = {
                    'mean_return': round(np.mean(returns), 3),
                    'count': len(returns),
                }

            impact[param_name] = group_stats

    return impact


def print_analysis(analysis: Dict[str, Any]):
    """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""

    print("\n" + "=" * 70)
    print("ğŸ“Š ê·¸ë¦¬ë“œ ì„œì¹˜ ë¶„ì„ ê²°ê³¼")
    print("=" * 70)

    print(f"\nì´ ì¡°í•©: {analysis['total_combinations']}ê°œ")
    print(f"ìœ íš¨ ê²°ê³¼: {analysis['valid_combinations']}ê°œ")
    print(f"ì˜¤ë¥˜: {analysis['error_count']}ê°œ")

    # Top 5 by Return
    print("\n" + "-" * 70)
    print("ğŸ† ìˆ˜ìµë¥  Top 5")
    print("-" * 70)
    for i, r in enumerate(analysis.get('top5_by_return', []), 1):
        print(f"  {i}. ìˆ˜ìµë¥ : {r['total_return_pct']:+.2f}%, "
              f"ìŠ¹ë¥ : {r['win_rate']:.1f}%, "
              f"MDD: {r['mdd_pct']:.2f}%, "
              f"ê±°ë˜: {r['total_trades']}ê±´")
        _print_key_params(r['params'])

    # Top 5 by Composite Score
    print("\n" + "-" * 70)
    print("ğŸ¯ ì¢…í•© ì ìˆ˜ Top 5 (ìˆ˜ìµë¥  Ã— ìŠ¹ë¥  / MDD)")
    print("-" * 70)
    for i, r in enumerate(analysis.get('top5_by_composite', []), 1):
        print(f"  {i}. ì¢…í•©: {r['composite_score']:.2f}, "
              f"ìˆ˜ìµë¥ : {r['total_return_pct']:+.2f}%, "
              f"ìŠ¹ë¥ : {r['win_rate']:.1f}%, "
              f"MDD: {r['mdd_pct']:.2f}%")
        _print_key_params(r['params'])

    # Top 5 by Sharpe
    print("\n" + "-" * 70)
    print("ğŸ“ˆ ìƒ¤í”„ ë¹„ìœ¨ Top 5")
    print("-" * 70)
    for i, r in enumerate(analysis.get('top5_by_sharpe', []), 1):
        print(f"  {i}. Sharpe: {r.get('sharpe_ratio', 0):.3f}, "
              f"ìˆ˜ìµë¥ : {r['total_return_pct']:+.2f}%, "
              f"MDD: {r['mdd_pct']:.2f}%")

    # íŒŒë¼ë¯¸í„° ì˜í–¥ ë¶„ì„
    print("\n" + "-" * 70)
    print("ğŸ” íŒŒë¼ë¯¸í„°ë³„ í‰ê·  ìˆ˜ìµë¥ ")
    print("-" * 70)

    param_impact = analysis.get('param_impact', {})
    for param_name, stats in param_impact.items():
        print(f"\n  {param_name}:")
        sorted_stats = sorted(stats.items(), key=lambda x: x[1]['mean_return'], reverse=True)
        for value, s in sorted_stats:
            print(f"    {value}: {s['mean_return']:+.2f}% (n={s['count']})")


def _print_key_params(params: dict):
    """í•µì‹¬ íŒŒë¼ë¯¸í„° ì¶œë ¥"""
    print(f"      RSIì°¨ë‹¨={params.get('rsi_max_threshold')}, "
          f"ì†ì ˆ={params.get('fixed_stop_loss_pct')}%, "
          f"TTPí™œì„±={params.get('trailing_activation_pct')}%, "
          f"DangerZone={params.get('danger_zone_enabled')}")


# =============================================================================
# CLI
# =============================================================================

def parse_args():
    parser = argparse.ArgumentParser(description="ë¶„ë´‰ ë°±í…ŒìŠ¤íŠ¸ ê·¸ë¦¬ë“œ ì„œì¹˜")

    parser.add_argument(
        "--start-date",
        type=str,
        default="2025-12-17",
        help="ì‹œì‘ì¼ (YYYY-MM-DD)",
    )
    parser.add_argument(
        "--end-date",
        type=str,
        default=None,
        help="ì¢…ë£Œì¼ (YYYY-MM-DD, ê¸°ë³¸: ì˜¤ëŠ˜)",
    )
    parser.add_argument(
        "--initial-capital",
        type=float,
        default=210_000_000,
        help="ì´ˆê¸° ìë³¸ê¸ˆ (ê¸°ë³¸: 2.1ì–µ)",
    )
    parser.add_argument(
        "--parallel", "-p",
        type=int,
        default=1,
        help="ë³‘ë ¬ ì²˜ë¦¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜ (ê¸°ë³¸: 1)",
    )
    parser.add_argument(
        "--quick", "-q",
        action="store_true",
        help="ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ)",
    )
    parser.add_argument(
        "--minimal", "-m",
        action="store_true",
        help="ìµœì†Œ í…ŒìŠ¤íŠ¸ (ê°€ì¥ í•µì‹¬ë§Œ)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="logs/backtest/grid",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬",
    )

    return parser.parse_args()


def main():
    args = parse_args()

    # ì¢…ë£Œì¼ ê¸°ë³¸ê°’
    if args.end_date:
        end_date = args.end_date
    else:
        end_date = datetime.now().strftime("%Y-%m-%d")

    # ê·¸ë¦¬ë“œ ì„ íƒ
    if args.minimal:
        grid = MINIMAL_GRID
        grid_name = "MINIMAL"
    elif args.quick:
        grid = QUICK_GRID
        grid_name = "QUICK"
    else:
        grid = FULL_GRID
        grid_name = "FULL"

    # ì¡°í•© ìˆ˜ ê³„ì‚°
    total_combos = 1
    for values in grid.values():
        total_combos *= len(values)

    logger.info("=" * 70)
    logger.info("ğŸ“Š ë¶„ë´‰ ë°±í…ŒìŠ¤íŠ¸ ê·¸ë¦¬ë“œ ì„œì¹˜")
    logger.info("=" * 70)
    logger.info(f"   ê·¸ë¦¬ë“œ ëª¨ë“œ: {grid_name}")
    logger.info(f"   ê¸°ê°„: {args.start_date} ~ {end_date}")
    logger.info(f"   ì´ˆê¸° ìë³¸: {args.initial_capital:,.0f}ì›")
    logger.info(f"   ì´ ì¡°í•© ìˆ˜: {total_combos}ê°œ")
    logger.info(f"   ë³‘ë ¬ ì²˜ë¦¬: {args.parallel}ê°œ í”„ë¡œì„¸ìŠ¤")

    # ì˜ˆìƒ ì‹œê°„ (ì¡°í•©ë‹¹ ~40ì´ˆ ê°€ì •)
    est_time = total_combos * 40 / max(args.parallel, 1)
    logger.info(f"   ì˜ˆìƒ ì†Œìš” ì‹œê°„: ~{est_time/60:.0f}ë¶„")

    # ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰
    results = run_grid_search(
        grid=grid,
        start_date=args.start_date,
        end_date=end_date,
        initial_capital=args.initial_capital,
        use_watchlist=True,
        parallel=args.parallel,
        output_dir=args.output_dir,
    )

    # ê²°ê³¼ ë¶„ì„
    analysis = analyze_results(results)

    # ê²°ê³¼ ì¶œë ¥
    print_analysis(analysis)

    # ê²°ê³¼ ì €ì¥
    os.makedirs(args.output_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ì „ì²´ ê²°ê³¼ JSON
    results_path = os.path.join(args.output_dir, f"grid_results_{timestamp}.json")
    with open(results_path, 'w', encoding='utf-8') as f:
        json.dump({
            'config': {
                'grid_mode': grid_name,
                'start_date': args.start_date,
                'end_date': end_date,
                'initial_capital': args.initial_capital,
                'total_combinations': total_combos,
            },
            'results': results,
            'analysis': {
                k: v for k, v in analysis.items()
                if k not in ['top5_by_return', 'top5_by_winrate', 'top5_by_sharpe',
                            'top5_by_low_mdd', 'top5_by_profit_factor', 'top5_by_composite']
            },
            'top_results': {
                'by_return': analysis.get('top5_by_return', []),
                'by_composite': analysis.get('top5_by_composite', []),
                'by_sharpe': analysis.get('top5_by_sharpe', []),
            },
        }, f, ensure_ascii=False, indent=2)

    logger.info(f"\nğŸ“ ê²°ê³¼ ì €ì¥: {results_path}")

    # CSV ìš”ì•½
    csv_path = os.path.join(args.output_dir, f"grid_summary_{timestamp}.csv")
    with open(csv_path, 'w', newline='', encoding='utf-8') as f:
        if results:
            # ìœ íš¨í•œ ê²°ê³¼ë§Œ í•„í„°ë§
            valid_results = [r for r in results if not r.get('error')]
            if valid_results:
                # ë™ì ìœ¼ë¡œ ëª¨ë“  íŒŒë¼ë¯¸í„° í¬í•¨
                all_param_keys = set()
                for r in valid_results:
                    all_param_keys.update(r['params'].keys())

                fieldnames = [
                    'total_return_pct', 'win_rate', 'mdd_pct', 'total_trades',
                    'sharpe_ratio', 'profit_factor', 'final_capital',
                ] + sorted(all_param_keys)

                writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
                writer.writeheader()

                for r in sorted(valid_results, key=lambda x: x['total_return_pct'], reverse=True):
                    row = {
                        'total_return_pct': r['total_return_pct'],
                        'win_rate': r['win_rate'],
                        'mdd_pct': r['mdd_pct'],
                        'total_trades': r['total_trades'],
                        'sharpe_ratio': r.get('sharpe_ratio', 0),
                        'profit_factor': r.get('profit_factor', 0),
                        'final_capital': r['final_capital'],
                        **r['params'],
                    }
                    writer.writerow(row)

    logger.info(f"ğŸ“ CSV ìš”ì•½: {csv_path}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
