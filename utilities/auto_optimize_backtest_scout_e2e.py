#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
auto_optimize_backtest_scout_e2e.py
-----------------------------------

`backtest_scout_e2e.py` íŒŒë¼ë¯¸í„°ë¥¼ Grid ë°©ì‹ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰í•´
ê°€ì¥ ì¢‹ì€ ì„±ê³¼(ê³ ìˆ˜ìµ/ì €MDD)ë¥¼ ë‚´ëŠ” ì¡°í•©ì„ íƒìƒ‰í•˜ëŠ” ìœ í‹¸ë¦¬í‹°.

- ProcessPoolExecutorë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì‹¤í–‰
- ì´ë¯¸ í…ŒìŠ¤íŠ¸í•œ ì¡°í•© ìŠ¤í‚µ (Resume ê¸°ëŠ¥)
- ì ìˆ˜ ê¸°ë°˜ ë­í‚¹ ë° ê²°ê³¼ ì €ì¥
"""

from __future__ import annotations

import argparse
import itertools
import json
import logging
import os
import random
import re
import subprocess
import sys
import time
import uuid
from concurrent.futures import ProcessPoolExecutor, as_completed
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
BACKTEST_SCRIPT = os.path.join(PROJECT_ROOT, "utilities", "backtest_scout_e2e.py")
DEFAULT_LOG_DIR = os.path.join(PROJECT_ROOT, "logs")

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("scout_e2e_optimizer")


# ---------------------------------------------------------------------------
# íŠœë‹ ëŒ€ìƒ íŒŒë¼ë¯¸í„° (Scout E2E ë°±í…ŒìŠ¤íŠ¸ì— ì˜í–¥ì´ í° í•­ëª©ë“¤)
# ---------------------------------------------------------------------------

PARAMETER_GRID = {
    # === ê³ ì • (ì ìˆ˜ ê¸°ì¤€) ===
    "scout_min_score": [70],                      # ì ìˆ˜ ìœ ì§€
    
    # === í…ŒìŠ¤íŠ¸: ê±°ë˜ ì œí•œ ===
    "daily_buy_limit": [3, 5, 8, 99],             # 99 = ë¬´ì œí•œ
    "max_portfolio_size": [10, 15, 20, 30],       # í¬íŠ¸í´ë¦¬ì˜¤ í¬ê¸°
    
    # === ë‚˜ë¨¸ì§€ ê³ ì • ===
    "scout_top_n": [20],
    "max_stock_pct": [0.12],
    "target_profit_pct": [0.10],
    "stop_loss_pct": [0.07],
    "buy_signal_threshold": [70],
}

# íŒŒë¼ë¯¸í„°ë³„ ì„¤ëª… (ë¡œê·¸ìš©)
PARAM_DESCRIPTIONS = {
    "scout_min_score": "Scout í†µê³¼ ìµœì†Œ ì ìˆ˜",
    "scout_top_n": "Hot Watchlist í¬ê¸°",
    "min_llm_score": "Buy Executor ìµœì†Œ LLM ì ìˆ˜",
    "daily_buy_limit": "ì¼ì¼ ë§¤ìˆ˜ í•œë„",
    "max_portfolio_size": "ìµœëŒ€ í¬íŠ¸í´ë¦¬ì˜¤ í¬ê¸°",
    "max_stock_pct": "ì¢…ëª©ë‹¹ ìµœëŒ€ ë¹„ì¤‘",
    "target_profit_pct": "ëª©í‘œ ìˆ˜ìµë¥ ",
    "stop_loss_pct": "ì†ì ˆ ë¹„ìœ¨",
    "buy_signal_threshold": "ë§¤ìˆ˜ ì‹ í˜¸ íŠ¸ë¦¬ê±° ì ìˆ˜",
}


# ---------------------------------------------------------------------------
# ê²°ê³¼ íŒŒì‹± & ì ìˆ˜í™”
# ---------------------------------------------------------------------------

def parse_backtest_output(output: str) -> Dict[str, Optional[float]]:
    """backtest_scout_e2e.py stdoutì—ì„œ ì§€í‘œë¥¼ ì¶”ì¶œ."""
    result = {
        "success": False,
        "total_return_pct": None,
        "mdd_pct": None,
        "final_equity": None,
        "total_trades": None,
    }

    def _extract(pattern: str) -> Optional[float]:
        m = re.search(pattern, output)
        return float(m.group(1)) if m else None

    result["total_return_pct"] = _extract(r"ì´ ìˆ˜ìµë¥ :\s*([\-0-9.]+)%")
    result["mdd_pct"] = _extract(r"ìµœëŒ€ ë‚™í­:\s*([\-0-9.]+)%")
    result["total_trades"] = _extract(r"ì´ ê±°ë˜:\s*(\d+)ê±´")
    
    equity_match = re.search(r"ìµœì¢… ìì‚°:\s*([0-9,]+)ì›", output)
    if equity_match:
        result["final_equity"] = float(equity_match.group(1).replace(",", ""))

    result["success"] = result["total_return_pct"] is not None and result["mdd_pct"] is not None
    return result


def score_result(result: Dict[str, Optional[float]]) -> float:
    """
    ìˆ˜ìµë¥ ì„ ë†’ì´ê³  MDDëŠ” ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°.
    
    ì ìˆ˜ ê³µì‹:
    - ì´ ìˆ˜ìµë¥  Ã— 5 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
    - MDD Ã— 4 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, íŒ¨ë„í‹°)
    - MDD > 15% ì´ë©´ ì¶”ê°€ íŒ¨ë„í‹°
    - ê±°ë˜ íšŸìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´(<10) íŒ¨ë„í‹°
    """
    if not result["success"]:
        return -1e6

    total_return = result["total_return_pct"] or 0.0
    mdd = result["mdd_pct"] or 0.0
    trades = result["total_trades"] or 0

    # ê¸°ë³¸ ì ìˆ˜: ìˆ˜ìµë¥  ê°€ì¤‘ - MDD íŒ¨ë„í‹°
    score = total_return * 5.0 - mdd * 4.0

    # MDDê°€ 15%ë¥¼ ë„˜ì–´ê°€ë©´ ê°•í•œ íŒ¨ë„í‹°
    if mdd > 15.0:
        score -= (mdd - 15.0) * 10.0

    # ê±°ë˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í†µê³„ì ìœ¼ë¡œ ì‹ ë¢°ë„ ë‚®ìŒ
    if trades < 10:
        score -= 50.0
    elif trades < 30:
        score -= 20.0
    
    # ìˆ˜ìµë¥ ì´ ìŒìˆ˜ì´ë©´ ì¶”ê°€ íŒ¨ë„í‹°
    if total_return < 0:
        score -= abs(total_return) * 3.0

    return score


# ---------------------------------------------------------------------------
# ë‹¨ì¼ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì„œë¸Œ í”„ë¡œì„¸ìŠ¤)
# ---------------------------------------------------------------------------

def run_single_backtest(params: Dict[str, float], args: argparse.Namespace) -> Dict:
    unique_id = uuid.uuid4().hex[:8]
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    
    log_dir = os.path.join(PROJECT_ROOT, "logs", "opt_scout_e2e")
    os.makedirs(log_dir, exist_ok=True)
    log_file_path = os.path.join(log_dir, f"backtest_{timestamp}_{unique_id}.log")

    cmd = [
        sys.executable,
        BACKTEST_SCRIPT,
        "--start-date", args.start_date,
        "--end-date", args.end_date,
        "--capital", str(args.capital),
    ]

    # íŒŒë¼ë¯¸í„° ì¶”ê°€
    for key, value in params.items():
        cmd.append(f"--{key.replace('_', '-')}")
        cmd.append(str(value))

    try:
        started = time.time()
        with open(log_file_path, "w", encoding="utf-8") as log_file:
            proc = subprocess.run(
                cmd,
                stdout=log_file,
                stderr=subprocess.STDOUT,
                cwd=PROJECT_ROOT,
                timeout=args.timeout,
            )
        elapsed = time.time() - started

        if os.path.exists(log_file_path):
            with open(log_file_path, "r", encoding="utf-8", errors="replace") as f:
                output = f.read()
        else:
            output = ""

        if proc.returncode != 0:
            return {"success": False, "error": f"Process failed (code {proc.returncode})", "params": params}

        metrics = parse_backtest_output(output)
        metrics["params"] = params
        metrics["elapsed"] = elapsed
        metrics["score"] = score_result(metrics)
        return metrics

    except subprocess.TimeoutExpired:
        return {"success": False, "error": "Timeout", "params": params}
    except Exception as exc:
        return {"success": False, "error": str(exc), "params": params}


# ---------------------------------------------------------------------------
# Optimizer ë³¸ì²´
# ---------------------------------------------------------------------------

@dataclass
class OptimizationResult:
    params: Dict[str, float]
    total_return_pct: float
    mdd_pct: float
    total_trades: int
    score: float
    elapsed: float = field(default=0.0)


class ScoutE2EOptimizer:
    def __init__(self, args: argparse.Namespace):
        self.args = args
        self.results: List[OptimizationResult] = []
        self.best_result: Optional[OptimizationResult] = None
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.history_file = os.path.join(PROJECT_ROOT, f"scout_e2e_opt_results_{timestamp}.json")
        
        if self.args.resume:
            self.history_file = self.args.resume
            self._load_history()
        
        self.summary_dir = os.path.join(DEFAULT_LOG_DIR, "optimize_summary")
        os.makedirs(self.summary_dir, exist_ok=True)

    def _load_history(self):
        if not os.path.exists(self.history_file):
            logger.warning(f"Resume íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.history_file}")
            return

        try:
            with open(self.history_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            for entry in data.get("results", []):
                res = OptimizationResult(
                    params=entry["params"],
                    total_return_pct=entry["total_return_pct"],
                    mdd_pct=entry["mdd_pct"],
                    total_trades=entry.get("total_trades", 0),
                    score=entry["score"],
                    elapsed=entry.get("elapsed", 0.0)
                )
                self.results.append(res)
                
                if self.best_result is None or res.score > self.best_result.score:
                    self.best_result = res
            
            logger.info(f"ğŸ”„ ì´ì „ ê²°ê³¼ {len(self.results)}ê°œ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì´ë ¥ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _should_skip(self, params: Dict[str, float]) -> bool:
        for res in self.results:
            if res.params == params:
                return True
        return False

    def _save_results(self):
        payload = {
            "timestamp": datetime.now().isoformat(),
            "args": {
                "start_date": self.args.start_date,
                "end_date": self.args.end_date,
                "capital": self.args.capital,
            },
            "results": [r.__dict__ for r in self.results],
            "best": self.best_result.__dict__ if self.best_result else None,
        }
        with open(self.history_file, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
        self._write_summary()

    def _write_summary(self):
        if not self.results:
            return
        sorted_results = sorted(self.results, key=lambda r: r.score, reverse=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_path = os.path.join(self.summary_dir, f"scout_e2e_opt_summary_{timestamp}.txt")
        latest_path = os.path.join(self.summary_dir, "scout_e2e_opt_summary_latest.txt")

        lines = []
        lines.append("=== Scout E2E Optimization Summary ===")
        lines.append(f"ìƒì„± ì‹œê°: {datetime.now().isoformat()}")
        lines.append(f"ê¸°ê°„: {self.args.start_date} ~ {self.args.end_date}")
        lines.append(f"ì´ í…ŒìŠ¤íŠ¸ ì¡°í•©: {len(self.results)}")
        
        if sorted_results:
            best = sorted_results[0]
            lines.append("")
            lines.append("ğŸ… Best Combination")
            lines.append(
                f"- Score {best.score:.2f} | ìˆ˜ìµë¥  {best.total_return_pct:.2f}% | "
                f"MDD {best.mdd_pct:.2f}% | ê±°ë˜ {best.total_trades}ê±´ | "
                f"ì†Œìš”ì‹œê°„ {best.elapsed:.1f}s"
            )
            lines.append(f"- Params: {json.dumps(best.params, ensure_ascii=False)}")

        lines.append("")
        lines.append("Top 10 Results")
        for idx, entry in enumerate(sorted_results[:10], start=1):
            lines.append(
                f"{idx:02d}. Score {entry.score:.2f} | ìˆ˜ìµë¥  {entry.total_return_pct:.2f}% | "
                f"MDD {entry.mdd_pct:.2f}% | ê±°ë˜ {entry.total_trades}ê±´"
            )
            lines.append(f"    Params: {json.dumps(entry.params, ensure_ascii=False)}")

        text = "\n".join(lines)
        with open(summary_path, "w", encoding="utf-8") as f:
            f.write(text)
        with open(latest_path, "w", encoding="utf-8") as f:
            f.write(text)
        logger.info("ğŸ“ ìš”ì•½ íŒŒì¼ ìƒì„±: %s", summary_path)

    def generate_param_sets(self) -> List[Dict[str, float]]:
        # ì§€ì •ëœ íŒŒë¼ë¯¸í„°ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ì „ì²´ Grid ì‚¬ìš©
        if self.args.quick:
            # Quick ëª¨ë“œ: í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ
            grid = {
                "scout_min_score": [60, 70, 80],
                "target_profit_pct": [0.10, 0.15, 0.20],
                "stop_loss_pct": [0.05, 0.07],
            }
        else:
            grid = PARAMETER_GRID

        param_names = list(grid.keys())
        param_values = list(grid.values())

        combinations = []
        for combo in itertools.product(*param_values):
            params = dict(zip(param_names, combo))
            if not self._should_skip(params):
                combinations.append(params)

        if not combinations:
            logger.info("ì´ë¯¸ ëª¨ë“  ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í–ˆìŠµë‹ˆë‹¤.")
            return []

        if len(combinations) > self.args.max_combinations:
            combinations = random.sample(combinations, self.args.max_combinations)

        random.shuffle(combinations)
        
        logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸í•  ì¡°í•©: {len(combinations)}ê°œ")
        return combinations

    def run(self):
        combos = self.generate_param_sets()
        if not combos:
            return

        cpu_count = os.cpu_count() or 8
        max_workers = min(self.args.max_workers, max(1, cpu_count // 2))
        logger.info(
            f"ğŸš€ Grid ìµœì í™” ì‹œì‘: ì¡°í•© {len(combos)}ê°œ / ë³‘ë ¬ worker {max_workers}ê°œ"
        )

        completed = 0
        total_tasks = len(combos)

        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(run_single_backtest, params, self.args): params
                for params in combos
            }

            for future in as_completed(futures):
                completed += 1
                result = future.result()
                
                progress_str = f"({completed}/{total_tasks})"
                
                if result["success"]:
                    res_obj = OptimizationResult(
                        params=result["params"],
                        total_return_pct=result["total_return_pct"],
                        mdd_pct=result["mdd_pct"],
                        total_trades=int(result.get("total_trades") or 0),
                        score=result["score"],
                        elapsed=result.get("elapsed", 0),
                    )
                    self.results.append(res_obj)
                    self._save_results()

                    if self.best_result is None or res_obj.score > self.best_result.score:
                        self.best_result = res_obj
                        logger.info(
                            f"{progress_str} âœ… ìƒˆë¡œìš´ ìµœê³  ì ìˆ˜! ìˆ˜ìµë¥  {res_obj.total_return_pct:.2f}% / "
                            f"MDD {res_obj.mdd_pct:.2f}% / ì ìˆ˜ {res_obj.score:.2f}"
                        )
                    else:
                        logger.info(
                            f"{progress_str} â„¹ï¸ ì™„ë£Œ (ì ìˆ˜ {res_obj.score:.2f}, ìˆ˜ìµë¥  {res_obj.total_return_pct:.2f}%)"
                        )
                else:
                    logger.warning(f"{progress_str} âŒ ì‹¤íŒ¨ - {result.get('error', 'Unknown')}")

        if not self.results:
            logger.info("ìœ íš¨í•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        # ìµœì¢… ìš”ì•½ ì¶œë ¥
        logger.info("=" * 60)
        if self.best_result:
            logger.info("ğŸ¯ ìµœì  ì¡°í•© ë°œê²¬!")
            logger.info(f"   ìˆ˜ìµë¥ : {self.best_result.total_return_pct:.2f}%")
            logger.info(f"   MDD: {self.best_result.mdd_pct:.2f}%")
            logger.info(f"   ì ìˆ˜: {self.best_result.score:.2f}")
            logger.info(f"   ê±°ë˜: {self.best_result.total_trades}ê±´")
            logger.info(f"   íŒŒë¼ë¯¸í„°: {json.dumps(self.best_result.params, ensure_ascii=False, indent=2)}")
        logger.info("=" * 60)


# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def build_parser() -> argparse.ArgumentParser:
    # ê¸°ë³¸ê°’: ìµœê·¼ 6ê°œì›”
    from datetime import datetime, timedelta
    default_end = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d")  # ì–´ì œ
    default_start = (datetime.now() - timedelta(days=180)).strftime("%Y-%m-%d")  # 6ê°œì›” ì „
    
    parser = argparse.ArgumentParser(description="Scout E2E ë°±í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„° ìë™ ìµœì í™”")
    parser.add_argument("--start-date", type=str, default=default_start, help=f"ì‹œì‘ì¼ (ê¸°ë³¸: {default_start})")
    parser.add_argument("--end-date", type=str, default=default_end, help=f"ì¢…ë£Œì¼ (ê¸°ë³¸: {default_end})")
    parser.add_argument("--capital", type=float, default=10_000_000, help="ì´ˆê¸° ìë³¸ê¸ˆ")
    parser.add_argument("--max-combinations", type=int, default=50, help="ìµœëŒ€ í…ŒìŠ¤íŠ¸ ì¡°í•© ìˆ˜")
    parser.add_argument("--max-workers", type=int, default=max(1, (os.cpu_count() or 8) // 2), help="ë³‘ë ¬ í”„ë¡œì„¸ìŠ¤ ìˆ˜")
    parser.add_argument("--resume", type=str, default=None, help="ì´ì „ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ì´ì–´í•˜ê¸°)")
    parser.add_argument("--timeout", type=int, default=900, help="ê° ë°±í…ŒìŠ¤íŠ¸ íƒ€ì„ì•„ì›ƒ(ì´ˆ)")
    parser.add_argument("--quick", action="store_true", help="Quick ëª¨ë“œ (í•µì‹¬ íŒŒë¼ë¯¸í„°ë§Œ)")
    return parser


def main():
    args = build_parser().parse_args()
    optimizer = ScoutE2EOptimizer(args)
    optimizer.run()


if __name__ == "__main__":
    main()
