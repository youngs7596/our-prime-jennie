
# -------------------------------------------------------------------------
# Database Configuration (Local Execution -> Docker Container)
# -------------------------------------------------------------------------
MARIADB_HOST=127.0.0.1
MARIADB_PORT=3307
MARIADB_USER=jennie
MARIADB_PASSWORD=q1w2e3R$
MARIADB_DBNAME=jennie_db

# -------------------------------------------------------------------------
# LLM Configuration
# -------------------------------------------------------------------------
# Hybrid LLM Tier Configuration
# FAST: Local Qwen 2.5 3B (Sentiment / Fast Checks)
TIER_FAST_PROVIDER=ollama
LOCAL_MODEL_FAST=qwen2.5:3b

# REASONING: Local Qwen 2.5 14B (Hunter / Analysis)
TIER_REASONING_PROVIDER=ollama
LOCAL_MODEL_REASONING=qwen2.5:14b

# THINKING: Cloud OpenAI/Claude (Judge / Daily Briefing) -> High Quality
TIER_THINKING_PROVIDER=openai
LOCAL_MODEL_THINKING=deepseek-r1:32b # Fallback or Opt-in

# Ollama Host 
# Script running locally needs access to localhost port mapped from container
# Docker internal: http://ollama:11434
# Localhost: http://127.0.0.1:11434
OLLAMA_HOST=http://127.0.0.1:11434

# Global Switch
USE_LOCAL_LLM=true
