#!/usr/bin/env python3
"""
DB ì¸ë±ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

MariaDB í…Œì´ë¸”ì— í•„ìˆ˜ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
- ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„ì„ í†µí•´ ì‹ë³„ëœ ì¸ë±ìŠ¤ë“¤
- ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì¸ë±ìŠ¤ëŠ” ê±´ë„ˆëœë‹ˆë‹¤

ì‹¤í–‰: python scripts/migrate_create_indexes.py [--dry-run]
"""

import argparse
import logging
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from shared.db.connection import init_engine, get_engine, session_scope
from sqlalchemy import text

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# ============================================================================
# ì¸ë±ìŠ¤ ì •ì˜ (í…Œì´ë¸”ëª…, ì¸ë±ìŠ¤ëª…, ì»¬ëŸ¼)
# ============================================================================
INDEXES_TO_CREATE = [
    # ---------------------------------------------------------
    # í•µì‹¬ í…Œì´ë¸” (ë§¤ë§¤/í¬íŠ¸í´ë¦¬ì˜¤)
    # ---------------------------------------------------------

    # TRADELOG - ê±°ë˜ ë‚´ì—­ (ìì£¼ ì¡°íšŒ)
    ("TRADELOG", "ix_tradelog_trade_timestamp", "TRADE_TIMESTAMP"),
    ("TRADELOG", "ix_tradelog_stock_code", "STOCK_CODE"),
    ("TRADELOG", "ix_tradelog_trade_type", "TRADE_TYPE"),

    # WATCHLIST - ê´€ì‹¬ ì¢…ëª© (ì •ë ¬/í•„í„°ë§)
    ("WATCHLIST", "ix_watchlist_llm_score", "LLM_SCORE"),
    ("WATCHLIST", "ix_watchlist_is_tradable", "IS_TRADABLE"),
    ("WATCHLIST", "ix_watchlist_trade_tier", "TRADE_TIER"),

    # AGENT_COMMANDS - ëª…ë ¹ í (ìƒíƒœ ê¸°ë°˜ ì¡°íšŒ)
    ("AGENT_COMMANDS", "ix_agent_commands_status", "STATUS"),
    ("AGENT_COMMANDS", "ix_agent_commands_requested_by", "REQUESTED_BY"),
    ("AGENT_COMMANDS", "ix_agent_commands_created_at", "CREATED_AT"),

    # ---------------------------------------------------------
    # ê°€ê²© ë°ì´í„° í…Œì´ë¸”
    # ---------------------------------------------------------

    # STOCK_DAILY_PRICES_3Y - ì¼ë´‰ (ë‚ ì§œ ë²”ìœ„ ì¿¼ë¦¬)
    ("STOCK_DAILY_PRICES_3Y", "ix_daily_prices_price_date", "PRICE_DATE"),

    # STOCK_MINUTE_PRICE - ë¶„ë´‰ (ì‹œê°„ ë²”ìœ„ ì¿¼ë¦¬)
    ("STOCK_MINUTE_PRICE", "ix_minute_price_stock_code", "STOCK_CODE"),

    # ---------------------------------------------------------
    # ë‰´ìŠ¤/ê°ì„± í…Œì´ë¸”
    # ---------------------------------------------------------

    # NEWS_SENTIMENT - ë‰´ìŠ¤ ê°ì„± ë¶„ì„
    ("NEWS_SENTIMENT", "ix_news_sentiment_stock_code", "STOCK_CODE"),
    ("NEWS_SENTIMENT", "ix_news_sentiment_published_at", "PUBLISHED_AT"),
    ("NEWS_SENTIMENT", "ix_news_sentiment_created_at", "CREATED_AT"),

    # STOCK_NEWS_SENTIMENT - ì¢…ëª©ë³„ ë‰´ìŠ¤ ê°ì„±
    ("STOCK_NEWS_SENTIMENT", "ix_stock_news_stock_code", "STOCK_CODE"),
    ("STOCK_NEWS_SENTIMENT", "ix_stock_news_news_date", "NEWS_DATE"),

    # ---------------------------------------------------------
    # ìˆ˜ê¸‰/íˆ¬ìì í…Œì´ë¸”
    # ---------------------------------------------------------

    # STOCK_INVESTOR_TRADING - íˆ¬ììë³„ ë§¤ë§¤ ë™í–¥
    ("STOCK_INVESTOR_TRADING", "ix_investor_stock_code", "STOCK_CODE"),
    ("STOCK_INVESTOR_TRADING", "ix_investor_trade_date", "TRADE_DATE"),

    # MARKET_FLOW_SNAPSHOT - ì‹œì¥ íë¦„
    ("MARKET_FLOW_SNAPSHOT", "ix_market_flow_stock_code", "STOCK_CODE"),
    ("MARKET_FLOW_SNAPSHOT", "ix_market_flow_timestamp", "TIMESTAMP"),
    ("MARKET_FLOW_SNAPSHOT", "ix_market_flow_data_type", "DATA_TYPE"),

    # ---------------------------------------------------------
    # ë§¤í¬ë¡œ/ì¸ì‚¬ì´íŠ¸ í…Œì´ë¸”
    # ---------------------------------------------------------

    # DAILY_MACRO_INSIGHT - ë§¤í¬ë¡œ ì¸ì‚¬ì´íŠ¸
    ("DAILY_MACRO_INSIGHT", "ix_macro_insight_date", "INSIGHT_DATE"),

    # ---------------------------------------------------------
    # LLM/AI ì˜ì‚¬ê²°ì • í…Œì´ë¸”
    # ---------------------------------------------------------

    # LLM_DECISION_LEDGER - LLM ì˜ì‚¬ê²°ì • ê¸°ë¡
    ("LLM_DECISION_LEDGER", "ix_llm_ledger_stock_code", "STOCK_CODE"),
    ("LLM_DECISION_LEDGER", "ix_llm_ledger_timestamp", "TIMESTAMP"),
    ("LLM_DECISION_LEDGER", "ix_llm_ledger_final_decision", "FINAL_DECISION"),

    # SHADOW_RADAR_LOG - ë†“ì¹œ ê¸°íšŒ ë¶„ì„
    ("SHADOW_RADAR_LOG", "ix_shadow_radar_stock_code", "STOCK_CODE"),
    ("SHADOW_RADAR_LOG", "ix_shadow_radar_timestamp", "TIMESTAMP"),

    # ---------------------------------------------------------
    # íŒ©í„°/ìŠ¤ì½”ì–´ë§ í…Œì´ë¸”
    # ---------------------------------------------------------

    # DAILY_QUANT_SCORE - ì¼ë³„ ì •ëŸ‰ ì ìˆ˜
    ("DAILY_QUANT_SCORE", "ix_quant_score_stock_code", "STOCK_CODE"),
    ("DAILY_QUANT_SCORE", "ix_quant_score_score_date", "SCORE_DATE"),
    ("DAILY_QUANT_SCORE", "ix_quant_score_is_passed", "IS_PASSED_FILTER"),

    # FINANCIAL_METRICS_QUARTERLY - ë¶„ê¸°ë³„ ì¬ë¬´ì§€í‘œ
    ("FINANCIAL_METRICS_QUARTERLY", "ix_fin_metrics_stock_code", "STOCK_CODE"),
    ("FINANCIAL_METRICS_QUARTERLY", "ix_fin_metrics_quarter_date", "QUARTER_DATE"),

    # FACTOR_METADATA - íŒ©í„° ë©”íƒ€ë°ì´í„°
    ("FACTOR_METADATA", "ix_factor_meta_factor_key", "FACTOR_KEY"),
    ("FACTOR_METADATA", "ix_factor_meta_market_regime", "MARKET_REGIME"),

    # FACTOR_PERFORMANCE - íŒ©í„° ì„±ê³¼
    ("FACTOR_PERFORMANCE", "ix_factor_perf_target_code", "TARGET_CODE"),
    ("FACTOR_PERFORMANCE", "ix_factor_perf_condition_key", "CONDITION_KEY"),

    # ---------------------------------------------------------
    # ê³µì‹œ/ê¸°íƒ€ í…Œì´ë¸”
    # ---------------------------------------------------------

    # STOCK_DISCLOSURES - ê³µì‹œ
    ("STOCK_DISCLOSURES", "ix_disclosures_stock_code", "STOCK_CODE"),
    ("STOCK_DISCLOSURES", "ix_disclosures_disclosure_date", "DISCLOSURE_DATE"),

    # WATCHLIST_HISTORY - ê´€ì‹¬ì¢…ëª© íˆìŠ¤í† ë¦¬
    ("WATCHLIST_HISTORY", "ix_watchlist_hist_snapshot_date", "SNAPSHOT_DATE"),

    # BACKTEST_TRADELOG - ë°±í…ŒìŠ¤íŠ¸ ê±°ë˜ ë‚´ì—­
    ("BACKTEST_TRADELOG", "ix_backtest_trade_date", "TRADE_DATE"),
    ("BACKTEST_TRADELOG", "ix_backtest_stock_code", "STOCK_CODE"),

    # ---------------------------------------------------------
    # ê²½ìŸì‚¬/ì„¹í„° ë¶„ì„ í…Œì´ë¸”
    # ---------------------------------------------------------

    # INDUSTRY_COMPETITORS - ì‚°ì—…/ê²½ìŸì‚¬ ë§¤í•‘
    ("INDUSTRY_COMPETITORS", "ix_competitors_sector_code", "SECTOR_CODE"),
    ("INDUSTRY_COMPETITORS", "ix_competitors_stock_code", "STOCK_CODE"),
    ("INDUSTRY_COMPETITORS", "ix_competitors_is_active", "IS_ACTIVE"),

    # SECTOR_RELATION_STATS - ì„¹í„° ê´€ê³„ í†µê³„
    ("SECTOR_RELATION_STATS", "ix_sector_rel_sector_code", "SECTOR_CODE"),
    ("SECTOR_RELATION_STATS", "ix_sector_rel_leader_code", "LEADER_STOCK_CODE"),
    ("SECTOR_RELATION_STATS", "ix_sector_rel_follower_code", "FOLLOWER_STOCK_CODE"),

    # COMPETITOR_BENEFIT_EVENTS - ê²½ìŸì‚¬ ìˆ˜í˜œ ì´ë²¤íŠ¸
    ("COMPETITOR_BENEFIT_EVENTS", "ix_benefit_events_affected", "AFFECTED_STOCK_CODE"),
    ("COMPETITOR_BENEFIT_EVENTS", "ix_benefit_events_beneficiary", "BENEFICIARY_STOCK_CODE"),
    ("COMPETITOR_BENEFIT_EVENTS", "ix_benefit_events_status", "STATUS"),

    # ---------------------------------------------------------
    # ìì‚° ìŠ¤ëƒ…ìƒ·
    # ---------------------------------------------------------

    # DAILY_ASSET_SNAPSHOT - ì¼ë³„ ìì‚° ìŠ¤ëƒ…ìƒ· (PKê°€ snapshot_dateì´ë¯€ë¡œ ì¶”ê°€ ì¸ë±ìŠ¤ ë¶ˆí•„ìš”)
]

# ë³µí•© ì¸ë±ìŠ¤ (ìì£¼ í•¨ê»˜ ì¡°íšŒë˜ëŠ” ì»¬ëŸ¼ ì¡°í•©)
COMPOSITE_INDEXES = [
    # (í…Œì´ë¸”ëª…, ì¸ë±ìŠ¤ëª…, (ì»¬ëŸ¼1, ì»¬ëŸ¼2, ...))
    ("STOCK_INVESTOR_TRADING", "ix_investor_stock_date", ("STOCK_CODE", "TRADE_DATE")),
    ("STOCK_NEWS_SENTIMENT", "ix_stock_news_stock_date", ("STOCK_CODE", "NEWS_DATE")),
    ("DAILY_QUANT_SCORE", "ix_quant_score_date_stock", ("SCORE_DATE", "STOCK_CODE")),
    ("FINANCIAL_METRICS_QUARTERLY", "ix_fin_metrics_stock_quarter", ("STOCK_CODE", "QUARTER_DATE")),
    ("TRADELOG", "ix_tradelog_stock_timestamp", ("STOCK_CODE", "TRADE_TIMESTAMP")),
]


def get_existing_indexes(engine) -> set:
    """í˜„ì¬ DBì— ì¡´ì¬í•˜ëŠ” ì¸ë±ìŠ¤ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    existing = set()

    with engine.connect() as conn:
        # MariaDB: information_schemaì—ì„œ ì¸ë±ìŠ¤ ì¡°íšŒ
        result = conn.execute(text("""
            SELECT DISTINCT INDEX_NAME
            FROM information_schema.STATISTICS
            WHERE TABLE_SCHEMA = DATABASE()
        """))
        for row in result:
            existing.add(row[0].upper())

    return existing


def get_existing_tables(engine) -> set:
    """í˜„ì¬ DBì— ì¡´ì¬í•˜ëŠ” í…Œì´ë¸” ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    tables = set()

    with engine.connect() as conn:
        result = conn.execute(text("""
            SELECT TABLE_NAME
            FROM information_schema.TABLES
            WHERE TABLE_SCHEMA = DATABASE()
        """))
        for row in result:
            tables.add(row[0].upper())

    return tables


def get_table_row_counts(engine, tables: list) -> dict:
    """í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤."""
    counts = {}

    with engine.connect() as conn:
        for table in tables:
            try:
                result = conn.execute(text(f"SELECT COUNT(*) FROM `{table}`"))
                counts[table] = result.scalar()
            except Exception:
                counts[table] = -1  # í…Œì´ë¸” ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜

    return counts


def create_index(engine, table: str, index_name: str, columns: str | tuple, dry_run: bool = False) -> bool:
    """
    ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        engine: SQLAlchemy ì—”ì§„
        table: í…Œì´ë¸”ëª…
        index_name: ì¸ë±ìŠ¤ëª…
        columns: ì»¬ëŸ¼ëª… (ë¬¸ìì—´) ë˜ëŠ” ì»¬ëŸ¼ íŠœí”Œ (ë³µí•© ì¸ë±ìŠ¤)
        dry_run: Trueë©´ ì‹¤ì œ ìƒì„±í•˜ì§€ ì•Šê³  SQLë§Œ ì¶œë ¥

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    if isinstance(columns, tuple):
        col_str = ", ".join(f"`{c}`" for c in columns)
    else:
        col_str = f"`{columns}`"

    sql = f"CREATE INDEX `{index_name}` ON `{table}` ({col_str})"

    if dry_run:
        logger.info(f"[DRY-RUN] {sql}")
        return True

    try:
        with engine.connect() as conn:
            conn.execute(text(sql))
            conn.commit()
        logger.info(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_name} ON {table}({col_str})")
        return True
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {index_name} - {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="MariaDB ì¸ë±ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜")
    parser.add_argument("--dry-run", action="store_true", help="ì‹¤ì œ ìƒì„± ì—†ì´ SQLë§Œ ì¶œë ¥")
    parser.add_argument("--check-only", action="store_true", help="í˜„ì¬ ì¸ë±ìŠ¤ ìƒíƒœë§Œ í™•ì¸")
    args = parser.parse_args()

    logger.info("=" * 60)
    logger.info("MariaDB ì¸ë±ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
    logger.info("=" * 60)

    # DB ì—°ê²°
    init_engine()
    engine = get_engine()

    # í˜„ì¬ ìƒíƒœ í™•ì¸
    existing_indexes = get_existing_indexes(engine)
    existing_tables = get_existing_tables(engine)

    logger.info(f"\nğŸ“Š í˜„ì¬ DB ìƒíƒœ:")
    logger.info(f"   - í…Œì´ë¸” ìˆ˜: {len(existing_tables)}")
    logger.info(f"   - ê¸°ì¡´ ì¸ë±ìŠ¤ ìˆ˜: {len(existing_indexes)}")

    # í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜ í™•ì¸
    all_tables = list(set(t for t, _, _ in INDEXES_TO_CREATE) | set(t for t, _, _ in COMPOSITE_INDEXES))
    row_counts = get_table_row_counts(engine, all_tables)

    logger.info(f"\nğŸ“ˆ í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜:")
    for table in sorted(row_counts.keys()):
        count = row_counts[table]
        if count >= 0:
            logger.info(f"   - {table}: {count:,} rows")
        else:
            logger.info(f"   - {table}: (í…Œì´ë¸” ì—†ìŒ)")

    if args.check_only:
        logger.info("\nâœ… ìƒíƒœ í™•ì¸ ì™„ë£Œ (--check-only)")
        return

    # ìƒì„±í•  ì¸ë±ìŠ¤ í•„í„°ë§
    indexes_to_create = []
    indexes_skipped = []
    tables_missing = set()

    # ë‹¨ì¼ ì»¬ëŸ¼ ì¸ë±ìŠ¤
    for table, index_name, column in INDEXES_TO_CREATE:
        if table.upper() not in existing_tables:
            tables_missing.add(table)
            continue
        if index_name.upper() in existing_indexes:
            indexes_skipped.append((table, index_name, column))
        else:
            indexes_to_create.append((table, index_name, column))

    # ë³µí•© ì¸ë±ìŠ¤
    for table, index_name, columns in COMPOSITE_INDEXES:
        if table.upper() not in existing_tables:
            tables_missing.add(table)
            continue
        if index_name.upper() in existing_indexes:
            indexes_skipped.append((table, index_name, columns))
        else:
            indexes_to_create.append((table, index_name, columns))

    # ê²°ê³¼ ì¶œë ¥
    logger.info(f"\nğŸ“‹ ì¸ë±ìŠ¤ ë¶„ì„ ê²°ê³¼:")
    logger.info(f"   - ì‹ ê·œ ìƒì„± ì˜ˆì •: {len(indexes_to_create)}")
    logger.info(f"   - ì´ë¯¸ ì¡´ì¬ (ìŠ¤í‚µ): {len(indexes_skipped)}")
    logger.info(f"   - í…Œì´ë¸” ì—†ìŒ (ìŠ¤í‚µ): {len(tables_missing)}")

    if tables_missing:
        logger.info(f"\nâš ï¸ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í…Œì´ë¸”: {', '.join(sorted(tables_missing))}")

    if not indexes_to_create:
        logger.info("\nâœ… ëª¨ë“  ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤!")
        return

    # ì¸ë±ìŠ¤ ìƒì„±
    logger.info(f"\n{'[DRY-RUN] ' if args.dry_run else ''}ì¸ë±ìŠ¤ ìƒì„± ì‹œì‘...")

    success_count = 0
    fail_count = 0

    for table, index_name, columns in indexes_to_create:
        if create_index(engine, table, index_name, columns, dry_run=args.dry_run):
            success_count += 1
        else:
            fail_count += 1

    # ìµœì¢… ê²°ê³¼
    logger.info("\n" + "=" * 60)
    logger.info(f"{'[DRY-RUN] ' if args.dry_run else ''}ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    logger.info(f"   - ì„±ê³µ: {success_count}")
    logger.info(f"   - ì‹¤íŒ¨: {fail_count}")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
