"""
Scout â†’ Buy í•„í„° ì²´ì¸ ì¢…í•© ë¶„ì„

WATCHLIST_HISTORYì˜ llm_metadataë¥¼ í™œìš©í•˜ì—¬:
1. ì ìˆ˜ ë¶„í¬ ë¶„ì„ (hybrid_score, quant_score, llm_score)
2. Hot Watchlist ì»¤íŠ¸ë¼ì¸ë³„ D+5 ìˆ˜ìµë¥ /Hit Rate
3. MAX_WATCHLIST_SIZE ì œí•œ ì˜í–¥ ë¶„ì„
4. trade_tierë³„ ìˆ˜ìµë¥  ë¶„ì„
5. ìµœì  ì»¤íŠ¸ë¼ì¸ ì œì•ˆ

ì‚¬ìš©ë²•:
    .venv/bin/python scripts/analyze_filter_chain.py
    .venv/bin/python scripts/analyze_filter_chain.py --days 60
"""
import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import argparse
import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from scipy import stats
from sqlalchemy import text

from shared.db.connection import init_engine, session_scope


def load_watchlist_with_metadata(session, start_date, end_date):
    """WATCHLIST_HISTORYì—ì„œ llm_metadata í¬í•¨ ì „ì²´ ì¡°íšŒ"""
    result = session.execute(text("""
        SELECT SNAPSHOT_DATE, STOCK_CODE, STOCK_NAME, IS_TRADABLE, LLM_SCORE, LLM_REASON
        FROM WATCHLIST_HISTORY
        WHERE SNAPSHOT_DATE BETWEEN :start AND :end
          AND STOCK_CODE != '0001'
        ORDER BY SNAPSHOT_DATE, LLM_SCORE DESC
    """), {"start": start_date, "end": end_date})

    rows = []
    for row in result.fetchall():
        snapshot_date, code, name, is_tradable, llm_score, llm_reason = row

        # llm_metadata ì¶”ì¶œ
        metadata = {}
        if llm_reason and '[LLM_METADATA]' in llm_reason:
            try:
                meta_str = llm_reason.split('[LLM_METADATA]')[1]
                metadata = json.loads(meta_str)
            except (json.JSONDecodeError, IndexError):
                pass

        rows.append({
            'snapshot_date': snapshot_date,
            'stock_code': code,
            'stock_name': name,
            'is_tradable': is_tradable,
            'hybrid_score': llm_score,  # llm_score ì»¬ëŸ¼ì— ì €ì¥ëœ ê°’ = hybrid_score
            'quant_score': metadata.get('quant_score'),
            'llm_raw_score': metadata.get('llm_raw_score'),
            'llm_clamped_score': metadata.get('llm_clamped_score'),
            'trade_tier': metadata.get('trade_tier'),
            'risk_tag': metadata.get('risk_tag'),
            'source': metadata.get('source'),
        })

    return pd.DataFrame(rows)


def load_forward_returns(session, stock_codes, start_date, end_date):
    """ì¢…ëª©ë³„ ì¼ë³„ ì¢…ê°€ â†’ D+1/D+3/D+5/D+10 Forward Return ê³„ì‚°"""
    if not stock_codes:
        return pd.DataFrame()

    # ë‚ ì§œ ë²”ìœ„ í™•ì¥ (forward return ê³„ì‚°ìš©)
    extended_end = end_date + timedelta(days=25)

    placeholders = ', '.join([f':code_{i}' for i in range(len(stock_codes))])
    params = {f'code_{i}': code for i, code in enumerate(stock_codes)}
    params['start'] = start_date - timedelta(days=5)
    params['end'] = extended_end

    result = session.execute(text(f"""
        SELECT STOCK_CODE, PRICE_DATE, CLOSE_PRICE
        FROM STOCK_DAILY_PRICES_3Y
        WHERE STOCK_CODE IN ({placeholders})
          AND PRICE_DATE BETWEEN :start AND :end
        ORDER BY STOCK_CODE, PRICE_DATE
    """), params)

    price_data = {}
    for row in result.fetchall():
        code, price_date, close_price = row
        # PRICE_DATEê°€ datetimeì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ dateë¡œ ë³€í™˜
        if hasattr(price_date, 'date'):
            price_date = price_date.date()
        if code not in price_data:
            price_data[code] = {}
        price_data[code][price_date] = close_price

    return price_data


def calculate_forward_return(price_data, stock_code, snapshot_date, days_forward):
    """íŠ¹ì • ì¢…ëª©ì˜ D+N ìˆ˜ìµë¥  ê³„ì‚°"""
    if stock_code not in price_data:
        return None

    prices = price_data[stock_code]
    sorted_dates = sorted(prices.keys())

    # snapshot_date ì´í›„ ì²« ê±°ë˜ì¼ ì°¾ê¸°
    entry_dates = [d for d in sorted_dates if d >= snapshot_date]
    if len(entry_dates) < 2:
        return None

    # D+0 = snapshot_date ì´í›„ ì²« ê±°ë˜ì¼ (ë‹¹ì¼ ë˜ëŠ” ë‹¤ìŒ ê±°ë˜ì¼)
    entry_price = prices[entry_dates[0]]

    # D+N ê±°ë˜ì¼
    if len(entry_dates) <= days_forward:
        return None

    exit_price = prices[entry_dates[days_forward]]

    if entry_price <= 0:
        return None

    return (exit_price - entry_price) / entry_price * 100


def analyze_score_distribution(df):
    """ì ìˆ˜ ë¶„í¬ ë¶„ì„"""
    print("\n" + "=" * 70)
    print("1. ì ìˆ˜ ë¶„í¬ ë¶„ì„")
    print("=" * 70)

    for score_col in ['hybrid_score', 'quant_score', 'llm_clamped_score']:
        valid = df[score_col].dropna()
        if len(valid) == 0:
            continue
        print(f"\n  [{score_col}] (n={len(valid)})")
        print(f"    í‰ê· : {valid.mean():.1f}, ì¤‘ì•™ê°’: {valid.median():.1f}")
        print(f"    std: {valid.std():.1f}")
        print(f"    min: {valid.min():.1f}, max: {valid.max():.1f}")
        print(f"    25%: {valid.quantile(0.25):.1f}, 75%: {valid.quantile(0.75):.1f}")

    # ì ìˆ˜ êµ¬ê°„ë³„ ì¢…ëª© ìˆ˜
    print(f"\n  [hybrid_score êµ¬ê°„ë³„ ë¶„í¬]")
    bins = [0, 40, 50, 55, 58, 62, 65, 70, 75, 80, 100]
    labels = ['<40', '40-50', '50-55', '55-58', '58-62', '62-65', '65-70', '70-75', '75-80', '80+']
    df['score_bin'] = pd.cut(df['hybrid_score'], bins=bins, labels=labels, right=False)
    dist = df['score_bin'].value_counts().sort_index()
    total = len(df)
    for label, count in dist.items():
        pct = count / total * 100
        bar = 'â–ˆ' * int(pct / 2)
        print(f"    {label:>6}: {count:>4} ({pct:>5.1f}%) {bar}")


def analyze_cutoff_returns(df, price_data):
    """ì»¤íŠ¸ë¼ì¸ë³„ D+5 ìˆ˜ìµë¥  ë¶„ì„"""
    print("\n" + "=" * 70)
    print("2. Hot Watchlist ì»¤íŠ¸ë¼ì¸ë³„ ìˆ˜ìµë¥  ë¶„ì„")
    print("=" * 70)

    # Forward return ê³„ì‚°
    returns = {}
    for horizon in [1, 3, 5, 10]:
        col = f'fwd_{horizon}d'
        df[col] = df.apply(
            lambda r: calculate_forward_return(
                price_data, r['stock_code'], r['snapshot_date'], horizon
            ), axis=1
        )
        returns[horizon] = col

    # ì»¤íŠ¸ë¼ì¸ í›„ë³´
    cutoffs = [0, 45, 50, 55, 58, 60, 62, 65, 68, 70, 75]

    print(f"\n  {'ì»¤íŠ¸ë¼ì¸':>8} | {'ì¢…ëª©ìˆ˜':>6} | {'D+1 í‰ê· ':>8} | {'D+5 í‰ê· ':>8} | {'D+5 Hit':>7} | {'D+10 í‰ê· ':>9} | {'D+5 IC':>7}")
    print(f"  {'-'*8} | {'-'*6} | {'-'*8} | {'-'*8} | {'-'*7} | {'-'*9} | {'-'*7}")

    for cutoff in cutoffs:
        subset = df[df['hybrid_score'] >= cutoff]
        n = len(subset)
        if n < 5:
            continue

        d1 = subset['fwd_1d'].dropna()
        d5 = subset['fwd_5d'].dropna()
        d10 = subset['fwd_10d'].dropna()

        d1_mean = d1.mean() if len(d1) > 0 else float('nan')
        d5_mean = d5.mean() if len(d5) > 0 else float('nan')
        d5_hit = (d5 > 0).mean() * 100 if len(d5) > 0 else float('nan')
        d10_mean = d10.mean() if len(d10) > 0 else float('nan')

        # IC (Rank Correlation between score and D+5 return)
        valid_ic = subset[['hybrid_score', 'fwd_5d']].dropna()
        if len(valid_ic) >= 10:
            ic, _ = stats.spearmanr(valid_ic['hybrid_score'], valid_ic['fwd_5d'])
        else:
            ic = float('nan')

        print(f"  >= {cutoff:>4} | {n:>6} | {d1_mean:>+7.2f}% | {d5_mean:>+7.2f}% | {d5_hit:>5.1f}% | {d10_mean:>+8.2f}% | {ic:>+6.3f}")

    # ë‚ ì§œë³„ í‰ê·  í†µê³¼ ì¢…ëª©ìˆ˜ (í˜„ì¬ ì»¤íŠ¸ë¼ì¸)
    print(f"\n  [ë‚ ì§œë³„ Hot Watchlist ì§„ì… ì¢…ëª©ìˆ˜ (í˜„ì¬ ì»¤íŠ¸ë¼ì¸ 62/BULL)]")
    for cutoff in [58, 62, 65, 70]:
        by_date = df[df['hybrid_score'] >= cutoff].groupby('snapshot_date').size()
        if len(by_date) > 0:
            print(f"    >= {cutoff}: ë‚ ì§œë‹¹ í‰ê·  {by_date.mean():.1f}ê°œ, ìµœì†Œ {by_date.min()}, ìµœëŒ€ {by_date.max()}")


def analyze_watchlist_size_impact(df, price_data):
    """MAX_WATCHLIST_SIZE ì œí•œ ì˜í–¥ ë¶„ì„"""
    print("\n" + "=" * 70)
    print("3. MAX_WATCHLIST_SIZE ì œí•œ ì˜í–¥ ë¶„ì„")
    print("=" * 70)

    # ë‚ ì§œë³„ë¡œ ìƒìœ„ Nê°œ vs ì „ì²´ì˜ ìˆ˜ìµë¥  ë¹„êµ
    sizes = [10, 15, 20, 25, 30, 999]

    print(f"\n  {'Watchlistí¬ê¸°':>14} | {'ë‚ ì§œë‹¹í‰ê· ':>10} | {'D+5 í‰ê· ':>8} | {'D+5 Hit':>7} | {'íƒˆë½ì¢…ëª© D+5':>12}")
    print(f"  {'-'*14} | {'-'*10} | {'-'*8} | {'-'*7} | {'-'*12}")

    for max_size in sizes:
        included = []
        excluded = []

        for date, group in df.groupby('snapshot_date'):
            approved = group[group['hybrid_score'] >= 50].sort_values('hybrid_score', ascending=False)

            top = approved.head(max_size)
            rest = approved.iloc[max_size:]

            included.append(top)
            if len(rest) > 0:
                excluded.append(rest)

        inc_df = pd.concat(included) if included else pd.DataFrame()
        exc_df = pd.concat(excluded) if excluded else pd.DataFrame()

        # Forward returns
        inc_d5 = inc_df['fwd_5d'].dropna() if 'fwd_5d' in inc_df.columns else pd.Series()
        exc_d5 = exc_df['fwd_5d'].dropna() if 'fwd_5d' in exc_df.columns and len(exc_df) > 0 else pd.Series()

        inc_mean = inc_d5.mean() if len(inc_d5) > 0 else float('nan')
        inc_hit = (inc_d5 > 0).mean() * 100 if len(inc_d5) > 0 else float('nan')
        exc_mean = exc_d5.mean() if len(exc_d5) > 0 else float('nan')

        avg_per_date = inc_df.groupby('snapshot_date').size().mean() if len(inc_df) > 0 else 0
        label = f"Top {max_size}" if max_size < 999 else "ì „ì²´(ì œí•œì—†ìŒ)"

        exc_str = f"{exc_mean:>+7.2f}%" if not np.isnan(exc_mean) else "     N/A"
        print(f"  {label:>14} | {avg_per_date:>9.1f} | {inc_mean:>+7.2f}% | {inc_hit:>5.1f}% | {exc_str}")


def analyze_trade_tier_returns(df, price_data):
    """trade_tierë³„ ìˆ˜ìµë¥  ë¶„ì„"""
    print("\n" + "=" * 70)
    print("4. Trade Tierë³„ ìˆ˜ìµë¥  ë¶„ì„")
    print("=" * 70)

    for tier in ['TIER1', 'RECON', 'BLOCKED']:
        subset = df[df['trade_tier'] == tier]
        if len(subset) == 0:
            continue

        d5 = subset['fwd_5d'].dropna()
        d10 = subset['fwd_10d'].dropna()

        d5_mean = d5.mean() if len(d5) > 0 else float('nan')
        d5_hit = (d5 > 0).mean() * 100 if len(d5) > 0 else float('nan')
        d10_mean = d10.mean() if len(d10) > 0 else float('nan')

        print(f"\n  [{tier}] (n={len(subset)}, D+5 ë°ì´í„°={len(d5)})")
        print(f"    hybrid_score í‰ê· : {subset['hybrid_score'].mean():.1f}")
        print(f"    D+5 í‰ê· ìˆ˜ìµë¥ : {d5_mean:>+.2f}%, Hit Rate: {d5_hit:.1f}%")
        print(f"    D+10 í‰ê· ìˆ˜ìµë¥ : {d10_mean:>+.2f}%")

    # risk_tagë³„ ë¶„ì„
    print(f"\n  [Risk Tagë³„]")
    for tag in ['BULLISH', 'NEUTRAL', 'CAUTION', 'DISTRIBUTION_RISK']:
        subset = df[df['risk_tag'] == tag]
        if len(subset) < 3:
            continue
        d5 = subset['fwd_5d'].dropna()
        d5_mean = d5.mean() if len(d5) > 0 else float('nan')
        d5_hit = (d5 > 0).mean() * 100 if len(d5) > 0 else float('nan')
        print(f"    {tag:>20}: n={len(subset):>3}, D+5={d5_mean:>+.2f}%, Hit={d5_hit:.1f}%")


def analyze_redundant_filters(df):
    """ì´ì¤‘ í•„í„° ë¶„ì„: Hot Watchlist ì»¤íŠ¸ë¼ì¸ vs Executor ì»¤íŠ¸ë¼ì¸"""
    print("\n" + "=" * 70)
    print("5. ì´ì¤‘ í•„í„° ë¶„ì„ (Scout Hot WL vs Executor ìµœì†Œ ì ìˆ˜)")
    print("=" * 70)

    # Executorì—ì„œì˜ recon_score_by_regimeì™€ scoutì˜ hot watchlist ì»¤íŠ¸ë¼ì¸ì´ ë™ì¼
    # ì¦‰, hot watchlistì— ë“¤ì–´ê°„ ì¢…ëª©ì€ executorì˜ ì ìˆ˜ ì²´í¬ë¥¼ ë¬´ì¡°ê±´ í†µê³¼
    cutoff = 62  # BULL ê¸°ì¤€

    approved = df[df['hybrid_score'] >= 50]  # watchlist ì§„ì…
    hot = approved[approved['hybrid_score'] >= cutoff]  # hot watchlist ì§„ì…
    blocked_by_hot = approved[approved['hybrid_score'] < cutoff]  # hotì—ì„œ íƒˆë½

    print(f"\n  BULL ì‹œì¥ ê¸°ì¤€ (ì»¤íŠ¸ë¼ì¸ 62):")
    print(f"    Watchlist ì§„ì… (hybrid >= 50): {len(approved)}ê°œ")
    print(f"    Hot Watchlist ì§„ì… (hybrid >= 62): {len(hot)}ê°œ")
    print(f"    Hot WLì—ì„œ íƒˆë½ (50 <= hybrid < 62): {len(blocked_by_hot)}ê°œ")

    if 'fwd_5d' in df.columns:
        hot_d5 = hot['fwd_5d'].dropna()
        blocked_d5 = blocked_by_hot['fwd_5d'].dropna()

        if len(hot_d5) > 0 and len(blocked_d5) > 0:
            print(f"\n    Hot WL ì§„ì… ì¢…ëª© D+5: {hot_d5.mean():>+.2f}% (Hit: {(hot_d5>0).mean()*100:.1f}%)")
            print(f"    Hot WL íƒˆë½ ì¢…ëª© D+5: {blocked_d5.mean():>+.2f}% (Hit: {(blocked_d5>0).mean()*100:.1f}%)")
            print(f"    â†’ íƒˆë½ ì¢…ëª©ì´ {'ë” ë‚˜ì¨' if blocked_d5.mean() < hot_d5.mean() else 'ì˜¤íˆë ¤ ë” ë‚˜ìŒ (ì»¤íŠ¸ë¼ì¸ì´ ê¸°íšŒ ì°¨ë‹¨!)'}")


def print_recommendations(df):
    """ìµœì ê°’ ì œì•ˆ"""
    print("\n" + "=" * 70)
    print("6. ì¢…í•© ì œì•ˆ")
    print("=" * 70)

    if 'fwd_5d' not in df.columns:
        print("  Forward return ë°ì´í„° ì—†ìŒ - ì œì•ˆ ë¶ˆê°€")
        return

    # ìµœì  ì»¤íŠ¸ë¼ì¸ ì°¾ê¸°: D+5 í‰ê·  * Hit Rate ë³µí•© ì ìˆ˜
    cutoffs = range(45, 76)
    best_score = -999
    best_cutoff = 50

    for c in cutoffs:
        subset = df[df['hybrid_score'] >= c]
        d5 = subset['fwd_5d'].dropna()
        if len(d5) < 10:
            continue
        composite = d5.mean() * (d5 > 0).mean()
        if composite > best_score:
            best_score = composite
            best_cutoff = c

    print(f"\n  ìµœì  Hot Watchlist ì»¤íŠ¸ë¼ì¸ (D+5 í‰ê· Ã—Hit Rate ê¸°ì¤€): {best_cutoff}")
    print(f"  í˜„ì¬ BULL ì»¤íŠ¸ë¼ì¸: 62 â†’ {'ìœ ì§€' if best_cutoff == 62 else f'{best_cutoff}ìœ¼ë¡œ ë³€ê²½ ê¶Œì¥'}")


def main():
    parser = argparse.ArgumentParser(description="Scoutâ†’Buy í•„í„° ì²´ì¸ ì¢…í•© ë¶„ì„")
    parser.add_argument('--days', type=int, default=30, help='ë¶„ì„ ê¸°ê°„ (ì¼)')
    args = parser.parse_args()

    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=args.days)

    print(f"ğŸ“Š Scout â†’ Buy í•„í„° ì²´ì¸ ì¢…í•© ë¶„ì„")
    print(f"   ê¸°ê°„: {start_date} ~ {end_date} ({args.days}ì¼)")

    init_engine()

    with session_scope() as session:
        # 1. ë°ì´í„° ë¡œë”©
        print(f"\nğŸ”„ ë°ì´í„° ë¡œë”© ì¤‘...")
        df = load_watchlist_with_metadata(session, start_date, end_date)

        if len(df) == 0:
            print("âŒ WATCHLIST_HISTORY ë°ì´í„° ì—†ìŒ!")
            return

        n_dates = df['snapshot_date'].nunique()
        print(f"   Watchlist íˆìŠ¤í† ë¦¬: {len(df)}ê±´, {n_dates}ì¼")

        # metadata ì¡´ì¬ ë¹„ìœ¨
        has_meta = df['quant_score'].notna().sum()
        print(f"   llm_metadata í¬í•¨: {has_meta}/{len(df)} ({has_meta/len(df)*100:.0f}%)")

        # 2. Forward returns ë¡œë”©
        stock_codes = df['stock_code'].unique().tolist()
        print(f"   ì¢…ëª©ìˆ˜: {len(stock_codes)}ê°œ, Forward return ê³„ì‚° ì¤‘...")
        price_data = load_forward_returns(session, stock_codes, start_date, end_date)

        # Forward return ì»¬ëŸ¼ ì¶”ê°€
        for horizon in [1, 3, 5, 10]:
            df[f'fwd_{horizon}d'] = df.apply(
                lambda r: calculate_forward_return(
                    price_data, r['stock_code'], r['snapshot_date'], horizon
                ), axis=1
            )

        fwd5_count = df['fwd_5d'].notna().sum()
        print(f"   D+5 return ê³„ì‚° ì™„ë£Œ: {fwd5_count}/{len(df)}")

        # 3. ë¶„ì„ ì‹¤í–‰
        analyze_score_distribution(df)
        analyze_cutoff_returns(df, price_data)
        analyze_watchlist_size_impact(df, price_data)
        analyze_trade_tier_returns(df, price_data)
        analyze_redundant_filters(df)
        print_recommendations(df)

        print(f"\n{'='*70}")
        print(f"ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
