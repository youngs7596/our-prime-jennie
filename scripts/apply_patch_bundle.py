#!/usr/bin/env python3
"""
scripts/apply_patch_bundle.py

Applies the patch bundle generated by the Daily Council.
- Validates target files against ALLOWED_PATHS.
- Creates backups before applying.
- Uses `patch` command to apply unified diffs.
- Defaults to DRY-RUN.
"""

import argparse
import json
import logging
import os
import sys
import shutil
import tempfile
import subprocess
from pathlib import Path
from typing import List, Dict, Any

# Logging Setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("PatchApplicator")

ALLOWED_PREFIXES = [
    "schemas/",
    "prompts/",
    "rules/",
    "tests/",
    # "shared/llm_constants.py" # Maybe allowed? Plan says No. Sticking to strict plan.
]

def parse_args():
    parser = argparse.ArgumentParser(description="Apply Patch Bundle")
    parser.add_argument("--input", required=True, help="Path to patch_bundle.json")
    parser.add_argument("--apply", action="store_true", help="Actually apply the patches (default is Dry-Run)")
    parser.add_argument("--no-backup", action="store_true", help="Skip creating backup files (Not recommended)")
    return parser.parse_args()

def is_safe_path(target_path: str) -> bool:
    # Normalize path
    target = Path(target_path).resolve()
    root = Path(os.getcwd()).resolve()
    
    # Check if relative path starts with allowed prefixes
    try:
        rel_path = target.relative_to(root)
        rel_str = str(rel_path)
        for prefix in ALLOWED_PREFIXES:
            if rel_str.startswith(prefix):
                 return True
        return False
    except ValueError:
        return False

def apply_patch(target_file: Path, diff_content: str, dry_run: bool, backup: bool):
    if not target_file.exists():
        logger.error(f"❌ Target file not found: {target_file}")
        return False
        
    if not is_safe_path(str(target_file)):
        logger.error(f"⛔ Security Block: Modification to '{target_file}' is NOT allowed.")
        return False

    logger.info(f"Target: {target_file}")
    
    if dry_run:
        logger.info("  [Dry-Run] Would apply diff:")
        for line in diff_content.splitlines()[:5]:
             logger.info(f"    {line}")
        if len(diff_content.splitlines()) > 5:
             logger.info("    ...")
        return True

    # Backup
    if backup:
        backup_path = target_file.with_suffix(target_file.suffix + ".bak")
        shutil.copy2(target_file, backup_path)
        logger.info(f"  [Backup] Created {backup_path}")

    # Apply Patch via subprocess
    # We write diff to a temp file and feed it to `patch`
    with tempfile.NamedTemporaryFile(mode='w', suffix='.diff', delete=False) as tmp_diff:
        tmp_diff.write(diff_content)
        tmp_diff_path = tmp_diff.name
        
    try:
        # patch -p1 < diff.patch ?? or just patch file diff?
        # Usually unified diffs contain path info "--- a/file +++ b/file"
        # If the diff inside JSON is just the content changes relative to the file, we might need to be careful.
        # Assuming the diff is a standard Unified Diff header. 
        # But if LLM generates it, it might just be the hunk.
        # If Junho prompt says "Generate unified diffs", Qwen/GPT might generate:
        # --- filename
        # +++ filename
        # @@ ... @@
        # 
        # If so, `patch` command needs context.
        # Let's try `patch {target_file} {diff_file}`
        
        cmd = ["patch", str(target_file), str(tmp_diff_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("  ✅ Patch applied successfully.")
            os.remove(tmp_diff_path)
            return True
        else:
            logger.error(f"  ❌ Patch failed: {result.stderr}")
            # Rollback
            if backup and backup_path.exists():
                shutil.move(backup_path, target_file)
                logger.warning("  ↪️ Rolled back to backup.")
            os.remove(tmp_diff_path)
            return False
            
    except Exception as e:
        logger.error(f"  ❌ Critical Error: {e}")
        if backup and backup_path.exists():
             shutil.move(backup_path, target_file)
        if os.path.exists(tmp_diff_path):
             os.remove(tmp_diff_path)
        return False

def main():
    args = parse_args()
    
    with open(args.input, "r", encoding="utf-8") as f:
        bundle = json.load(f)
        
    logger.info(f"Loaded Bundle: {bundle.get('bundle_id')} (Drafted: {bundle.get('created_at')})")
    
    patches = bundle.get("patches", [])
    if not patches:
        logger.info("No patches in bundle.")
        return

    success_count = 0
    fail_count = 0
    
    for patch in patches:
        target = Path(patch["target_file"])
        diff = patch["diff"]
        desc = patch["description"]
        
        logger.info(f"\nProcessing Patch: {desc}")
        
        if apply_patch(target, diff, not args.apply, not args.no_backup):
            success_count += 1
        else:
            fail_count += 1
            
    logger.info("-" * 40)
    mode = "DRY-RUN" if not args.apply else "APPLIED"
    logger.info(f"Summary [{mode}]: {success_count} Success, {fail_count} Failed")
    
    if fail_count > 0 and args.apply:
        sys.exit(1)

if __name__ == "__main__":
    main()
