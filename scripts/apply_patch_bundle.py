#!/usr/bin/env python3
"""
scripts/apply_patch_bundle.py

Applies the patch bundle generated by the Daily Council.
- Validates target files against ALLOWED_PATHS.
- Creates backups before applying.
- Uses `patch` command to apply unified diffs.
- Defaults to DRY-RUN.
"""

import argparse
import json
import logging
import os
import sys
import shutil
import tempfile
import subprocess
from pathlib import Path
from typing import List, Dict, Any

# Logging Setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("PatchApplicator")

ALLOWED_PREFIXES = [
    "schemas/",
    "prompts/",
    "rules/",
    "tests/",
    "config/",
    # "shared/llm_constants.py" # Maybe allowed? Plan says No. Sticking to strict plan.
]

def parse_args():
    parser = argparse.ArgumentParser(description="Apply Patch Bundle")
    parser.add_argument("--input", required=True, help="Path to patch_bundle.json")
    parser.add_argument("--apply", action="store_true", help="Actually apply the patches (default is Dry-Run)")
    parser.add_argument("--no-backup", action="store_true", help="Skip creating backup files (Not recommended)")
    return parser.parse_args()

def is_safe_path(target_path: str) -> bool:
    # Normalize path
    target = Path(target_path).resolve()
    root = Path(os.getcwd()).resolve()
    
    # Check if relative path starts with allowed prefixes
    try:
        rel_path = target.relative_to(root)
        rel_str = str(rel_path)
        for prefix in ALLOWED_PREFIXES:
            if rel_str.startswith(prefix):
                 return True
        return False
    except ValueError:
        return False

def apply_patch(target_file: Path, diff_content: str, dry_run: bool, backup: bool):
    if not target_file.exists():
        logger.error(f"❌ Target file not found: {target_file}")
        return False
        
    if not is_safe_path(str(target_file)):
        logger.error(f"⛔ Security Block: Modification to '{target_file}' is NOT allowed.")
        return False

    logger.info(f"Target: {target_file}")
    
    if dry_run:
        logger.info("  [Dry-Run] Would apply diff:")
        for line in diff_content.splitlines()[:5]:
             logger.info(f"    {line}")
        if len(diff_content.splitlines()) > 5:
             logger.info("    ...")
        return True

    # Backup
    if backup:
        backup_path = target_file.with_suffix(target_file.suffix + ".bak")
        shutil.copy2(target_file, backup_path)
        logger.info(f"  [Backup] Created {backup_path}")

    # Apply Patch via subprocess
    # We write diff to a temp file and feed it to `patch`
    with tempfile.NamedTemporaryFile(mode='w', suffix='.diff', delete=False) as tmp_diff:
        tmp_diff.write(diff_content)
        tmp_diff_path = tmp_diff.name
        
    try:
        # patch -p1 < diff.patch ?? or just patch file diff?
        # Usually unified diffs contain path info "--- a/file +++ b/file"
        # If the diff inside JSON is just the content changes relative to the file, we might need to be careful.
        # Assuming the diff is a standard Unified Diff header. 
        # But if LLM generates it, it might just be the hunk.
        # If Junho prompt says "Generate unified diffs", Qwen/GPT might generate:
        # --- filename
        # +++ filename
        # @@ ... @@
        # 
        # If so, `patch` command needs context.
        # Let's try `patch {target_file} {diff_file}`
        
        cmd = ["patch", str(target_file), str(tmp_diff_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            logger.info("  ✅ Patch applied successfully.")
            os.remove(tmp_diff_path)
            return True
        else:
            logger.error(f"  ❌ Patch failed: {result.stderr}")
            # Rollback
            if backup and backup_path.exists():
                shutil.move(backup_path, target_file)
                logger.warning("  ↪️ Rolled back to backup.")
            os.remove(tmp_diff_path)
            return False
            
    except Exception as e:
        logger.error(f"  ❌ Critical Error: {e}")
        if backup and backup_path.exists():
             shutil.move(backup_path, target_file)
        if os.path.exists(tmp_diff_path):
             os.remove(tmp_diff_path)
        return False

DANGEROUS_KEYWORDS = [
    "rm -rf", "shutil.rmtree", "os.remove", "os.unlink", # 삭제 관련
    "DROP TABLE", "DELETE FROM", "TRUNCATE", # DB 관련
    "subprocess", "os.system", "popen", # 시스템 호출 관련
    "sudo", "chmod 777", # 권한 관련
    "mkfs", "dd if=" # 치명적 시스템 명령
]

def check_safety(diff_content: str) -> bool:
    """위험한 키워드가 포함되어 있는지 검사"""
    for keyword in DANGEROUS_KEYWORDS:
        if keyword in diff_content:
            logger.error(f"⛔ Security Violation: Detected dangerous keyword '{keyword}' in patch.")
            return False
    return True

def normalize_bundle(bundle: Dict[str, Any]) -> List[Dict[str, Any]]:
    """번들 스키마를 정규화하여 패치 리스트를 추출"""
    patches = []
    
    # 1. 'patches' 키 확인
    if "patches" in bundle:
        patches = bundle["patches"]
    # 2. 'changes' 키 확인 (가끔 LLM이 이걸 씀)
    elif "changes" in bundle:
        patches = bundle["changes"]
        logger.warning("⚠️ Schema Mismatch: Used 'changes' key instead of 'patches'. (Auto-corrected)")
    # 3. 'patch_list' 키 확인
    elif "patch_list" in bundle:
        patches = bundle["patch_list"]
        logger.warning("⚠️ Schema Mismatch: Used 'patch_list' key instead of 'patches'. (Auto-corrected)")
    # 4. 'patch_candidates' 키 확인 (Minji Mock)
    elif "patch_candidates" in bundle:
        patches = bundle["patch_candidates"]
        logger.warning("⚠️ Schema Mismatch: Used 'patch_candidates' key instead of 'patches'. (Auto-corrected)")
    
    normalized_patches = []
    for p in patches:
        # 필드 이름 정규화
        target = p.get("target_file") or p.get("file") or p.get("path")
        diff = p.get("diff") or p.get("content") or p.get("patch")
        desc = p.get("description") or p.get("summary") or "No description"
        
        if target and diff:
            normalized_patches.append({
                "target_file": target,
                "diff": diff,
                "description": desc
            })
        else:
            logger.warning(f"⚠️ Skipping invalid patch item: {p.keys()}")
            
    return normalized_patches

def main():
    args = parse_args()
    
    if not os.path.exists(args.input):
        logger.error(f"Input file not found: {args.input}")
        sys.exit(1)

    with open(args.input, "r", encoding="utf-8") as f:
        bundle = json.load(f)
        
    logger.info(f"Loaded Bundle: {bundle.get('bundle_id')} (Drafted: {bundle.get('created_at')})")
    
    patches = normalize_bundle(bundle)
    if not patches:
        logger.info("No valid patches found in bundle.")
        return

    success_count = 0
    fail_count = 0
    
    for patch in patches:
        target = Path(patch["target_file"])
        diff = patch["diff"]
        desc = patch["description"]
        
        logger.info(f"\nProcessing Patch: {desc}")
        
        # Safety Check
        if not check_safety(diff):
            fail_count += 1
            continue

        if apply_patch(target, diff, not args.apply, not args.no_backup):
            success_count += 1
        else:
            fail_count += 1
            
    logger.info("-" * 40)
    mode = "DRY-RUN" if not args.apply else "APPLIED"
    logger.info(f"Summary [{mode}]: {success_count} Success, {fail_count} Failed")
    
    if fail_count > 0 and args.apply:
        sys.exit(1)

if __name__ == "__main__":
    main()
