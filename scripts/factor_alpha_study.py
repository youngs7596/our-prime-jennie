"""
Alpha Factor Study: ì „í†µì  í€€íŠ¸ ë°©ë²•ë¡ ìœ¼ë¡œ íŒ©í„°ë³„ ìˆ˜ìµ ì˜ˆì¸¡ë ¥ ë¶„ì„

ë°©ë²•ë¡ :
  1. ë§¤ì£¼ ê¸ˆìš”ì¼(ë¦¬ë°¸ëŸ°ì‹±ì¼)ë§ˆë‹¤ ê° íŒ©í„°ë¡œ ì¢…ëª© ë­í‚¹
  2. ë­í‚¹ê³¼ í–¥í›„ 5ì¼/10ì¼ ìˆ˜ìµë¥ ì˜ ìƒê´€ê´€ê³„(IC) ì¸¡ì •
  3. ìƒìœ„ 20% vs í•˜ìœ„ 20% ìˆ˜ìµë¥  ë¹„êµ (Long-Short)
  4. ICì˜ í‰ê· , í‘œì¤€í¸ì°¨, IR(Information Ratio) ê³„ì‚°

ì‚¬ìš©ë²•:
    .venv/bin/python scripts/factor_alpha_study.py
"""
import os
import sys
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from scipy import stats

from sqlalchemy import func as sa_func
from shared.db.connection import init_engine, session_scope
from shared.db.models import StockDailyPrice, StockMaster, StockInvestorTrading, NewsSentiment

MIN_MARKET_CAP = 3000_0000_0000  # 3,000ì–µ
LOOKBACK_DAYS = 120  # íŒ©í„° ê³„ì‚°ìš© ì—¬ìœ  ë°ì´í„° í™•ë³´ (90ì¼ ë¶„ì„ + 20ì¼ ì›Œë°ì—…)
FORWARD_DAYS = [5, 10]  # ìˆ˜ìµë¥  ì¸¡ì • ê¸°ê°„
ABNORMAL_DAILY_CHANGE_PCT = 50.0


# ============================================================
# ë°ì´í„° ë¡œë“œ
# ============================================================

def load_all_data(session):
    """ë¶„ì„ì— í•„ìš”í•œ ëª¨ë“  ë°ì´í„° ë¡œë“œ"""
    cutoff_date = (datetime.now() - timedelta(days=LOOKBACK_DAYS)).date()

    # 1) ì‹œì´ ëŒ€í˜•ì£¼ í•„í„°
    masters = session.query(
        StockMaster.stock_code, StockMaster.stock_name, StockMaster.market_cap
    ).filter(StockMaster.market_cap >= MIN_MARKET_CAP).all()

    target_codes = {m.stock_code for m in masters}
    name_map = {m.stock_code: m.stock_name for m in masters}
    cap_map = {m.stock_code: float(m.market_cap) if m.market_cap else 0 for m in masters}
    print(f"ğŸ“Š ì‹œì´ â‰¥ 3,000ì–µ ëŒ€ìƒ: {len(target_codes)}ê°œ ì¢…ëª©")

    # 2) ì¼ë´‰ ê°€ê²©
    print("   ê°€ê²© ë°ì´í„° ë¡œë“œ ì¤‘...")
    prices = session.query(
        StockDailyPrice.stock_code,
        StockDailyPrice.price_date,
        StockDailyPrice.open_price,
        StockDailyPrice.close_price,
        StockDailyPrice.high_price,
        StockDailyPrice.low_price,
        StockDailyPrice.volume,
    ).filter(
        StockDailyPrice.price_date >= cutoff_date,
        StockDailyPrice.stock_code.in_(target_codes),
    ).order_by(
        StockDailyPrice.stock_code,
        StockDailyPrice.price_date,
    ).all()

    df_price = pd.DataFrame(prices, columns=[
        'stock_code', 'date', 'open', 'close', 'high', 'low', 'volume'
    ])
    df_price['date'] = pd.to_datetime(df_price['date'])

    # ë¹„ì •ìƒ ë³€ë™ ì¢…ëª© ì œê±°
    abnormal_codes = set()
    for code in df_price['stock_code'].unique():
        sdf = df_price[df_price['stock_code'] == code].sort_values('date')
        rets = sdf['close'].pct_change().abs() * 100
        if rets.max() > ABNORMAL_DAILY_CHANGE_PCT:
            abnormal_codes.add(code)
    if abnormal_codes:
        df_price = df_price[~df_price['stock_code'].isin(abnormal_codes)]
        print(f"   ë¹„ì •ìƒ ë³€ë™ ì œì™¸: {len(abnormal_codes)}ê°œ")

    print(f"   â†’ ê°€ê²©: {len(df_price):,}ê±´, {df_price['stock_code'].nunique()}ê°œ ì¢…ëª©, "
          f"{df_price['date'].min().date()} ~ {df_price['date'].max().date()}")

    # 3) ìˆ˜ê¸‰ ë°ì´í„°
    print("   ìˆ˜ê¸‰ ë°ì´í„° ë¡œë“œ ì¤‘...")
    inv_rows = session.query(
        StockInvestorTrading.stock_code,
        StockInvestorTrading.trade_date,
        StockInvestorTrading.foreign_net_buy,
        StockInvestorTrading.institution_net_buy,
        StockInvestorTrading.individual_net_buy,
    ).filter(
        StockInvestorTrading.trade_date >= cutoff_date,
        StockInvestorTrading.stock_code.in_(target_codes),
    ).all()

    df_inv = pd.DataFrame(inv_rows, columns=[
        'stock_code', 'date', 'foreign_net', 'institution_net', 'individual_net'
    ])
    df_inv['date'] = pd.to_datetime(df_inv['date'])
    for col in ['foreign_net', 'institution_net', 'individual_net']:
        df_inv[col] = df_inv[col].astype(float)
    print(f"   â†’ ìˆ˜ê¸‰: {len(df_inv):,}ê±´")

    # 4) ë‰´ìŠ¤ ê°ì„±
    print("   ë‰´ìŠ¤ ê°ì„± ë¡œë“œ ì¤‘...")
    news_rows = session.query(
        NewsSentiment.stock_code,
        NewsSentiment.created_at,
        NewsSentiment.sentiment_score,
    ).filter(
        NewsSentiment.created_at >= cutoff_date,
        NewsSentiment.stock_code.in_(target_codes),
    ).all()

    df_news = pd.DataFrame(news_rows, columns=['stock_code', 'date', 'sentiment'])
    if not df_news.empty:
        df_news['date'] = pd.to_datetime(df_news['date']).dt.normalize()
        df_news['sentiment'] = df_news['sentiment'].astype(float)
    print(f"   â†’ ë‰´ìŠ¤: {len(df_news):,}ê±´")

    return df_price, df_inv, df_news, name_map, cap_map


# ============================================================
# íŒ©í„° ê³„ì‚°
# ============================================================

def compute_all_factors(df_price, df_inv, df_news, cap_map):
    """
    ê° ì¢…ëª©/ë‚ ì§œë³„ë¡œ íŒ©í„° ê°’ + í–¥í›„ ìˆ˜ìµë¥ ì„ ê³„ì‚°
    ë¦¬ë°¸ëŸ°ì‹± ì£¼ê¸°: ë§¤ì£¼ (5ê±°ë˜ì¼ë§ˆë‹¤)
    """
    all_dates = sorted(df_price['date'].unique())
    stock_codes = sorted(df_price['stock_code'].unique())

    # ì¢…ëª©ë³„ ì‹œê³„ì—´ í”¼ë²—
    pivot_close = df_price.pivot(index='date', columns='stock_code', values='close').sort_index()
    pivot_high = df_price.pivot(index='date', columns='stock_code', values='high').sort_index()
    pivot_low = df_price.pivot(index='date', columns='stock_code', values='low').sort_index()
    pivot_volume = df_price.pivot(index='date', columns='stock_code', values='volume').sort_index()

    # ìˆ˜ê¸‰ í”¼ë²—
    inv_foreign = df_inv.pivot_table(index='date', columns='stock_code', values='foreign_net', aggfunc='sum')
    inv_institution = df_inv.pivot_table(index='date', columns='stock_code', values='institution_net', aggfunc='sum')

    # ë‰´ìŠ¤ ê°ì„± í”¼ë²— (ì¼ë³„ í‰ê· )
    if not df_news.empty:
        news_pivot = df_news.pivot_table(index='date', columns='stock_code', values='sentiment', aggfunc='mean')
    else:
        news_pivot = pd.DataFrame()

    # ìˆ˜ìµë¥  ê³„ì‚°
    returns_1d = pivot_close.pct_change(1)
    returns_5d = pivot_close.pct_change(5)
    returns_10d = pivot_close.pct_change(10)
    returns_20d = pivot_close.pct_change(20)

    # í–¥í›„ ìˆ˜ìµë¥  (forward returns)
    fwd_5d = pivot_close.pct_change(5).shift(-5)
    fwd_10d = pivot_close.pct_change(10).shift(-10)

    # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ (5ê±°ë˜ì¼ë§ˆë‹¤)
    rebal_dates = [all_dates[i] for i in range(25, len(all_dates) - 12, 5)]
    # ì›Œë°ì—… 25ì¼(RSI ë“± ê³„ì‚°), ì•ìœ¼ë¡œ 12ì¼(fwd_10d+ì—¬ìœ ) í•„ìš”

    print(f"\nğŸ“… ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ: {len(rebal_dates)}íšŒ ({pd.Timestamp(rebal_dates[0]).date()} ~ {pd.Timestamp(rebal_dates[-1]).date()})")

    records = []

    for rdate in rebal_dates:
        # í•´ë‹¹ ë‚ ì§œê¹Œì§€ì˜ ë°ì´í„°ë¡œ íŒ©í„° ê³„ì‚°
        loc_idx = pivot_close.index.get_loc(rdate)

        for code in stock_codes:
            if code not in pivot_close.columns:
                continue

            close_series = pivot_close[code].iloc[:loc_idx + 1]
            if close_series.isna().iloc[-1] or len(close_series.dropna()) < 25:
                continue

            closes = close_series.dropna().values
            cur_price = closes[-1]

            # --- íŒ©í„° ê³„ì‚° ---
            factors = {}

            # [1] ëª¨ë©˜í…€ íŒ©í„°
            if len(closes) >= 6:
                factors['momentum_5d'] = (cur_price / closes[-6] - 1) * 100
            if len(closes) >= 11:
                factors['momentum_10d'] = (cur_price / closes[-11] - 1) * 100
            if len(closes) >= 21:
                factors['momentum_20d'] = (cur_price / closes[-21] - 1) * 100

            # [2] ë‹¨ê¸° ë°˜ì „ (Short-term Reversal)
            if len(closes) >= 4:
                factors['reversal_3d'] = -(cur_price / closes[-4] - 1) * 100  # ë¶€í˜¸ ë°˜ì „: í•˜ë½ ë§ì„ìˆ˜ë¡ ë†’ì€ ê°’

            # [3] RSI (14ì¼)
            if len(closes) >= 15:
                deltas = np.diff(closes[-15:])
                gains = np.where(deltas > 0, deltas, 0)
                losses = np.where(deltas < 0, -deltas, 0)
                avg_gain = np.mean(gains)
                avg_loss = np.mean(losses)
                if avg_loss > 0:
                    rs = avg_gain / avg_loss
                    factors['rsi_14'] = 100 - (100 / (1 + rs))
                else:
                    factors['rsi_14'] = 100.0

            # [4] ê³¼ë§¤ë„ ë°˜ì „ ì‹œê·¸ë„ (RSI < 40ì´ë©´ ë†’ì€ ê°’)
            if 'rsi_14' in factors:
                factors['oversold_signal'] = max(0, 50 - factors['rsi_14'])  # RSI 30ì´ë©´ 20, RSI 50ì´ë©´ 0

            # [5] ë³€ë™ì„± (20ì¼ ì‹¤í˜„ ë³€ë™ì„±)
            if len(closes) >= 21:
                daily_rets = np.diff(np.log(closes[-21:]))
                factors['volatility_20d'] = np.std(daily_rets) * np.sqrt(252) * 100

            # [6] ì €ë³€ë™ì„± íŒ©í„° (ë³€ë™ì„± ì—­ìˆ˜ â€” ì €ë³€ë™ì„± í”„ë¦¬ë¯¸ì—„)
            if 'volatility_20d' in factors and factors['volatility_20d'] > 0:
                factors['low_vol'] = -factors['volatility_20d']

            # [7] ê±°ë˜ëŸ‰ ë¹„ìœ¨
            if code in pivot_volume.columns:
                vol_series = pivot_volume[code].iloc[max(0, loc_idx - 20):loc_idx + 1].dropna()
                if len(vol_series) >= 20:
                    avg_vol_20 = vol_series.iloc[:-1].mean()
                    if avg_vol_20 > 0:
                        factors['volume_ratio'] = vol_series.iloc[-1] / avg_vol_20
                        factors['volume_trend_5d'] = vol_series.iloc[-5:].mean() / avg_vol_20

            # [8] ê±°ë˜ëŸ‰ ê¸‰ì¦ (ë‹¹ì¼ ê±°ë˜ëŸ‰ > 2x í‰ê· )
            if 'volume_ratio' in factors:
                factors['volume_surge'] = max(0, factors['volume_ratio'] - 1.5)

            # [9] MA20 ì´ê²©ë„
            if len(closes) >= 20:
                ma20 = np.mean(closes[-20:])
                factors['ma20_deviation'] = (cur_price / ma20 - 1) * 100

            # [10] ê³ ì  ëŒ€ë¹„ í•˜ë½ë¥  (Drawdown from 20d high)
            if len(closes) >= 20:
                high_20d = np.max(closes[-20:])
                factors['drawdown_20d'] = (cur_price / high_20d - 1) * 100

            # [11] ëˆŒë¦¼ëª© ë°˜ë“± ì‹œê·¸ë„ (ê³ ì  ëŒ€ë¹„ -10~-25% í•˜ë½)
            if 'drawdown_20d' in factors:
                dd = factors['drawdown_20d']
                if -25 <= dd <= -10:
                    factors['pullback_signal'] = abs(dd)  # í•˜ë½ ê¹Šì„ìˆ˜ë¡ ê°•í•œ ì‹ í˜¸
                else:
                    factors['pullback_signal'] = 0

            # [12] ë³¼ë¦°ì €ë°´ë“œ ìœ„ì¹˜
            if len(closes) >= 20:
                bb_mid = np.mean(closes[-20:])
                bb_std = np.std(closes[-20:])
                if bb_std > 0:
                    factors['bb_position'] = (cur_price - bb_mid) / (2 * bb_std)

            # [13] ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ ê·¼ì ‘ ì‹œê·¸ë„
            if 'bb_position' in factors:
                factors['bb_lower_signal'] = max(0, -factors['bb_position'] - 0.3)  # BB í•˜ë‹¨ ì´í•˜ì¼ìˆ˜ë¡ ê°•í•œ ì‹ í˜¸

            # [14] ì‹œì´ (Size factor â€” ì†Œí˜•ì£¼ í”„ë¦¬ë¯¸ì—„)
            factors['size'] = -np.log(cap_map.get(code, 1e12))  # ì‘ì„ìˆ˜ë¡ ë†’ì€ ê°’

            # [15] ìˆ˜ê¸‰ íŒ©í„°
            if code in (inv_foreign.columns if not inv_foreign.empty else []):
                inv_slice = inv_foreign[code].iloc[max(0, loc_idx - 5):loc_idx + 1].dropna()
                if len(inv_slice) > 0:
                    factors['foreign_flow_5d'] = inv_slice.sum()

            if code in (inv_institution.columns if not inv_institution.empty else []):
                inv_slice = inv_institution[code].iloc[max(0, loc_idx - 5):loc_idx + 1].dropna()
                if len(inv_slice) > 0:
                    factors['institution_flow_5d'] = inv_slice.sum()

            # [16] ìŠ¤ë§ˆíŠ¸ ë¨¸ë‹ˆ (ì™¸ì¸+ê¸°ê´€ í•©ì‚°)
            f_flow = factors.get('foreign_flow_5d', 0) or 0
            i_flow = factors.get('institution_flow_5d', 0) or 0
            if f_flow != 0 or i_flow != 0:
                factors['smart_money_5d'] = f_flow + i_flow

            # [17] ë‰´ìŠ¤ ê°ì„±
            if code in (news_pivot.columns if not news_pivot.empty else []):
                news_slice = news_pivot[code].iloc[max(0, loc_idx - 5):loc_idx + 1].dropna()
                if len(news_slice) > 0:
                    factors['news_sentiment_5d'] = news_slice.mean()

            # --- í–¥í›„ ìˆ˜ìµë¥  ---
            fwd_rets = {}
            if rdate in fwd_5d.index and code in fwd_5d.columns:
                val = fwd_5d.loc[rdate, code]
                if not pd.isna(val):
                    fwd_rets['fwd_5d'] = val * 100
            if rdate in fwd_10d.index and code in fwd_10d.columns:
                val = fwd_10d.loc[rdate, code]
                if not pd.isna(val):
                    fwd_rets['fwd_10d'] = val * 100

            if fwd_rets:
                records.append({
                    'date': rdate,
                    'stock_code': code,
                    **factors,
                    **fwd_rets,
                })

    df_factors = pd.DataFrame(records)
    print(f"âœ… íŒ©í„° ë°ì´í„°: {len(df_factors):,}ê±´ ({df_factors['stock_code'].nunique()}ê°œ ì¢…ëª© Ã— {len(rebal_dates)}íšŒ)")
    return df_factors


# ============================================================
# IC ë¶„ì„ (Information Coefficient)
# ============================================================

def analyze_ic(df_factors):
    """ê° íŒ©í„°ì˜ IC(Spearman rank correlation with forward returns) ê³„ì‚°"""

    factor_cols = [c for c in df_factors.columns
                   if c not in ('date', 'stock_code', 'fwd_5d', 'fwd_10d')]

    results = []

    for factor in factor_cols:
        for fwd_col in ['fwd_5d', 'fwd_10d']:
            ics = []
            for date, group in df_factors.groupby('date'):
                valid = group[[factor, fwd_col]].dropna()
                if len(valid) < 10:
                    continue
                ic, _ = stats.spearmanr(valid[factor], valid[fwd_col])
                if not np.isnan(ic):
                    ics.append(ic)

            if len(ics) < 3:
                continue

            ic_mean = np.mean(ics)
            ic_std = np.std(ics)
            ir = ic_mean / ic_std if ic_std > 0 else 0  # Information Ratio
            ic_positive_pct = sum(1 for x in ics if x > 0) / len(ics) * 100

            results.append({
                'factor': factor,
                'forward': fwd_col,
                'ic_mean': round(ic_mean, 4),
                'ic_std': round(ic_std, 4),
                'ir': round(ir, 3),
                'ic_positive_pct': round(ic_positive_pct, 1),
                'n_periods': len(ics),
            })

    return pd.DataFrame(results)


# ============================================================
# Quintile ë¶„ì„ (ìƒìœ„/í•˜ìœ„ 20% ìˆ˜ìµë¥  ë¹„êµ)
# ============================================================

def analyze_quintiles(df_factors):
    """íŒ©í„° ìƒìœ„ 20% vs í•˜ìœ„ 20% í–¥í›„ ìˆ˜ìµë¥  ë¹„êµ"""

    factor_cols = [c for c in df_factors.columns
                   if c not in ('date', 'stock_code', 'fwd_5d', 'fwd_10d')]

    results = []

    for factor in factor_cols:
        for fwd_col in ['fwd_5d', 'fwd_10d']:
            top_rets = []
            bot_rets = []

            for date, group in df_factors.groupby('date'):
                valid = group[[factor, fwd_col]].dropna()
                if len(valid) < 10:
                    continue

                q80 = valid[factor].quantile(0.8)
                q20 = valid[factor].quantile(0.2)

                top = valid[valid[factor] >= q80][fwd_col]
                bot = valid[valid[factor] <= q20][fwd_col]

                if len(top) > 0 and len(bot) > 0:
                    top_rets.append(top.mean())
                    bot_rets.append(bot.mean())

            if len(top_rets) < 3:
                continue

            top_avg = np.mean(top_rets)
            bot_avg = np.mean(bot_rets)
            spread = top_avg - bot_avg
            spread_std = np.std([t - b for t, b in zip(top_rets, bot_rets)])
            spread_ir = spread / spread_std if spread_std > 0 else 0

            results.append({
                'factor': factor,
                'forward': fwd_col,
                'top20_ret': round(top_avg, 2),
                'bot20_ret': round(bot_avg, 2),
                'spread': round(spread, 2),
                'spread_ir': round(spread_ir, 3),
                'n_periods': len(top_rets),
            })

    return pd.DataFrame(results)


# ============================================================
# ë©”ì¸
# ============================================================

def main():
    init_engine()

    with session_scope(readonly=True) as session:
        df_price, df_inv, df_news, name_map, cap_map = load_all_data(session)

    # íŒ©í„° ê³„ì‚°
    df_factors = compute_all_factors(df_price, df_inv, df_news, cap_map)

    if df_factors.empty:
        print("âŒ íŒ©í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # IC ë¶„ì„
    print("\n" + "=" * 90)
    print("ğŸ“Š Factor IC Analysis (Spearman Rank Correlation with Forward Returns)")
    print("=" * 90)
    print("  IC > 0: íŒ©í„° ê°’ì´ ë†’ì„ìˆ˜ë¡ í–¥í›„ ìˆ˜ìµë¥  ë†’ìŒ")
    print("  |IR| > 0.5: ì¼ë°˜ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ íŒ©í„°")
    print("  IC Positive %: ICê°€ ì–‘ìˆ˜ì¸ ê¸°ê°„ ë¹„ìœ¨ (>50% = ì¼ê´€ì„±)")
    print()

    ic_results = analyze_ic(df_factors)

    for fwd_col in ['fwd_5d', 'fwd_10d']:
        subset = ic_results[ic_results['forward'] == fwd_col].sort_values('ir', ascending=False)
        days = fwd_col.replace('fwd_', '').replace('d', '')

        print(f"  â”Œâ”€ Forward {days}D Returns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print(f"  â”‚ {'íŒ©í„°':26s} â”‚ {'ICí‰ê· ':>7s} â”‚ {'ICí‘œì¤€í¸ì°¨':>8s} â”‚ {'IR':>6s} â”‚ {'IC+ë¹„ìœ¨':>7s} â”‚ {'ê¸°ê°„':>4s} â”‚")
        print(f"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤")

        for _, row in subset.iterrows():
            marker = ""
            if abs(row['ir']) >= 0.5:
                marker = " â˜…"
            elif abs(row['ir']) >= 0.3:
                marker = " â˜†"
            print(f"  â”‚ {row['factor']:26s} â”‚ {row['ic_mean']:>+7.4f} â”‚ {row['ic_std']:>8.4f} â”‚ {row['ir']:>+6.3f} â”‚ {row['ic_positive_pct']:>6.1f}% â”‚ {row['n_periods']:>4d} â”‚{marker}")

        print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜")
        print()

    # Quintile ë¶„ì„
    print("=" * 90)
    print("ğŸ“Š Quintile Analysis (Top 20% vs Bottom 20% Average Forward Return)")
    print("=" * 90)
    print("  Spread > 0: íŒ©í„° ìƒìœ„ ì¢…ëª©ì´ í•˜ìœ„ ì¢…ëª© ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµ")
    print("  |Spread IR| > 0.5: ì¼ê´€ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ Long-Short ìˆ˜ìµ")
    print()

    q_results = analyze_quintiles(df_factors)

    for fwd_col in ['fwd_5d', 'fwd_10d']:
        subset = q_results[q_results['forward'] == fwd_col].sort_values('spread', ascending=False)
        days = fwd_col.replace('fwd_', '').replace('d', '')

        print(f"  â”Œâ”€ Forward {days}D Returns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print(f"  â”‚ {'íŒ©í„°':26s} â”‚ {'Top20%':>7s} â”‚ {'Bot20%':>7s} â”‚ {'Spread':>7s} â”‚ {'SpreadIR':>8s} â”‚ {'ê¸°ê°„':>4s} â”‚")
        print(f"  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤")

        for _, row in subset.iterrows():
            marker = ""
            if abs(row['spread_ir']) >= 0.5:
                marker = " â˜…"
            elif abs(row['spread_ir']) >= 0.3:
                marker = " â˜†"
            print(f"  â”‚ {row['factor']:26s} â”‚ {row['top20_ret']:>+6.2f}% â”‚ {row['bot20_ret']:>+6.2f}% â”‚ {row['spread']:>+6.2f}% â”‚ {row['spread_ir']:>+8.3f} â”‚ {row['n_periods']:>4d} â”‚{marker}")

        print(f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜")
        print()

    # ============================================================
    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
    # ============================================================
    print("=" * 90)
    print("ğŸ’¡ ì•ŒíŒŒ íŒ©í„° ì¸ì‚¬ì´íŠ¸ ìš”ì•½")
    print("=" * 90)

    # IC ê¸°ì¤€ ìƒìœ„ íŒ©í„°
    for fwd_col in ['fwd_5d', 'fwd_10d']:
        days = fwd_col.replace('fwd_', '').replace('d', '')
        subset = ic_results[ic_results['forward'] == fwd_col].sort_values('ir', ascending=False)
        strong = subset[subset['ir'].abs() >= 0.3]

        if not strong.empty:
            print(f"\n  [Forward {days}D] ìœ ì˜ë¯¸í•œ íŒ©í„° (|IR| â‰¥ 0.3):")
            for _, row in strong.iterrows():
                direction = "ë†’ì„ìˆ˜ë¡ â†‘" if row['ic_mean'] > 0 else "ë‚®ì„ìˆ˜ë¡ â†‘"
                print(f"    â€¢ {row['factor']:25s}  IC={row['ic_mean']:+.4f}  IR={row['ir']:+.3f}  ({direction})")
        else:
            print(f"\n  [Forward {days}D] |IR| â‰¥ 0.3ì¸ íŒ©í„° ì—†ìŒ (ë°ì´í„° ê¸°ê°„ ì§§ìŒ)")

    # Long-Short ê¸°ì¤€ ìƒìœ„ íŒ©í„°
    print()
    for fwd_col in ['fwd_5d', 'fwd_10d']:
        days = fwd_col.replace('fwd_', '').replace('d', '')
        subset = q_results[q_results['forward'] == fwd_col].sort_values('spread', ascending=False)
        top3 = subset.head(3)

        if not top3.empty:
            print(f"  [Forward {days}D] Long-Short Spread ìƒìœ„ 3ê°œ:")
            for _, row in top3.iterrows():
                print(f"    â€¢ {row['factor']:25s}  Top20%={row['top20_ret']:+.2f}%  Bot20%={row['bot20_ret']:+.2f}%  "
                      f"Spread={row['spread']:+.2f}%")

    print()


if __name__ == '__main__':
    main()
