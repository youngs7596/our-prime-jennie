
import logging
import pandas as pd
from sqlalchemy import text
from shared.db.connection import ensure_engine_initialized, session_scope

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def populate_fundamentals_pandas():
    """
    Pandasë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ë°ì´í„° ê²°í•© ë° ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    Collation ì¶©ëŒì„ í”¼í•˜ê³  ë¡œì§ì„ ë‹¨ìˆœí™”í•©ë‹ˆë‹¤.
    """
    ensure_engine_initialized()
    
    START_DATE = '2024-01-01'
    END_DATE = '2026-01-10'
    
    logger.info(f"ğŸš€ ì¬ë¬´ ë°ì´í„° ë³µêµ¬ (Pandas) ì‹œì‘ ({START_DATE} ~ {END_DATE})")
    
    with session_scope() as session:
        # 1. ì¬ë¬´ ë°ì´í„° (ESP, BPS) ë¡œë“œ
        logger.info("ğŸ“¥ ì¬ë¬´ ë°ì´í„° ë¡œë“œ ì¤‘...")
        fin_query = text("""
            SELECT STOCK_CODE, QUARTER_DATE, EPS, BPS, ROE 
            FROM FINANCIAL_METRICS_QUARTERLY 
            WHERE EPS > 0 AND BPS > 0
        """)
        fin_df = pd.read_sql(fin_query, session.bind)
        fin_df['QUARTER_DATE'] = pd.to_datetime(fin_df['QUARTER_DATE'])
        fin_df = fin_df.sort_values(['STOCK_CODE', 'QUARTER_DATE'])
        logger.info(f"   - {len(fin_df)}ê°œ ë¶„ê¸° ì¬ë¬´ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        
        # 2. ìƒì¥ ì£¼ì‹ ìˆ˜ ë¡œë“œ
        logger.info("ğŸ“¥ ìƒì¥ ì£¼ì‹ ìˆ˜ ë¡œë“œ ì¤‘...")
        master_query = text("SELECT STOCK_CODE, LISTED_SHARES FROM STOCK_MASTER")
        master_df = pd.read_sql(master_query, session.bind)
        shares_map = master_df.set_index('STOCK_CODE')['LISTED_SHARES'].to_dict()
        
        # 3. ëŒ€ìƒ ì¢…ëª© ì¡°íšŒ (ì¬ë¬´ ë°ì´í„°ê°€ ìˆëŠ” ì¢…ëª©ë§Œ)
        target_stocks = fin_df['STOCK_CODE'].unique()
        logger.info(f"ğŸ“Š ëŒ€ìƒ ì¢…ëª©: {len(target_stocks)}ê°œ")
        
        # 4. ê°€ê²© ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¢…ëª©ë³„ ì²˜ë¦¬)
        total_inserted = 0
        
        for i, code in enumerate(target_stocks):
            try:
                # í•´ë‹¹ ì¢…ëª©ì˜ ê°€ê²© ë°ì´í„° ì¡°íšŒ
                price_query = text("""
                    SELECT STOCK_CODE, PRICE_DATE, CLOSE_PRICE
                    FROM STOCK_DAILY_PRICES_3Y
                    WHERE STOCK_CODE = :code 
                      AND PRICE_DATE BETWEEN :start AND :end
                """)
                price_df = pd.read_sql(price_query, session.bind, params={'code': code, 'start': START_DATE, 'end': END_DATE})
                
                if price_df.empty:
                    continue
                    
                price_df['PRICE_DATE'] = pd.to_datetime(price_df['PRICE_DATE'])
                
                # í•´ë‹¹ ì¢…ëª©ì˜ ì¬ë¬´ ë°ì´í„°
                stock_fin = fin_df[fin_df['STOCK_CODE'] == code].copy()
                
                if stock_fin.empty:
                    continue
                
                # asof mergeë¥¼ ìœ„í•´ ì •ë ¬
                price_df = price_df.sort_values('PRICE_DATE')
                
                # backward search (ê°€ì¥ ìµœê·¼ ê³¼ê±° ë¶„ê¸° ë°ì´í„° ë§¤ì¹­)
                merged = pd.merge_asof(
                    price_df, 
                    stock_fin, 
                    left_on='PRICE_DATE', 
                    right_on='QUARTER_DATE', 
                    by='STOCK_CODE',
                    direction='backward'
                )
                
                # ê³„ì‚° (PER, PBR, Market Cap)
                # EPS, BPSê°€ ì—†ëŠ” ê²½ìš°(NaN) ì œì™¸
                merged = merged.dropna(subset=['EPS', 'BPS'])
                
                if merged.empty:
                    continue
                    
                merged['PER'] = (merged['CLOSE_PRICE'] / merged['EPS']).round(2)
                merged['PBR'] = (merged['CLOSE_PRICE'] / merged['BPS']).round(2)
                merged['MARKET_CAP'] = (merged['CLOSE_PRICE'] * shares_map.get(code, 0)).astype(int)
                merged['ROE'] = merged['ROE'].fillna(0)
                
                # DB Insertë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„
                records = []
                for _, row in merged.iterrows():
                    records.append({
                        'code': row['STOCK_CODE'],
                        'date': row['PRICE_DATE'].strftime('%Y-%m-%d'),
                        'per': float(row['PER']),
                        'pbr': float(row['PBR']),
                        'roe': float(row['ROE']),
                        'mcap': int(row['MARKET_CAP'])
                    })
                
                # Bulk Insert (ON DUPLICATE KEY UPDATE)
                if records:
                    stmt = text("""
                        INSERT INTO STOCK_FUNDAMENTALS (STOCK_CODE, TRADE_DATE, PER, PBR, ROE, MARKET_CAP, CREATED_AT, UPDATED_AT)
                        VALUES (:code, :date, :per, :pbr, :roe, :mcap, NOW(), NOW())
                        ON DUPLICATE KEY UPDATE
                            PER = VALUES(PER),
                            PBR = VALUES(PBR),
                            ROE = VALUES(ROE),
                            MARKET_CAP = VALUES(MARKET_CAP),
                            UPDATED_AT = NOW()
                    """)
                    session.execute(stmt, records)
                    total_inserted += len(records)
                    
                if (i + 1) % 10 == 0:
                    session.commit()
                    logger.info(f"   [{i+1}/{len(target_stocks)}] {code}: {len(records)}ê±´ ì²˜ë¦¬ë¨")
                    
            except Exception as e:
                logger.error(f"âŒ {code} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
        session.commit()
        logger.info(f"âœ… ì „ì²´ ì™„ë£Œ! ì´ {total_inserted}ê±´ ì‚½ì…ë¨")

if __name__ == "__main__":
    populate_fundamentals_pandas()
