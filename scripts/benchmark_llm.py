#!/usr/bin/env python3
"""
scripts/benchmark_llm.py

LLM ëª¨ë¸ ë° Concurrency ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸.
ë‹¤ì–‘í•œ ë¡œì»¬ LLM ëª¨ë¸ê³¼ ë³‘ë ¬ì²˜ë¦¬(Worker) ìˆ˜ì— ë”°ë¥¸ ì•ˆì •ì„± ë° ì²˜ë¦¬ ì†ë„ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.

[ë³€ê²½ì‚¬í•­]
- ìš”ì²­ ìˆ˜: Caseë‹¹ 30íšŒ (30ê°œ ì¢…ëª© ì‹œë®¬ë ˆì´ì…˜)
- Fail-Fast: í•œ ê±´ì´ë¼ë„ ì‹¤íŒ¨(Timeout/Error) ë°œìƒ ì‹œ í•´ë‹¹ Case ì¦‰ì‹œ ì¤‘ë‹¨
"""

import sys
import os
import time
import json
import logging
import concurrent.futures
import random
from typing import List, Dict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from shared.llm_providers import OllamaLLMProvider
from shared.llm_factory import ModelStateManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("Benchmark")

# í…ŒìŠ¤íŠ¸ ì„¤ì •
MODELS = [
    # "qwen3:32b",
    # "gpt-oss:20b",
    "gemma3:27b",
    # "deepseek-r1:32b"
]

WORKER_COUNTS = [2, 4]
TOTAL_REQUESTS_PER_CASE = 16  # 30ê°œ ì¢…ëª© í…ŒìŠ¤íŠ¸

# 30ê°œì˜ ë”ë¯¸ ë°ì´í„° ìƒì„± (KV Cache íšŒí”¼ ë° ë¦¬ì–¼í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸ìš©)
SECTORS = ["ë°˜ë„ì²´", "ì´ì°¨ì „ì§€", "ìë™ì°¨", "ë°”ì´ì˜¤", "ì¸í„°ë„·", "ê²Œì„", "í†µì‹ ", "ê¸ˆìœµ"]
NEWS_TEMPLATES = [
    "ìµœê·¼ ê¸€ë¡œë²Œ ê²½ê¸° ì¹¨ì²´ ìš°ë ¤ì—ë„ ë¶ˆêµ¬í•˜ê³  ê²¬ì¡°í•œ ì‹¤ì ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤. íŠ¹íˆ ë¶ë¯¸ ì‹œì¥ì—ì„œì˜ ì ìœ ìœ¨ í™•ëŒ€ê°€ ë‘ë“œëŸ¬ì§€ë©°, ì‹ ì œí’ˆ ì¶œì‹œ íš¨ê³¼ê°€ 3ë¶„ê¸°ë¶€í„° ë³¸ê²©í™”ë  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤. ë‹¤ë§Œ, ì›ìì¬ ê°€ê²© ìƒìŠ¹ì— ë”°ë¥¸ ì´ìµë¥  í›¼ì† ìš°ë ¤ëŠ” ì—¬ì „íˆ ì¡´ì¬í•©ë‹ˆë‹¤. CEOëŠ” ì»¨í¼ëŸ°ìŠ¤ ì½œì—ì„œ 'ë¹„ìš© ì ˆê°ì„ ìœ„í•œ TFë¥¼ êµ¬ì„±í–ˆë‹¤'ê³  ë°í˜”ì§€ë§Œ, ì‹œì¥ ë°˜ì‘ì€ ë¯¸ì§€ê·¼í•©ë‹ˆë‹¤. ê²½ìŸì‚¬ ëŒ€ë¹„ ë°¸ë¥˜ì—ì´ì…˜ ë§¤ë ¥ì€ ë†’ìœ¼ë‚˜ ìˆ˜ê¸‰ ìƒí™©ì´ ì¢‹ì§€ ì•Šì•„ ë‹¨ê¸° ë°˜ë“±ì€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
    "ëŒ€ê·œëª¨ ìˆ˜ì£¼ ê³µì‹œê°€ ë°œí‘œë˜ë©´ì„œ ì¥ ì´ˆë°˜ ê°•ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ê³„ì•½ì€ íšŒì‚¬ ì°½ì‚¬ ì´ë˜ ìµœëŒ€ ê·œëª¨ë¡œ, ë‚´ë…„ ë§¤ì¶œ ì„±ì¥ì— í¬ê²Œ ê¸°ì—¬í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìµœê·¼ ìœ ìƒì¦ì ë£¨ë¨¸ê°€ ëŒë©´ì„œ ì£¼ì£¼ë“¤ì˜ ë¶ˆì•ˆê°ì´ ì»¤ì§€ê³  ìˆìŠµë‹ˆë‹¤. íšŒì‚¬ ì¸¡ì€ 'ì‚¬ì‹¤ë¬´ê·¼'ì´ë¼ê³  ë¶€ì¸í–ˆìœ¼ë‚˜, ì¬ë¬´ êµ¬ì¡° ê°œì„ ì´ ì‹œê¸‰í•œ ìƒí™©ì„ì€ ë¶€ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì™¸êµ­ì¸ íˆ¬ììë“¤ì€ 3ì¼ ì—°ì† ìˆœë§¤ë„ë¥¼ ê¸°ë¡ ì¤‘ì…ë‹ˆë‹¤.",
    "ì‹ ì•½ ì„ìƒ 3ìƒ ê²°ê³¼ ë°œí‘œë¥¼ ì•ë‘ê³  ë°”ì´ì˜¤ ì„¹í„° ì „ë°˜ì— ê¸°ëŒ€ê°ì´ ìœ ì…ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë™ì‚¬ëŠ” ê²½ìŸ ì•½ë¬¼ ëŒ€ë¹„ ìš°ìˆ˜í•œ íš¨ëŠ¥ì„ ì…ì¦í–ˆë‹¤ê³  ì£¼ì¥í•˜ê³  ìˆìœ¼ë©°, FDA ìŠ¹ì¸ ê°€ëŠ¥ì„±ì„ ë†’ê²Œ ë³´ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì„ìƒ ì‹¤íŒ¨ ë¦¬ìŠ¤í¬ëŠ” ì–¸ì œë‚˜ ì¡´ì¬í•˜ë©°, ì‹¤íŒ¨ ì‹œ ì£¼ê°€ ê¸‰ë½ì€ ë¶ˆê°€í”¼í•©ë‹ˆë‹¤. ìµœê·¼ ê³µë§¤ë„ ì”ê³ ê°€ ê¸‰ì¦í•˜ê³  ìˆì–´ ë³€ë™ì„± í™•ëŒ€ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤.",
    "ì •ë¶€ì˜ ê·œì œ ì™„í™” ìˆ˜í˜œì£¼ë¡œ ë¶€ê°ë˜ë©° ì‹ ê³ ê°€ë¥¼ ê²½ì‹ í–ˆìŠµë‹ˆë‹¤. ì •ì±… ëª¨ë©˜í…€ì€ ë‹¹ë¶„ê°„ ì§€ì†ë  ê²ƒìœ¼ë¡œ ë³´ì´ë‚˜, ì‹¤ì ì´ ë’·ë°›ì¹¨ë˜ì§€ ì•ŠëŠ” ë‹¨ìˆœ í…Œë§ˆì„± ìƒìŠ¹ì´ë¼ëŠ” ì§€ì ë„ ìˆìŠµë‹ˆë‹¤. PER 50ë°° ìˆ˜ì¤€ì˜ ê³ í‰ê°€ ë…¼ë€ì´ ìˆìœ¼ë©°, ê¸°ê´€ íˆ¬ììë“¤ì€ ì°¨ìµ ì‹¤í˜„ì— ë‚˜ì„œëŠ” ëª¨ìŠµì…ë‹ˆë‹¤. ê¸°ìˆ ì  ë¶„ì„ìƒ ê³¼ì—´ ì‹ í˜¸ê°€ ê°ì§€ë˜ë¯€ë¡œ ì¶”ê²© ë§¤ìˆ˜ëŠ” ìì œí•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
]

def generate_mock_stocks(n=30):
    stocks = []
    for i in range(n):
        # ë‰´ìŠ¤ í…ìŠ¤íŠ¸ë¥¼ ê¸¸ê²Œ ë§Œë“¤ê¸° ìœ„í•´ 2~3ê°œë¥¼ ëœë¤ ì¡°í•©
        news_summary = " ".join(random.sample(NEWS_TEMPLATES, k=2))
        
        stocks.append({
            "name": f"í…ŒìŠ¤íŠ¸ì¢…ëª©_{i+1}",
            "code": f"{i:06d}",
            "price": random.randint(1000, 500000),
            "per": round(random.uniform(5.0, 50.0), 2),
            "pbr": round(random.uniform(0.5, 5.0), 2),
            "market_cap": f"{random.randint(1000, 50000)}ì–µ",
            "sector": random.choice(SECTORS),
            "news": news_summary
        })
    return stocks

MockStocks = generate_mock_stocks(TOTAL_REQUESTS_PER_CASE)

TEST_SCHEMA = {
    "type": "object",
    "properties": {
        "score": {"type": "integer"},
        "grade": {"type": "string"},
        "reason": {"type": "string"}
    },
    "required": ["score", "grade", "reason"]
}

def build_prompt(stock):
    return f"""
ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¢…ëª©ì— ëŒ€í•´ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

[ì¢…ëª© ì •ë³´]
- ì¢…ëª©ëª…: {stock['name']} ({stock['code']})
- í˜„ì¬ê°€: {stock['price']}ì›
- PER: {stock['per']}
- PBR: {stock['pbr']}
- ì‹œê°€ì´ì•¡: {stock['market_cap']}
- ì„¹í„°: {stock['sector']}

[ìµœê·¼ ë‰´ìŠ¤ ìš”ì•½ (ì¤‘ìš”)]
{stock['news']}

[ë¶„ì„ ìš”êµ¬ì‚¬í•­]
1. ì´ ì¢…ëª©ì˜ ì¬ë¬´ ê±´ì „ì„±ê³¼ ì„±ì¥ì„±ì„ í‰ê°€í•˜ì„¸ìš”.
2. ìœ„ ë‰´ìŠ¤ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ì˜ ê¸°íšŒì™€ ë¦¬ìŠ¤í¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
3. ìµœì¢…ì ìœ¼ë¡œ 'ë§¤ìˆ˜', 'ë§¤ë„', 'ë³´ìœ ' ì¤‘ í•˜ë‚˜ì˜ ì˜ê²¬ì„ ì œì‹œí•˜ê³ , ê·¸ ì´ìœ ë¥¼ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
4. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

JSON Schema:
{{
    "score": "integer (0-100)",
    "grade": "string (S/A/B/C/D)",
    "reason": "string (detailed analysis)"
}}
"""

def run_single_request(model: str, task_id: int, stock: Dict) -> Dict:
    """ë‹¨ì¼ LLM ìš”ì²­ ìˆ˜í–‰"""
    provider = OllamaLLMProvider(
        model=model,
        state_manager=ModelStateManager()
    )
    
    prompt = build_prompt(stock)
    start_ts = time.time()
    try:
        logger.info(f"    [Task-{task_id}] ìš”ì²­ ì‹œì‘ ({stock['name']})")
        # Timeoutì€ Provider ê¸°ë³¸ê°’(ë³´í†µ 120s~300s)ì„ ë”°ë¥´ê±°ë‚˜, í•„ìš” ì‹œ override
        result = provider.generate_json(
            prompt=prompt,
            response_schema=TEST_SCHEMA,
            temperature=0.1
        )
        elapsed = time.time() - start_ts
        logger.info(f"    âœ… [Task-{task_id}] ì„±ê³µ ({elapsed:.1f}s)")
        return {"success": True, "elapsed": elapsed, "error": None}
    except Exception as e:
        elapsed = time.time() - start_ts
        logger.error(f"    âŒ [Task-{task_id}] ì‹¤íŒ¨ ({elapsed:.1f}s): {e}")
        return {"success": False, "elapsed": elapsed, "error": str(e)}

def run_benchmark_case(model: str, workers: int, total_reqs: int) -> Dict:
    """íŠ¹ì • ëª¨ë¸ ë° Worker ìˆ˜ì— ëŒ€í•œ ë²¤ì¹˜ë§ˆí¬ ìˆ˜í–‰ (Fail-Fast ì ìš©)"""
    logger.info(f"\nğŸš€ Case Start: Model={model}, Workers={workers}, TotalReqs={total_reqs}")
    
    start_time = time.time()
    results = []
    failed_early = False
    fail_reason = None
    
    # Python 3.9+ cancel_futures=True ì§€ì›
    with concurrent.futures.ThreadPoolExecutor(max_workers=workers) as executor:
        # Future -> Task ID ë§¤í•‘
        future_to_id = {}
        for i in range(total_reqs):
            stock = MockStocks[i]
            future = executor.submit(run_single_request, model, i, stock)
            future_to_id[future] = i
        
        # as_completedë¡œ ì™„ë£Œë˜ëŠ” ìˆœì„œëŒ€ë¡œ í™•ì¸
        try:
            for future in concurrent.futures.as_completed(future_to_id):
                result = future.result()
                results.append(result)
                
                if not result['success']:
                    logger.error(f"ğŸš¨ [Fail-Fast] Task Failed! Stopping remaining tasks for this case...")
                    failed_early = True
                    fail_reason = result['error']
                    
                    # ë‚¨ì€ ëŒ€ê¸°ì¤‘ì¸ Futureë“¤ ì·¨ì†Œ ì‹œë„
                    for f in future_to_id.keys():
                        f.cancel()
                    break # Loop ì¤‘ë‹¨ -> Context Manager exit í˜¸ì¶œ -> Shutdown waiting for running threads
                    
        except Exception as e:
            logger.error(f"ğŸš¨ [System Error] {e}")
            failed_early = True
            fail_reason = str(e)

    total_time = time.time() - start_time
    
    success_count = sum(1 for r in results if r['success'])
    fail_count = total_reqs - success_count if not failed_early else "STOPPED"
    
    if failed_early:
        logger.warning(f"ğŸ›‘ Case Aborted due to failure. Success: {success_count}")
    else:
        # ë¶„ë‹¹ ì²˜ë¦¬ ê±´ìˆ˜ (Throughput)
        tpm = (success_count / total_time) * 60 if total_time > 0 else 0
        logger.info(f"ğŸ Case Done: Success={success_count}/{total_reqs}, TotalTime={total_time:.1f}s, TPM={tpm:.1f}")
    
    avg_latency = 0
    max_latency = 0
    tpm = 0
    if not failed_early and success_count > 0:
        avg_latency = sum(r['elapsed'] for r in results) / success_count
        max_latency = max(r['elapsed'] for r in results)
        tpm = (success_count / total_time) * 60

    return {
        "model": model,
        "workers": workers,
        "total_reqs": total_reqs,
        "success": success_count,
        "failed_early": failed_early,
        "fail_reason": fail_reason,
        "total_time": total_time,
        "avg_latency": avg_latency,
        "max_latency": max_latency,
        "tpm": tpm
    }

def print_table(results: List[Dict]):
    """ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "="*120)
    print(f"{'Model':<20} | {'W':<3} | {'Result':<15} | {'Time(s)':<8} | {'AvgLat':<8} | {'TPM':<8} | {'Note':<20}")
    print("-" * 120)
    
    best_tpm = 0
    best_config = None
    
    for r in results:
        status_str = f"{r['success']}/{r['total_reqs']}"
        if r['failed_early']:
            status_str = "ABORTED"
            note = f"âŒ Error: {r['fail_reason'][:15]}..."
        else:
            note = ""
            if r['tpm'] > best_tpm:
                best_tpm = r['tpm']
                best_config = f"{r['model']} ({r['workers']}w)"
                note = "ğŸ† Best Speed"
            
        print(f"{r['model']:<20} | {r['workers']:<3} | {status_str:<15} | {r['total_time']:<8.1f} | {r['avg_latency']:<8.1f} | {r['tpm']:<8.1f} | {note:<20}")
    print("="*120)
    if best_config:
        print(f"\nğŸ… Winner: {best_config} with {best_tpm:.1f} TPM (Approx. {int(best_tpm*60)} requests/hour)")
    else:
        print("\nâš ï¸ No successful configuration found.")

def main():
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    if not os.getenv("OLLAMA_GATEWAY_URL"):
        os.environ["OLLAMA_GATEWAY_URL"] = "http://localhost:11500"
        
    # Gateway ì‚¬ìš© ê°•ì œ
    os.environ["USE_OLLAMA_GATEWAY"] = "true"

    print("\nğŸï¸  LLM Stress Test Benchmark (Fail-Fast Mode)")
    print(f"Models: {MODELS}")
    print(f"Workers: {WORKER_COUNTS}")
    print(f"Requests per Case: {TOTAL_REQUESTS_PER_CASE} (Unique Stocks)")
    print("Condition: Stop immediately on ANY failure.")
    
    all_results = []
    
    for model in MODELS:
        print(f"\n==================================================")
        print(f"ğŸ¤– Testing Model: {model}")
        print(f"==================================================")
        
        for workers in WORKER_COUNTS:
            result = run_benchmark_case(model, workers, TOTAL_REQUESTS_PER_CASE)
            all_results.append(result)
            
            # ì‹¤íŒ¨í–ˆìœ¼ë©´ í•´ë‹¹ ëª¨ë¸ì˜ ë” ë†’ì€ Worker í…ŒìŠ¤íŠ¸ëŠ” ì˜ë¯¸ê°€ ì—†ì„ í™•ë¥ ì´ í¼ (ì´ë¯¸ ê³¼ë¶€í•˜)
            # í•˜ì§€ë§Œ User requestëŠ” "ë©ˆì¶”ëŠ”ê±¸ë¡œ"ê°€ "í…ŒìŠ¤íŠ¸ ì „ì²´"ì¸ì§€ "í•´ë‹¹ ì¼€ì´ìŠ¤"ì¸ì§€ ëª¨í˜¸í•¨.
            # "í•œë²ˆì´ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ê·¸ ì¦‰ì‹œ í…ŒìŠ¤íŠ¸ëŠ” ë©ˆì¶”ëŠ”ê±¸ë¡œ" -> Case ì¤‘ë‹¨ì„ ì˜ë¯¸í•œë‹¤ê³  í•´ì„.
            # ë§Œì•½ Worker=2ì—ì„œ ì‹¤íŒ¨í•˜ë©´ Worker=3, 4ë„ ì‹¤íŒ¨í•  ê²ƒì´ ë»”í•˜ë¯€ë¡œ ëª¨ë¸ ìì²´ë¥¼ ìŠ¤í‚µí•˜ëŠ”ê²Œ íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ.
            # ì—¬ê¸°ì„œëŠ” Caseë§Œ ë©ˆì¶”ê³  ë‹¤ìŒ Worker í…ŒìŠ¤íŠ¸ë¡œ ë„˜ì–´ê°ˆì§€, ëª¨ë¸ ì „ì²´ë¥¼ ìŠ¤í‚µí• ì§€ ê³ ë¯¼.
            # ë³´í†µ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ë‹ˆ, 2ì—ì„œ í„°ì§€ë©´ 3ì€ ë³¼ í•„ìš” ì—†ìŒ.
            
            if result['failed_early']:
                print(f"âš ï¸  Skipping higher worker counts for {model} due to failure at {workers} workers.")
                break # ë‹¤ìŒ ëª¨ë¸ë¡œ ë„˜ì–´ê°
            
            time.sleep(3) # Cool-down
            
    print_table(all_results)
    print("\nâœ… Benchmark Completed.")

if __name__ == "__main__":
    main()
